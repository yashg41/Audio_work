{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "MFCC COEFFICIENTS computed FROM LAPTOP "
      ],
      "metadata": {
        "id": "jPPIifYBdLhk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "QUU1zQyph0Pa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "cwYuOnnYhNWs",
        "outputId": "edde8a15-290c-4dc1-cb1d-539c2f2534cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0                                            feature  \\\n",
              "0              0  [-217.35526      70.22338    -130.38527     -5...   \n",
              "1              1  [-4.2409818e+02  1.0934077e+02 -5.2919525e+01 ...   \n",
              "2              2  [-4.5879114e+02  1.2138419e+02 -4.6520657e+01 ...   \n",
              "3              3  [-413.89984     101.66373     -35.42945      5...   \n",
              "4              4  [-4.4660352e+02  1.1368541e+02 -5.2402206e+01 ...   \n",
              "...          ...                                                ...   \n",
              "8727        8727  [-3.9858450e+02  1.3553496e+02 -5.0725018e+01 ...   \n",
              "8728        8728  [-3.4647421e+02  8.6348152e+01 -4.5168579e+01 ...   \n",
              "8729        8729  [-3.0388824e+02  1.1135945e+02 -4.5941563e+01 ...   \n",
              "8730        8730  [-3.4411008e+02  1.2545021e+02 -5.4903442e+01 ...   \n",
              "8731        8731  [-315.6028       94.854805    -37.22234      4...   \n",
              "\n",
              "                 class  \n",
              "0             dog_bark  \n",
              "1     children_playing  \n",
              "2     children_playing  \n",
              "3     children_playing  \n",
              "4     children_playing  \n",
              "...                ...  \n",
              "8727          car_horn  \n",
              "8728          car_horn  \n",
              "8729          car_horn  \n",
              "8730          car_horn  \n",
              "8731          car_horn  \n",
              "\n",
              "[8732 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6bb86166-c1f9-45d3-977d-787f9dbb193b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>feature</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[-217.35526      70.22338    -130.38527     -5...</td>\n",
              "      <td>dog_bark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[-4.2409818e+02  1.0934077e+02 -5.2919525e+01 ...</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>[-4.5879114e+02  1.2138419e+02 -4.6520657e+01 ...</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>[-413.89984     101.66373     -35.42945      5...</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>[-4.4660352e+02  1.1368541e+02 -5.2402206e+01 ...</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8727</th>\n",
              "      <td>8727</td>\n",
              "      <td>[-3.9858450e+02  1.3553496e+02 -5.0725018e+01 ...</td>\n",
              "      <td>car_horn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8728</th>\n",
              "      <td>8728</td>\n",
              "      <td>[-3.4647421e+02  8.6348152e+01 -4.5168579e+01 ...</td>\n",
              "      <td>car_horn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8729</th>\n",
              "      <td>8729</td>\n",
              "      <td>[-3.0388824e+02  1.1135945e+02 -4.5941563e+01 ...</td>\n",
              "      <td>car_horn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8730</th>\n",
              "      <td>8730</td>\n",
              "      <td>[-3.4411008e+02  1.2545021e+02 -5.4903442e+01 ...</td>\n",
              "      <td>car_horn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8731</th>\n",
              "      <td>8731</td>\n",
              "      <td>[-315.6028       94.854805    -37.22234      4...</td>\n",
              "      <td>car_horn</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8732 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6bb86166-c1f9-45d3-977d-787f9dbb193b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6bb86166-c1f9-45d3-977d-787f9dbb193b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6bb86166-c1f9-45d3-977d-787f9dbb193b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "data=pd.read_csv(\"/content/MFCC_coefficients.csv\")\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_features_df=pd.DataFrame(data,columns=['feature','class'])\n",
        "extracted_features_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "lpYNZtlKhyyJ",
        "outputId": "bf9e5ad7-fdbb-44a1-a46d-d0e0b02dd27f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                feature             class\n",
              "0     [-217.35526      70.22338    -130.38527     -5...          dog_bark\n",
              "1     [-4.2409818e+02  1.0934077e+02 -5.2919525e+01 ...  children_playing\n",
              "2     [-4.5879114e+02  1.2138419e+02 -4.6520657e+01 ...  children_playing\n",
              "3     [-413.89984     101.66373     -35.42945      5...  children_playing\n",
              "4     [-4.4660352e+02  1.1368541e+02 -5.2402206e+01 ...  children_playing\n",
              "...                                                 ...               ...\n",
              "8727  [-3.9858450e+02  1.3553496e+02 -5.0725018e+01 ...          car_horn\n",
              "8728  [-3.4647421e+02  8.6348152e+01 -4.5168579e+01 ...          car_horn\n",
              "8729  [-3.0388824e+02  1.1135945e+02 -4.5941563e+01 ...          car_horn\n",
              "8730  [-3.4411008e+02  1.2545021e+02 -5.4903442e+01 ...          car_horn\n",
              "8731  [-315.6028       94.854805    -37.22234      4...          car_horn\n",
              "\n",
              "[8732 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-61c448f9-458a-4720-b54e-625ec4f5ff5c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[-217.35526      70.22338    -130.38527     -5...</td>\n",
              "      <td>dog_bark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[-4.2409818e+02  1.0934077e+02 -5.2919525e+01 ...</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[-4.5879114e+02  1.2138419e+02 -4.6520657e+01 ...</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[-413.89984     101.66373     -35.42945      5...</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[-4.4660352e+02  1.1368541e+02 -5.2402206e+01 ...</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8727</th>\n",
              "      <td>[-3.9858450e+02  1.3553496e+02 -5.0725018e+01 ...</td>\n",
              "      <td>car_horn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8728</th>\n",
              "      <td>[-3.4647421e+02  8.6348152e+01 -4.5168579e+01 ...</td>\n",
              "      <td>car_horn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8729</th>\n",
              "      <td>[-3.0388824e+02  1.1135945e+02 -4.5941563e+01 ...</td>\n",
              "      <td>car_horn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8730</th>\n",
              "      <td>[-3.4411008e+02  1.2545021e+02 -5.4903442e+01 ...</td>\n",
              "      <td>car_horn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8731</th>\n",
              "      <td>[-315.6028       94.854805    -37.22234      4...</td>\n",
              "      <td>car_horn</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8732 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61c448f9-458a-4720-b54e-625ec4f5ff5c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-61c448f9-458a-4720-b54e-625ec4f5ff5c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-61c448f9-458a-4720-b54e-625ec4f5ff5c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "column_info=pd.DataFrame(data,columns=['class'])"
      ],
      "metadata": {
        "id": "OTTYQrHBAWbk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "qeBOGV5YZdYo",
        "outputId": "d45e2b38-76c9-4aac-da23-642c93a63f12"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 class\n",
              "0             dog_bark\n",
              "1     children_playing\n",
              "2     children_playing\n",
              "3     children_playing\n",
              "4     children_playing\n",
              "...                ...\n",
              "8727          car_horn\n",
              "8728          car_horn\n",
              "8729          car_horn\n",
              "8730          car_horn\n",
              "8731          car_horn\n",
              "\n",
              "[8732 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2cf80e0a-99ed-4916-a82e-5319344bb082\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dog_bark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8727</th>\n",
              "      <td>car_horn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8728</th>\n",
              "      <td>car_horn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8729</th>\n",
              "      <td>car_horn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8730</th>\n",
              "      <td>car_horn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8731</th>\n",
              "      <td>car_horn</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8732 rows Ã— 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2cf80e0a-99ed-4916-a82e-5319344bb082')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2cf80e0a-99ed-4916-a82e-5319344bb082 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2cf80e0a-99ed-4916-a82e-5319344bb082');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "column_info['class'].unique()#all types of classes of audio available"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHdnj7QMaiRt",
        "outputId": "82520fd1-8b9c-478d-9f17-37d80b614470"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['dog_bark', 'children_playing', 'car_horn', 'air_conditioner',\n",
              "       'street_music', 'gun_shot', 'siren', 'engine_idling', 'jackhammer',\n",
              "       'drilling'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_encoded_data = pd.get_dummies(column_info, columns = ['class'])\n",
        "one_hot_encoded_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "Bt6X2x82a8xR",
        "outputId": "902116bf-1324-4557-810d-7cb2aa9ae3ae"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      class_air_conditioner  class_car_horn  class_children_playing  \\\n",
              "0                         0               0                       0   \n",
              "1                         0               0                       1   \n",
              "2                         0               0                       1   \n",
              "3                         0               0                       1   \n",
              "4                         0               0                       1   \n",
              "...                     ...             ...                     ...   \n",
              "8727                      0               1                       0   \n",
              "8728                      0               1                       0   \n",
              "8729                      0               1                       0   \n",
              "8730                      0               1                       0   \n",
              "8731                      0               1                       0   \n",
              "\n",
              "      class_dog_bark  class_drilling  class_engine_idling  class_gun_shot  \\\n",
              "0                  1               0                    0               0   \n",
              "1                  0               0                    0               0   \n",
              "2                  0               0                    0               0   \n",
              "3                  0               0                    0               0   \n",
              "4                  0               0                    0               0   \n",
              "...              ...             ...                  ...             ...   \n",
              "8727               0               0                    0               0   \n",
              "8728               0               0                    0               0   \n",
              "8729               0               0                    0               0   \n",
              "8730               0               0                    0               0   \n",
              "8731               0               0                    0               0   \n",
              "\n",
              "      class_jackhammer  class_siren  class_street_music  \n",
              "0                    0            0                   0  \n",
              "1                    0            0                   0  \n",
              "2                    0            0                   0  \n",
              "3                    0            0                   0  \n",
              "4                    0            0                   0  \n",
              "...                ...          ...                 ...  \n",
              "8727                 0            0                   0  \n",
              "8728                 0            0                   0  \n",
              "8729                 0            0                   0  \n",
              "8730                 0            0                   0  \n",
              "8731                 0            0                   0  \n",
              "\n",
              "[8732 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0d9dbe1d-15bd-4554-880f-c9a28ad64d9a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class_air_conditioner</th>\n",
              "      <th>class_car_horn</th>\n",
              "      <th>class_children_playing</th>\n",
              "      <th>class_dog_bark</th>\n",
              "      <th>class_drilling</th>\n",
              "      <th>class_engine_idling</th>\n",
              "      <th>class_gun_shot</th>\n",
              "      <th>class_jackhammer</th>\n",
              "      <th>class_siren</th>\n",
              "      <th>class_street_music</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8727</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8728</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8729</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8730</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8731</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8732 rows Ã— 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d9dbe1d-15bd-4554-880f-c9a28ad64d9a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0d9dbe1d-15bd-4554-880f-c9a28ad64d9a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0d9dbe1d-15bd-4554-880f-c9a28ad64d9a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LABEL ENCODING"
      ],
      "metadata": {
        "id": "UU_nE4jSoRIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Split the dataset into independent and dependent dataset\n",
        "y=np.array(extracted_features_df['class'].tolist())\n",
        "y"
      ],
      "metadata": {
        "id": "QVCZ9A9liTj8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d68b25f-ad38-4721-83fa-301fd6f626e9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['dog_bark', 'children_playing', 'children_playing', ...,\n",
              "       'car_horn', 'car_horn', 'car_horn'], dtype='<U16')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Label Encoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder=LabelEncoder()\n",
        "y=to_categorical(labelencoder.fit_transform(y))"
      ],
      "metadata": {
        "id": "UOW5IzXJikIg"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6VrwQkCZxmr",
        "outputId": "9269a5fe-a086-4adb-e937-fc520821c805"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_coeff = pd.read_csv('X_values.csv')#feature coefficients uploaded seperately because of error in csv convertion\n"
      ],
      "metadata": {
        "id": "Qa-7q1qvp6Gh"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_coeff"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "XmMwP5btIEg0",
        "outputId": "0ed7dc39-d19d-4dac-f734-ca8feb048147"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0          0           1           2          3          4  \\\n",
              "0              0 -217.35526   70.223380 -130.385270 -53.282898 -21.199130   \n",
              "1              1 -424.09818  109.340770  -52.919525  60.864750   0.245292   \n",
              "2              2 -458.79114  121.384190  -46.520657  52.008120  -0.000384   \n",
              "3              3 -413.89984  101.663730  -35.429450  53.036354   1.520217   \n",
              "4              4 -446.60352  113.685410  -52.402206  60.302044   2.779428   \n",
              "...          ...        ...         ...         ...        ...        ...   \n",
              "8727        8727 -398.58450  135.534960  -50.725018  35.855907  -8.039597   \n",
              "8728        8728 -346.47420   86.348150  -45.168580  51.709873 -32.506092   \n",
              "8729        8729 -303.88824  111.359450  -45.941563  35.877018  -9.130412   \n",
              "8730        8730 -344.11008  125.450210  -54.903442  34.891148 -19.626827   \n",
              "8731        8731 -315.60280   94.854805  -37.222340  46.778263  -6.728693   \n",
              "\n",
              "              5          6          7          8  ...         30        31  \\\n",
              "0    -22.677622 -10.855970  18.294254   6.652703  ...   0.915979  6.970493   \n",
              "1     17.347328   2.095583  10.712965  -1.398613  ...  -1.031447  1.868079   \n",
              "2     23.783813   8.749806   9.052491  -0.636421  ...   0.984424 -1.243447   \n",
              "3     14.886695   2.878706   7.631294  -2.215483  ...  -5.103359  1.192205   \n",
              "4     25.073837   2.803380  10.143700   3.034920  ...  -2.638711 -1.249170   \n",
              "...         ...        ...        ...        ...  ...        ...       ...   \n",
              "8727  15.109999   7.619319  16.819832  -5.080297  ...  -8.461614  2.560358   \n",
              "8728  -4.313032  18.822187  -0.500065 -14.026640  ...   4.175921  2.989778   \n",
              "8729  12.614908   2.730064   9.983287  -7.045451  ...  -6.438552  0.037069   \n",
              "8730   7.352660  13.471235   9.143031  -8.673483  ...  -8.522343  2.401435   \n",
              "8731  10.012548  -1.607553  18.511341 -11.900620  ... -12.185813 -3.052291   \n",
              "\n",
              "            32        33        34        35        36        37         38  \\\n",
              "0    -0.248668  1.678219 -5.611182 -2.964347  3.149057 -1.693053  -0.616984   \n",
              "1    -0.960069  0.036977 -0.015435 -0.071756 -1.598885  0.534893  -0.544687   \n",
              "2    -4.046101 -2.161726 -1.494173 -1.784590 -1.424619  2.076848   1.696297   \n",
              "3     0.896591  0.998597 -2.278609  1.134796 -1.398987 -1.308791  -2.098211   \n",
              "4    -0.344982  1.779847 -2.061509  0.043404 -0.698911  2.079336   1.116136   \n",
              "...        ...       ...       ...       ...       ...       ...        ...   \n",
              "8727  4.204066  2.918537 -0.076288  1.535927 -4.409472 -7.080214  -2.464464   \n",
              "8728  0.199695  6.329091  4.560744  0.637593 -1.592893  2.627199  -2.163822   \n",
              "8729  4.099027  6.523638  3.317523  1.906624 -3.719005 -3.029238   2.717030   \n",
              "8730  5.968165  5.917666  1.596667  2.846004 -4.340133 -7.908244  -1.641459   \n",
              "8731  3.728414  8.962752  0.930645  3.180080  2.485049  0.613865 -11.449189   \n",
              "\n",
              "            39  \n",
              "0     0.386005  \n",
              "1     0.446321  \n",
              "2    -0.961410  \n",
              "3    -1.193339  \n",
              "4     0.043718  \n",
              "...        ...  \n",
              "8727  4.035294  \n",
              "8728 -2.886271  \n",
              "8729  7.619742  \n",
              "8730  5.666844  \n",
              "8731 -6.010585  \n",
              "\n",
              "[8732 rows x 41 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c18714e4-ccbb-4d09-a972-6024890b4d3f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-217.35526</td>\n",
              "      <td>70.223380</td>\n",
              "      <td>-130.385270</td>\n",
              "      <td>-53.282898</td>\n",
              "      <td>-21.199130</td>\n",
              "      <td>-22.677622</td>\n",
              "      <td>-10.855970</td>\n",
              "      <td>18.294254</td>\n",
              "      <td>6.652703</td>\n",
              "      <td>...</td>\n",
              "      <td>0.915979</td>\n",
              "      <td>6.970493</td>\n",
              "      <td>-0.248668</td>\n",
              "      <td>1.678219</td>\n",
              "      <td>-5.611182</td>\n",
              "      <td>-2.964347</td>\n",
              "      <td>3.149057</td>\n",
              "      <td>-1.693053</td>\n",
              "      <td>-0.616984</td>\n",
              "      <td>0.386005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>-424.09818</td>\n",
              "      <td>109.340770</td>\n",
              "      <td>-52.919525</td>\n",
              "      <td>60.864750</td>\n",
              "      <td>0.245292</td>\n",
              "      <td>17.347328</td>\n",
              "      <td>2.095583</td>\n",
              "      <td>10.712965</td>\n",
              "      <td>-1.398613</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.031447</td>\n",
              "      <td>1.868079</td>\n",
              "      <td>-0.960069</td>\n",
              "      <td>0.036977</td>\n",
              "      <td>-0.015435</td>\n",
              "      <td>-0.071756</td>\n",
              "      <td>-1.598885</td>\n",
              "      <td>0.534893</td>\n",
              "      <td>-0.544687</td>\n",
              "      <td>0.446321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>-458.79114</td>\n",
              "      <td>121.384190</td>\n",
              "      <td>-46.520657</td>\n",
              "      <td>52.008120</td>\n",
              "      <td>-0.000384</td>\n",
              "      <td>23.783813</td>\n",
              "      <td>8.749806</td>\n",
              "      <td>9.052491</td>\n",
              "      <td>-0.636421</td>\n",
              "      <td>...</td>\n",
              "      <td>0.984424</td>\n",
              "      <td>-1.243447</td>\n",
              "      <td>-4.046101</td>\n",
              "      <td>-2.161726</td>\n",
              "      <td>-1.494173</td>\n",
              "      <td>-1.784590</td>\n",
              "      <td>-1.424619</td>\n",
              "      <td>2.076848</td>\n",
              "      <td>1.696297</td>\n",
              "      <td>-0.961410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>-413.89984</td>\n",
              "      <td>101.663730</td>\n",
              "      <td>-35.429450</td>\n",
              "      <td>53.036354</td>\n",
              "      <td>1.520217</td>\n",
              "      <td>14.886695</td>\n",
              "      <td>2.878706</td>\n",
              "      <td>7.631294</td>\n",
              "      <td>-2.215483</td>\n",
              "      <td>...</td>\n",
              "      <td>-5.103359</td>\n",
              "      <td>1.192205</td>\n",
              "      <td>0.896591</td>\n",
              "      <td>0.998597</td>\n",
              "      <td>-2.278609</td>\n",
              "      <td>1.134796</td>\n",
              "      <td>-1.398987</td>\n",
              "      <td>-1.308791</td>\n",
              "      <td>-2.098211</td>\n",
              "      <td>-1.193339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>-446.60352</td>\n",
              "      <td>113.685410</td>\n",
              "      <td>-52.402206</td>\n",
              "      <td>60.302044</td>\n",
              "      <td>2.779428</td>\n",
              "      <td>25.073837</td>\n",
              "      <td>2.803380</td>\n",
              "      <td>10.143700</td>\n",
              "      <td>3.034920</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.638711</td>\n",
              "      <td>-1.249170</td>\n",
              "      <td>-0.344982</td>\n",
              "      <td>1.779847</td>\n",
              "      <td>-2.061509</td>\n",
              "      <td>0.043404</td>\n",
              "      <td>-0.698911</td>\n",
              "      <td>2.079336</td>\n",
              "      <td>1.116136</td>\n",
              "      <td>0.043718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8727</th>\n",
              "      <td>8727</td>\n",
              "      <td>-398.58450</td>\n",
              "      <td>135.534960</td>\n",
              "      <td>-50.725018</td>\n",
              "      <td>35.855907</td>\n",
              "      <td>-8.039597</td>\n",
              "      <td>15.109999</td>\n",
              "      <td>7.619319</td>\n",
              "      <td>16.819832</td>\n",
              "      <td>-5.080297</td>\n",
              "      <td>...</td>\n",
              "      <td>-8.461614</td>\n",
              "      <td>2.560358</td>\n",
              "      <td>4.204066</td>\n",
              "      <td>2.918537</td>\n",
              "      <td>-0.076288</td>\n",
              "      <td>1.535927</td>\n",
              "      <td>-4.409472</td>\n",
              "      <td>-7.080214</td>\n",
              "      <td>-2.464464</td>\n",
              "      <td>4.035294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8728</th>\n",
              "      <td>8728</td>\n",
              "      <td>-346.47420</td>\n",
              "      <td>86.348150</td>\n",
              "      <td>-45.168580</td>\n",
              "      <td>51.709873</td>\n",
              "      <td>-32.506092</td>\n",
              "      <td>-4.313032</td>\n",
              "      <td>18.822187</td>\n",
              "      <td>-0.500065</td>\n",
              "      <td>-14.026640</td>\n",
              "      <td>...</td>\n",
              "      <td>4.175921</td>\n",
              "      <td>2.989778</td>\n",
              "      <td>0.199695</td>\n",
              "      <td>6.329091</td>\n",
              "      <td>4.560744</td>\n",
              "      <td>0.637593</td>\n",
              "      <td>-1.592893</td>\n",
              "      <td>2.627199</td>\n",
              "      <td>-2.163822</td>\n",
              "      <td>-2.886271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8729</th>\n",
              "      <td>8729</td>\n",
              "      <td>-303.88824</td>\n",
              "      <td>111.359450</td>\n",
              "      <td>-45.941563</td>\n",
              "      <td>35.877018</td>\n",
              "      <td>-9.130412</td>\n",
              "      <td>12.614908</td>\n",
              "      <td>2.730064</td>\n",
              "      <td>9.983287</td>\n",
              "      <td>-7.045451</td>\n",
              "      <td>...</td>\n",
              "      <td>-6.438552</td>\n",
              "      <td>0.037069</td>\n",
              "      <td>4.099027</td>\n",
              "      <td>6.523638</td>\n",
              "      <td>3.317523</td>\n",
              "      <td>1.906624</td>\n",
              "      <td>-3.719005</td>\n",
              "      <td>-3.029238</td>\n",
              "      <td>2.717030</td>\n",
              "      <td>7.619742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8730</th>\n",
              "      <td>8730</td>\n",
              "      <td>-344.11008</td>\n",
              "      <td>125.450210</td>\n",
              "      <td>-54.903442</td>\n",
              "      <td>34.891148</td>\n",
              "      <td>-19.626827</td>\n",
              "      <td>7.352660</td>\n",
              "      <td>13.471235</td>\n",
              "      <td>9.143031</td>\n",
              "      <td>-8.673483</td>\n",
              "      <td>...</td>\n",
              "      <td>-8.522343</td>\n",
              "      <td>2.401435</td>\n",
              "      <td>5.968165</td>\n",
              "      <td>5.917666</td>\n",
              "      <td>1.596667</td>\n",
              "      <td>2.846004</td>\n",
              "      <td>-4.340133</td>\n",
              "      <td>-7.908244</td>\n",
              "      <td>-1.641459</td>\n",
              "      <td>5.666844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8731</th>\n",
              "      <td>8731</td>\n",
              "      <td>-315.60280</td>\n",
              "      <td>94.854805</td>\n",
              "      <td>-37.222340</td>\n",
              "      <td>46.778263</td>\n",
              "      <td>-6.728693</td>\n",
              "      <td>10.012548</td>\n",
              "      <td>-1.607553</td>\n",
              "      <td>18.511341</td>\n",
              "      <td>-11.900620</td>\n",
              "      <td>...</td>\n",
              "      <td>-12.185813</td>\n",
              "      <td>-3.052291</td>\n",
              "      <td>3.728414</td>\n",
              "      <td>8.962752</td>\n",
              "      <td>0.930645</td>\n",
              "      <td>3.180080</td>\n",
              "      <td>2.485049</td>\n",
              "      <td>0.613865</td>\n",
              "      <td>-11.449189</td>\n",
              "      <td>-6.010585</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8732 rows Ã— 41 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c18714e4-ccbb-4d09-a972-6024890b4d3f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c18714e4-ccbb-4d09-a972-6024890b4d3f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c18714e4-ccbb-4d09-a972-6024890b4d3f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_coeff.columns#an extra column is being formed so simply remove it"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDQaCf06qxnB",
        "outputId": "da3c8470-deca-4716-f2a6-047aca20f7d2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10',\n",
              "       '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22',\n",
              "       '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34',\n",
              "       '35', '36', '37', '38', '39'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_coeff=feature_coeff.drop(['Unnamed: 0'], axis=1)"
      ],
      "metadata": {
        "id": "AOzmK0woH-Fm"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_coeff"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "WWqtGoFWK940",
        "outputId": "80adedc2-ef30-4ce1-d4f5-c9e238ac76d3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              0           1           2          3          4          5  \\\n",
              "0    -217.35526   70.223380 -130.385270 -53.282898 -21.199130 -22.677622   \n",
              "1    -424.09818  109.340770  -52.919525  60.864750   0.245292  17.347328   \n",
              "2    -458.79114  121.384190  -46.520657  52.008120  -0.000384  23.783813   \n",
              "3    -413.89984  101.663730  -35.429450  53.036354   1.520217  14.886695   \n",
              "4    -446.60352  113.685410  -52.402206  60.302044   2.779428  25.073837   \n",
              "...         ...         ...         ...        ...        ...        ...   \n",
              "8727 -398.58450  135.534960  -50.725018  35.855907  -8.039597  15.109999   \n",
              "8728 -346.47420   86.348150  -45.168580  51.709873 -32.506092  -4.313032   \n",
              "8729 -303.88824  111.359450  -45.941563  35.877018  -9.130412  12.614908   \n",
              "8730 -344.11008  125.450210  -54.903442  34.891148 -19.626827   7.352660   \n",
              "8731 -315.60280   94.854805  -37.222340  46.778263  -6.728693  10.012548   \n",
              "\n",
              "              6          7          8          9  ...         30        31  \\\n",
              "0    -10.855970  18.294254   6.652703  14.324025  ...   0.915979  6.970493   \n",
              "1      2.095583  10.712965  -1.398613  12.310798  ...  -1.031447  1.868079   \n",
              "2      8.749806   9.052491  -0.636421  10.987134  ...   0.984424 -1.243447   \n",
              "3      2.878706   7.631294  -2.215483   9.920996  ...  -5.103359  1.192205   \n",
              "4      2.803380  10.143700   3.034920  10.420083  ...  -2.638711 -1.249170   \n",
              "...         ...        ...        ...        ...  ...        ...       ...   \n",
              "8727   7.619319  16.819832  -5.080297   3.601191  ...  -8.461614  2.560358   \n",
              "8728  18.822187  -0.500065 -14.026640  20.996353  ...   4.175921  2.989778   \n",
              "8729   2.730064   9.983287  -7.045451   5.537089  ...  -6.438552  0.037069   \n",
              "8730  13.471235   9.143031  -8.673483  18.334300  ...  -8.522343  2.401435   \n",
              "8731  -1.607553  18.511341 -11.900620   7.594036  ... -12.185813 -3.052291   \n",
              "\n",
              "            32        33        34        35        36        37         38  \\\n",
              "0    -0.248668  1.678219 -5.611182 -2.964347  3.149057 -1.693053  -0.616984   \n",
              "1    -0.960069  0.036977 -0.015435 -0.071756 -1.598885  0.534893  -0.544687   \n",
              "2    -4.046101 -2.161726 -1.494173 -1.784590 -1.424619  2.076848   1.696297   \n",
              "3     0.896591  0.998597 -2.278609  1.134796 -1.398987 -1.308791  -2.098211   \n",
              "4    -0.344982  1.779847 -2.061509  0.043404 -0.698911  2.079336   1.116136   \n",
              "...        ...       ...       ...       ...       ...       ...        ...   \n",
              "8727  4.204066  2.918537 -0.076288  1.535927 -4.409472 -7.080214  -2.464464   \n",
              "8728  0.199695  6.329091  4.560744  0.637593 -1.592893  2.627199  -2.163822   \n",
              "8729  4.099027  6.523638  3.317523  1.906624 -3.719005 -3.029238   2.717030   \n",
              "8730  5.968165  5.917666  1.596667  2.846004 -4.340133 -7.908244  -1.641459   \n",
              "8731  3.728414  8.962752  0.930645  3.180080  2.485049  0.613865 -11.449189   \n",
              "\n",
              "            39  \n",
              "0     0.386005  \n",
              "1     0.446321  \n",
              "2    -0.961410  \n",
              "3    -1.193339  \n",
              "4     0.043718  \n",
              "...        ...  \n",
              "8727  4.035294  \n",
              "8728 -2.886271  \n",
              "8729  7.619742  \n",
              "8730  5.666844  \n",
              "8731 -6.010585  \n",
              "\n",
              "[8732 rows x 40 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cc432fb2-0ec0-49f7-8a71-7949b32fe45e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-217.35526</td>\n",
              "      <td>70.223380</td>\n",
              "      <td>-130.385270</td>\n",
              "      <td>-53.282898</td>\n",
              "      <td>-21.199130</td>\n",
              "      <td>-22.677622</td>\n",
              "      <td>-10.855970</td>\n",
              "      <td>18.294254</td>\n",
              "      <td>6.652703</td>\n",
              "      <td>14.324025</td>\n",
              "      <td>...</td>\n",
              "      <td>0.915979</td>\n",
              "      <td>6.970493</td>\n",
              "      <td>-0.248668</td>\n",
              "      <td>1.678219</td>\n",
              "      <td>-5.611182</td>\n",
              "      <td>-2.964347</td>\n",
              "      <td>3.149057</td>\n",
              "      <td>-1.693053</td>\n",
              "      <td>-0.616984</td>\n",
              "      <td>0.386005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-424.09818</td>\n",
              "      <td>109.340770</td>\n",
              "      <td>-52.919525</td>\n",
              "      <td>60.864750</td>\n",
              "      <td>0.245292</td>\n",
              "      <td>17.347328</td>\n",
              "      <td>2.095583</td>\n",
              "      <td>10.712965</td>\n",
              "      <td>-1.398613</td>\n",
              "      <td>12.310798</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.031447</td>\n",
              "      <td>1.868079</td>\n",
              "      <td>-0.960069</td>\n",
              "      <td>0.036977</td>\n",
              "      <td>-0.015435</td>\n",
              "      <td>-0.071756</td>\n",
              "      <td>-1.598885</td>\n",
              "      <td>0.534893</td>\n",
              "      <td>-0.544687</td>\n",
              "      <td>0.446321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-458.79114</td>\n",
              "      <td>121.384190</td>\n",
              "      <td>-46.520657</td>\n",
              "      <td>52.008120</td>\n",
              "      <td>-0.000384</td>\n",
              "      <td>23.783813</td>\n",
              "      <td>8.749806</td>\n",
              "      <td>9.052491</td>\n",
              "      <td>-0.636421</td>\n",
              "      <td>10.987134</td>\n",
              "      <td>...</td>\n",
              "      <td>0.984424</td>\n",
              "      <td>-1.243447</td>\n",
              "      <td>-4.046101</td>\n",
              "      <td>-2.161726</td>\n",
              "      <td>-1.494173</td>\n",
              "      <td>-1.784590</td>\n",
              "      <td>-1.424619</td>\n",
              "      <td>2.076848</td>\n",
              "      <td>1.696297</td>\n",
              "      <td>-0.961410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-413.89984</td>\n",
              "      <td>101.663730</td>\n",
              "      <td>-35.429450</td>\n",
              "      <td>53.036354</td>\n",
              "      <td>1.520217</td>\n",
              "      <td>14.886695</td>\n",
              "      <td>2.878706</td>\n",
              "      <td>7.631294</td>\n",
              "      <td>-2.215483</td>\n",
              "      <td>9.920996</td>\n",
              "      <td>...</td>\n",
              "      <td>-5.103359</td>\n",
              "      <td>1.192205</td>\n",
              "      <td>0.896591</td>\n",
              "      <td>0.998597</td>\n",
              "      <td>-2.278609</td>\n",
              "      <td>1.134796</td>\n",
              "      <td>-1.398987</td>\n",
              "      <td>-1.308791</td>\n",
              "      <td>-2.098211</td>\n",
              "      <td>-1.193339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-446.60352</td>\n",
              "      <td>113.685410</td>\n",
              "      <td>-52.402206</td>\n",
              "      <td>60.302044</td>\n",
              "      <td>2.779428</td>\n",
              "      <td>25.073837</td>\n",
              "      <td>2.803380</td>\n",
              "      <td>10.143700</td>\n",
              "      <td>3.034920</td>\n",
              "      <td>10.420083</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.638711</td>\n",
              "      <td>-1.249170</td>\n",
              "      <td>-0.344982</td>\n",
              "      <td>1.779847</td>\n",
              "      <td>-2.061509</td>\n",
              "      <td>0.043404</td>\n",
              "      <td>-0.698911</td>\n",
              "      <td>2.079336</td>\n",
              "      <td>1.116136</td>\n",
              "      <td>0.043718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8727</th>\n",
              "      <td>-398.58450</td>\n",
              "      <td>135.534960</td>\n",
              "      <td>-50.725018</td>\n",
              "      <td>35.855907</td>\n",
              "      <td>-8.039597</td>\n",
              "      <td>15.109999</td>\n",
              "      <td>7.619319</td>\n",
              "      <td>16.819832</td>\n",
              "      <td>-5.080297</td>\n",
              "      <td>3.601191</td>\n",
              "      <td>...</td>\n",
              "      <td>-8.461614</td>\n",
              "      <td>2.560358</td>\n",
              "      <td>4.204066</td>\n",
              "      <td>2.918537</td>\n",
              "      <td>-0.076288</td>\n",
              "      <td>1.535927</td>\n",
              "      <td>-4.409472</td>\n",
              "      <td>-7.080214</td>\n",
              "      <td>-2.464464</td>\n",
              "      <td>4.035294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8728</th>\n",
              "      <td>-346.47420</td>\n",
              "      <td>86.348150</td>\n",
              "      <td>-45.168580</td>\n",
              "      <td>51.709873</td>\n",
              "      <td>-32.506092</td>\n",
              "      <td>-4.313032</td>\n",
              "      <td>18.822187</td>\n",
              "      <td>-0.500065</td>\n",
              "      <td>-14.026640</td>\n",
              "      <td>20.996353</td>\n",
              "      <td>...</td>\n",
              "      <td>4.175921</td>\n",
              "      <td>2.989778</td>\n",
              "      <td>0.199695</td>\n",
              "      <td>6.329091</td>\n",
              "      <td>4.560744</td>\n",
              "      <td>0.637593</td>\n",
              "      <td>-1.592893</td>\n",
              "      <td>2.627199</td>\n",
              "      <td>-2.163822</td>\n",
              "      <td>-2.886271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8729</th>\n",
              "      <td>-303.88824</td>\n",
              "      <td>111.359450</td>\n",
              "      <td>-45.941563</td>\n",
              "      <td>35.877018</td>\n",
              "      <td>-9.130412</td>\n",
              "      <td>12.614908</td>\n",
              "      <td>2.730064</td>\n",
              "      <td>9.983287</td>\n",
              "      <td>-7.045451</td>\n",
              "      <td>5.537089</td>\n",
              "      <td>...</td>\n",
              "      <td>-6.438552</td>\n",
              "      <td>0.037069</td>\n",
              "      <td>4.099027</td>\n",
              "      <td>6.523638</td>\n",
              "      <td>3.317523</td>\n",
              "      <td>1.906624</td>\n",
              "      <td>-3.719005</td>\n",
              "      <td>-3.029238</td>\n",
              "      <td>2.717030</td>\n",
              "      <td>7.619742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8730</th>\n",
              "      <td>-344.11008</td>\n",
              "      <td>125.450210</td>\n",
              "      <td>-54.903442</td>\n",
              "      <td>34.891148</td>\n",
              "      <td>-19.626827</td>\n",
              "      <td>7.352660</td>\n",
              "      <td>13.471235</td>\n",
              "      <td>9.143031</td>\n",
              "      <td>-8.673483</td>\n",
              "      <td>18.334300</td>\n",
              "      <td>...</td>\n",
              "      <td>-8.522343</td>\n",
              "      <td>2.401435</td>\n",
              "      <td>5.968165</td>\n",
              "      <td>5.917666</td>\n",
              "      <td>1.596667</td>\n",
              "      <td>2.846004</td>\n",
              "      <td>-4.340133</td>\n",
              "      <td>-7.908244</td>\n",
              "      <td>-1.641459</td>\n",
              "      <td>5.666844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8731</th>\n",
              "      <td>-315.60280</td>\n",
              "      <td>94.854805</td>\n",
              "      <td>-37.222340</td>\n",
              "      <td>46.778263</td>\n",
              "      <td>-6.728693</td>\n",
              "      <td>10.012548</td>\n",
              "      <td>-1.607553</td>\n",
              "      <td>18.511341</td>\n",
              "      <td>-11.900620</td>\n",
              "      <td>7.594036</td>\n",
              "      <td>...</td>\n",
              "      <td>-12.185813</td>\n",
              "      <td>-3.052291</td>\n",
              "      <td>3.728414</td>\n",
              "      <td>8.962752</td>\n",
              "      <td>0.930645</td>\n",
              "      <td>3.180080</td>\n",
              "      <td>2.485049</td>\n",
              "      <td>0.613865</td>\n",
              "      <td>-11.449189</td>\n",
              "      <td>-6.010585</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8732 rows Ã— 40 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc432fb2-0ec0-49f7-8a71-7949b32fe45e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cc432fb2-0ec0-49f7-8a71-7949b32fe45e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cc432fb2-0ec0-49f7-8a71-7949b32fe45e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "array = feature_coeff.to_numpy(dtype ='float32' )#converting featire_coeff to float"
      ],
      "metadata": {
        "id": "2_yiO5pXs_Cz"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwtoj414pFrS",
        "outputId": "a11771e3-9bc4-4a60-b88a-b6c8c96096bb"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-2.1735526e+02,  7.0223381e+01, -1.3038527e+02, ...,\n",
              "        -1.6930530e+00, -6.1698359e-01,  3.8600540e-01],\n",
              "       [-4.2409818e+02,  1.0934077e+02, -5.2919525e+01, ...,\n",
              "         5.3489321e-01, -5.4468733e-01,  4.4632089e-01],\n",
              "       [-4.5879114e+02,  1.2138419e+02, -4.6520657e+01, ...,\n",
              "         2.0768483e+00,  1.6962965e+00, -9.6140963e-01],\n",
              "       ...,\n",
              "       [-3.0388824e+02,  1.1135945e+02, -4.5941563e+01, ...,\n",
              "        -3.0292380e+00,  2.7170298e+00,  7.6197419e+00],\n",
              "       [-3.4411008e+02,  1.2545021e+02, -5.4903442e+01, ...,\n",
              "        -7.9082437e+00, -1.6414586e+00,  5.6668444e+00],\n",
              "       [-3.1560281e+02,  9.4854805e+01, -3.7222340e+01, ...,\n",
              "         6.1386454e-01, -1.1449189e+01, -6.0105853e+00]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "array.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDHSr960gwGy",
        "outputId": "fa9645d6-bda0-4783-cbd9-018d881ab40a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8732, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "array[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lcoL617ISvV",
        "outputId": "9f8a4a84-d7e6-4e89-82cc-bcf7671dcfb1"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-217.35526   ,   70.22338   , -130.38527   ,  -53.282898  ,\n",
              "        -21.19913   ,  -22.677622  ,  -10.85597   ,   18.294254  ,\n",
              "          6.652703  ,   14.324025  ,  -12.167682  ,    2.2768366 ,\n",
              "        -17.779188  ,   10.388951  ,   -6.5828357 ,   -0.69445676,\n",
              "        -18.336023  ,    1.9942534 ,   -5.143332  ,    8.3024    ,\n",
              "        -12.645056  ,   -6.529732  ,    4.6176677 ,   -2.1799166 ,\n",
              "         -6.6628237 ,    0.35971048,   -3.9084098 ,    4.7756243 ,\n",
              "         -6.384521  ,   -5.379818  ,    0.91597855,    6.9704933 ,\n",
              "         -0.248668  ,    1.6782187 ,   -5.6111817 ,   -2.9643466 ,\n",
              "          3.1490574 ,   -1.693053  ,   -0.6169836 ,    0.3860054 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=array"
      ],
      "metadata": {
        "id": "FMcOQiq2gxwH"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85e92R67QL2W",
        "outputId": "88c2e289-90a3-454c-d9ee-ad2f62f79123"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NOW WE HAVE FEATURE ARRAY IN X AND LABEL IN Y"
      ],
      "metadata": {
        "id": "-FNPTLVopLsM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "NOW WE CAN SPLIT OUR DATA INTO TRAINING AND TEST SET\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SHpQ3Ns4Qpib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Train Test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
      ],
      "metadata": {
        "id": "0hYGB89nQN_Q"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPFf7vB4QoqX",
        "outputId": "b9919753-fb6c-4e76-a415-83016980a3ef"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.31104706e+02,  1.12505905e+02, -2.25746956e+01, ...,\n",
              "         3.24665260e+00, -1.36902368e+00,  2.75575471e+00],\n",
              "       [-1.36703424e+01,  9.10850830e+01, -7.79273319e+00, ...,\n",
              "        -3.25305033e+00, -5.27745247e+00, -1.55697143e+00],\n",
              "       [-4.98715439e+01,  2.65352994e-01, -2.05009365e+01, ...,\n",
              "         2.85459447e+00, -1.60920465e+00,  3.52480578e+00],\n",
              "       ...,\n",
              "       [-4.27012360e+02,  9.26230469e+01,  3.12939739e+00, ...,\n",
              "         7.42641389e-01,  7.33490825e-01,  7.11009085e-01],\n",
              "       [-1.45754608e+02,  1.36265778e+02, -3.35155220e+01, ...,\n",
              "         1.46811950e+00, -2.00917006e+00, -8.82181883e-01],\n",
              "       [-4.21031342e+02,  2.10654541e+02,  3.49066067e+00, ...,\n",
              "        -5.38886690e+00, -3.37136054e+00, -1.56651139e+00]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGBlViJ9Q7V-",
        "outputId": "8f5058c7-fd71-4d53-8135-036b582d8be0"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6985, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1vsXUPLQ_8f",
        "outputId": "41b395de-c5f6-488d-aa25-835190519c71"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1747, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_u2eTKSRBpe",
        "outputId": "19a6d207-0cb5-4fc7-a928-bc23df169fee"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6985, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTxSDDlfRFuO",
        "outputId": "ae6fd3d2-bd95-445a-8afa-c76a524d8a19"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1747, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LETS GO, MODEL TIME"
      ],
      "metadata": {
        "id": "N_L0fz2Abaqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4IsL6mZRHdq",
        "outputId": "6a9bc45d-7a45-45da-bcd0-e91257769fff"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "TuChUGpWbtAf"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_labels=y.shape[1]#NO OF PROBABILITIES ,probability of the example to be of particular class"
      ],
      "metadata": {
        "id": "XELeSCn6bvTL"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DIFFERENT MODELS"
      ],
      "metadata": {
        "id": "UGm_Tizcc4UU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1=Sequential()\n",
        "###first layer\n",
        "model1.add(Dense(100,input_shape=(40,)))\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(Dropout(0.5))\n",
        "###second layer\n",
        "model1.add(Dense(200))\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(Dropout(0.5))\n",
        "###third layer\n",
        "model1.add(Dense(100))\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "###final layer\n",
        "model1.add(Dense(num_labels))\n",
        "model1.add(Activation('softmax'))"
      ],
      "metadata": {
        "id": "kMFmtCrSbw0Q"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2=Sequential()\n",
        "###first layer\n",
        "model2.add(Dense(100,input_shape=(40,)))\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Dropout(0.5))\n",
        "###second layer\n",
        "model2.add(Dense(200))\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Dropout(0.5))\n",
        "###third layer\n",
        "model2.add(Dense(100))\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Dropout(0.5))\n",
        "###fourth layer\n",
        "model2.add(Dense(50))\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Dropout(0.2))\n",
        "\n",
        "###final layer\n",
        "model2.add(Dense(num_labels))\n",
        "model2.add(Activation('softmax'))"
      ],
      "metadata": {
        "id": "zViTNQpncQ4C"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igMNxc8sbzP-",
        "outputId": "ead67e6f-37e7-442a-f7ea-555e58b3f5fe"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 100)               4100      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 100)               0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 100)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 200)               20200     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 200)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 200)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 100)               20100     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 100)               0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 45,410\n",
            "Trainable params: 45,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wmz3IErYcaPn",
        "outputId": "22016829-5012-44b3-d0e9-18d9c670f387"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 100)               4100      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 100)               0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 200)               20200     \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 200)               0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 200)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 100)               20100     \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 100)               0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 50)                5050      \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 50)                0         \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 50)                0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 10)                510       \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 49,960\n",
            "Trainable params: 49,960\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
      ],
      "metadata": {
        "id": "Sx_dPfDkb4oh"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
      ],
      "metadata": {
        "id": "bRjwedNZceHl"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAINING TIME"
      ],
      "metadata": {
        "id": "L9J_99prcBxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from datetime import datetime \n",
        "\n",
        "num_epochs = 400\n",
        "num_batch_size = 32\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='saved_models/audio_classification_model1.hdf5', \n",
        "                               verbose=1, save_best_only=True)\n",
        "start = datetime.now()\n",
        "\n",
        "model1.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n",
        "\n",
        "\n",
        "duration = datetime.now() - start\n",
        "print(\"Training completed in time: \", duration)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuNCAjjHci7T",
        "outputId": "86e34d94-b210-4aa5-a065-a6d024eadd4d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 10.0408 - accuracy: 0.1294\n",
            "Epoch 1: val_loss improved from inf to 2.27633, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 2s 4ms/step - loss: 9.9023 - accuracy: 0.1291 - val_loss: 2.2763 - val_accuracy: 0.1236\n",
            "Epoch 2/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 2.5206 - accuracy: 0.1402\n",
            "Epoch 2: val_loss improved from 2.27633 to 2.26140, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 2.5206 - accuracy: 0.1402 - val_loss: 2.2614 - val_accuracy: 0.1580\n",
            "Epoch 3/400\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 2.3074 - accuracy: 0.1492\n",
            "Epoch 3: val_loss improved from 2.26140 to 2.17248, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 2.3020 - accuracy: 0.1509 - val_loss: 2.1725 - val_accuracy: 0.1986\n",
            "Epoch 4/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 2.2172 - accuracy: 0.1772\n",
            "Epoch 4: val_loss improved from 2.17248 to 2.11961, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 2.2170 - accuracy: 0.1778 - val_loss: 2.1196 - val_accuracy: 0.1878\n",
            "Epoch 5/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 2.1569 - accuracy: 0.1986\n",
            "Epoch 5: val_loss improved from 2.11961 to 2.08283, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 2.1570 - accuracy: 0.1984 - val_loss: 2.0828 - val_accuracy: 0.2129\n",
            "Epoch 6/400\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 2.1063 - accuracy: 0.2166\n",
            "Epoch 6: val_loss improved from 2.08283 to 1.97818, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 2.1043 - accuracy: 0.2165 - val_loss: 1.9782 - val_accuracy: 0.3160\n",
            "Epoch 7/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 2.0680 - accuracy: 0.2193\n",
            "Epoch 7: val_loss improved from 1.97818 to 1.94997, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 2.0675 - accuracy: 0.2195 - val_loss: 1.9500 - val_accuracy: 0.2936\n",
            "Epoch 8/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 2.0274 - accuracy: 0.2332\n",
            "Epoch 8: val_loss improved from 1.94997 to 1.89949, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 2s 9ms/step - loss: 2.0269 - accuracy: 0.2334 - val_loss: 1.8995 - val_accuracy: 0.2999\n",
            "Epoch 9/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 2.0027 - accuracy: 0.2475\n",
            "Epoch 9: val_loss improved from 1.89949 to 1.86470, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 2.0027 - accuracy: 0.2475 - val_loss: 1.8647 - val_accuracy: 0.3017\n",
            "Epoch 10/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 1.9724 - accuracy: 0.2664\n",
            "Epoch 10: val_loss improved from 1.86470 to 1.82550, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 2s 8ms/step - loss: 1.9706 - accuracy: 0.2663 - val_loss: 1.8255 - val_accuracy: 0.3532\n",
            "Epoch 11/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 1.9283 - accuracy: 0.2900\n",
            "Epoch 11: val_loss improved from 1.82550 to 1.76175, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 2s 9ms/step - loss: 1.9301 - accuracy: 0.2892 - val_loss: 1.7618 - val_accuracy: 0.3835\n",
            "Epoch 12/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 1.8855 - accuracy: 0.3109\n",
            "Epoch 12: val_loss improved from 1.76175 to 1.71948, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 1.8834 - accuracy: 0.3114 - val_loss: 1.7195 - val_accuracy: 0.3950\n",
            "Epoch 13/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 1.8452 - accuracy: 0.3363\n",
            "Epoch 13: val_loss improved from 1.71948 to 1.64101, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.8449 - accuracy: 0.3361 - val_loss: 1.6410 - val_accuracy: 0.4264\n",
            "Epoch 14/400\n",
            "201/219 [==========================>...] - ETA: 0s - loss: 1.7850 - accuracy: 0.3605\n",
            "Epoch 14: val_loss improved from 1.64101 to 1.58523, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.7818 - accuracy: 0.3605 - val_loss: 1.5852 - val_accuracy: 0.4562\n",
            "Epoch 15/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 1.7395 - accuracy: 0.3679\n",
            "Epoch 15: val_loss improved from 1.58523 to 1.55684, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.7395 - accuracy: 0.3679 - val_loss: 1.5568 - val_accuracy: 0.4631\n",
            "Epoch 16/400\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 1.6819 - accuracy: 0.3904\n",
            "Epoch 16: val_loss improved from 1.55684 to 1.50669, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.6811 - accuracy: 0.3911 - val_loss: 1.5067 - val_accuracy: 0.4854\n",
            "Epoch 17/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 1.6454 - accuracy: 0.4118\n",
            "Epoch 17: val_loss improved from 1.50669 to 1.48204, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.6482 - accuracy: 0.4110 - val_loss: 1.4820 - val_accuracy: 0.4969\n",
            "Epoch 18/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 1.5982 - accuracy: 0.4375\n",
            "Epoch 18: val_loss improved from 1.48204 to 1.43830, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 1.5965 - accuracy: 0.4379 - val_loss: 1.4383 - val_accuracy: 0.5152\n",
            "Epoch 19/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 1.5574 - accuracy: 0.4670\n",
            "Epoch 19: val_loss improved from 1.43830 to 1.37506, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.5562 - accuracy: 0.4677 - val_loss: 1.3751 - val_accuracy: 0.5484\n",
            "Epoch 20/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 1.5539 - accuracy: 0.4601\n",
            "Epoch 20: val_loss improved from 1.37506 to 1.33040, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.5524 - accuracy: 0.4606 - val_loss: 1.3304 - val_accuracy: 0.5615\n",
            "Epoch 21/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 1.5133 - accuracy: 0.4732\n",
            "Epoch 21: val_loss improved from 1.33040 to 1.31181, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 1.5144 - accuracy: 0.4723 - val_loss: 1.3118 - val_accuracy: 0.5730\n",
            "Epoch 22/400\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 1.4683 - accuracy: 0.4862\n",
            "Epoch 22: val_loss improved from 1.31181 to 1.27081, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.4691 - accuracy: 0.4859 - val_loss: 1.2708 - val_accuracy: 0.5776\n",
            "Epoch 23/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 1.4600 - accuracy: 0.4965\n",
            "Epoch 23: val_loss improved from 1.27081 to 1.25606, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.4622 - accuracy: 0.4952 - val_loss: 1.2561 - val_accuracy: 0.5953\n",
            "Epoch 24/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 1.4457 - accuracy: 0.5070\n",
            "Epoch 24: val_loss improved from 1.25606 to 1.21390, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.4448 - accuracy: 0.5069 - val_loss: 1.2139 - val_accuracy: 0.6113\n",
            "Epoch 25/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 1.3989 - accuracy: 0.5244\n",
            "Epoch 25: val_loss did not improve from 1.21390\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3984 - accuracy: 0.5238 - val_loss: 1.2221 - val_accuracy: 0.5879\n",
            "Epoch 26/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 1.3886 - accuracy: 0.5216\n",
            "Epoch 26: val_loss improved from 1.21390 to 1.20117, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3892 - accuracy: 0.5221 - val_loss: 1.2012 - val_accuracy: 0.5970\n",
            "Epoch 27/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 1.3757 - accuracy: 0.5204\n",
            "Epoch 27: val_loss did not improve from 1.20117\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3749 - accuracy: 0.5207 - val_loss: 1.2020 - val_accuracy: 0.6045\n",
            "Epoch 28/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 1.3511 - accuracy: 0.5404\n",
            "Epoch 28: val_loss improved from 1.20117 to 1.15159, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3497 - accuracy: 0.5413 - val_loss: 1.1516 - val_accuracy: 0.6377\n",
            "Epoch 29/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 1.3321 - accuracy: 0.5463\n",
            "Epoch 29: val_loss improved from 1.15159 to 1.14391, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 2s 8ms/step - loss: 1.3321 - accuracy: 0.5463 - val_loss: 1.1439 - val_accuracy: 0.6377\n",
            "Epoch 30/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 1.3171 - accuracy: 0.5467\n",
            "Epoch 30: val_loss improved from 1.14391 to 1.11415, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 3s 12ms/step - loss: 1.3181 - accuracy: 0.5463 - val_loss: 1.1141 - val_accuracy: 0.6325\n",
            "Epoch 31/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 1.2944 - accuracy: 0.5557\n",
            "Epoch 31: val_loss improved from 1.11415 to 1.09583, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 1.2914 - accuracy: 0.5568 - val_loss: 1.0958 - val_accuracy: 0.6554\n",
            "Epoch 32/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 1.2818 - accuracy: 0.5677\n",
            "Epoch 32: val_loss did not improve from 1.09583\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2803 - accuracy: 0.5685 - val_loss: 1.1178 - val_accuracy: 0.6314\n",
            "Epoch 33/400\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 1.2762 - accuracy: 0.5728\n",
            "Epoch 33: val_loss improved from 1.09583 to 1.06706, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2818 - accuracy: 0.5722 - val_loss: 1.0671 - val_accuracy: 0.6600\n",
            "Epoch 34/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 1.2440 - accuracy: 0.5833\n",
            "Epoch 34: val_loss improved from 1.06706 to 1.06116, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 1.2398 - accuracy: 0.5838 - val_loss: 1.0612 - val_accuracy: 0.6583\n",
            "Epoch 35/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 1.2407 - accuracy: 0.5768\n",
            "Epoch 35: val_loss improved from 1.06116 to 1.02310, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.2392 - accuracy: 0.5772 - val_loss: 1.0231 - val_accuracy: 0.6646\n",
            "Epoch 36/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 1.2254 - accuracy: 0.5830\n",
            "Epoch 36: val_loss did not improve from 1.02310\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.2257 - accuracy: 0.5824 - val_loss: 1.0290 - val_accuracy: 0.6691\n",
            "Epoch 37/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 1.2242 - accuracy: 0.5937\n",
            "Epoch 37: val_loss did not improve from 1.02310\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2242 - accuracy: 0.5937 - val_loss: 1.0363 - val_accuracy: 0.6697\n",
            "Epoch 38/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 1.1909 - accuracy: 0.5891\n",
            "Epoch 38: val_loss improved from 1.02310 to 1.00222, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.1897 - accuracy: 0.5901 - val_loss: 1.0022 - val_accuracy: 0.6714\n",
            "Epoch 39/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 1.1934 - accuracy: 0.5925\n",
            "Epoch 39: val_loss improved from 1.00222 to 0.99443, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.1950 - accuracy: 0.5917 - val_loss: 0.9944 - val_accuracy: 0.6823\n",
            "Epoch 40/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 1.1752 - accuracy: 0.6066\n",
            "Epoch 40: val_loss improved from 0.99443 to 0.99252, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 2s 8ms/step - loss: 1.1763 - accuracy: 0.6062 - val_loss: 0.9925 - val_accuracy: 0.6749\n",
            "Epoch 41/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 1.1560 - accuracy: 0.6075\n",
            "Epoch 41: val_loss improved from 0.99252 to 0.96051, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 1.1559 - accuracy: 0.6069 - val_loss: 0.9605 - val_accuracy: 0.6863\n",
            "Epoch 42/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 1.1631 - accuracy: 0.6108\n",
            "Epoch 42: val_loss did not improve from 0.96051\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1635 - accuracy: 0.6106 - val_loss: 0.9642 - val_accuracy: 0.6835\n",
            "Epoch 43/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 1.1515 - accuracy: 0.6124\n",
            "Epoch 43: val_loss did not improve from 0.96051\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 1.1500 - accuracy: 0.6130 - val_loss: 0.9683 - val_accuracy: 0.6806\n",
            "Epoch 44/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 1.1404 - accuracy: 0.6140\n",
            "Epoch 44: val_loss improved from 0.96051 to 0.95891, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 1.1400 - accuracy: 0.6152 - val_loss: 0.9589 - val_accuracy: 0.6772\n",
            "Epoch 45/400\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 1.1252 - accuracy: 0.6186\n",
            "Epoch 45: val_loss improved from 0.95891 to 0.93168, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1243 - accuracy: 0.6192 - val_loss: 0.9317 - val_accuracy: 0.6961\n",
            "Epoch 46/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 1.1103 - accuracy: 0.6259\n",
            "Epoch 46: val_loss improved from 0.93168 to 0.92430, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1103 - accuracy: 0.6259 - val_loss: 0.9243 - val_accuracy: 0.6898\n",
            "Epoch 47/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 1.1088 - accuracy: 0.6299\n",
            "Epoch 47: val_loss improved from 0.92430 to 0.91605, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 1.1088 - accuracy: 0.6299 - val_loss: 0.9161 - val_accuracy: 0.6903\n",
            "Epoch 48/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 1.0806 - accuracy: 0.6369\n",
            "Epoch 48: val_loss did not improve from 0.91605\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.0798 - accuracy: 0.6369 - val_loss: 0.9234 - val_accuracy: 0.7018\n",
            "Epoch 49/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 1.1061 - accuracy: 0.6282\n",
            "Epoch 49: val_loss improved from 0.91605 to 0.90906, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 1.1061 - accuracy: 0.6282 - val_loss: 0.9091 - val_accuracy: 0.7069\n",
            "Epoch 50/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 1.0825 - accuracy: 0.6335\n",
            "Epoch 50: val_loss improved from 0.90906 to 0.88841, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.0817 - accuracy: 0.6342 - val_loss: 0.8884 - val_accuracy: 0.7086\n",
            "Epoch 51/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 1.0878 - accuracy: 0.6373\n",
            "Epoch 51: val_loss improved from 0.88841 to 0.88138, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.0892 - accuracy: 0.6358 - val_loss: 0.8814 - val_accuracy: 0.7132\n",
            "Epoch 52/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 1.0905 - accuracy: 0.6406\n",
            "Epoch 52: val_loss did not improve from 0.88138\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 1.0891 - accuracy: 0.6404 - val_loss: 0.9161 - val_accuracy: 0.6955\n",
            "Epoch 53/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 1.0684 - accuracy: 0.6400\n",
            "Epoch 53: val_loss improved from 0.88138 to 0.87665, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 2s 8ms/step - loss: 1.0680 - accuracy: 0.6404 - val_loss: 0.8766 - val_accuracy: 0.7207\n",
            "Epoch 54/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 1.0636 - accuracy: 0.6399\n",
            "Epoch 54: val_loss improved from 0.87665 to 0.87371, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 1.0638 - accuracy: 0.6409 - val_loss: 0.8737 - val_accuracy: 0.7161\n",
            "Epoch 55/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 1.0761 - accuracy: 0.6365\n",
            "Epoch 55: val_loss improved from 0.87371 to 0.86548, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.0742 - accuracy: 0.6369 - val_loss: 0.8655 - val_accuracy: 0.7155\n",
            "Epoch 56/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 1.0520 - accuracy: 0.6483\n",
            "Epoch 56: val_loss did not improve from 0.86548\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.0504 - accuracy: 0.6492 - val_loss: 0.8725 - val_accuracy: 0.7138\n",
            "Epoch 57/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 1.0571 - accuracy: 0.6459\n",
            "Epoch 57: val_loss improved from 0.86548 to 0.85035, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.0568 - accuracy: 0.6461 - val_loss: 0.8503 - val_accuracy: 0.7138\n",
            "Epoch 58/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 1.0247 - accuracy: 0.6521\n",
            "Epoch 58: val_loss did not improve from 0.85035\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.0246 - accuracy: 0.6517 - val_loss: 0.8646 - val_accuracy: 0.7104\n",
            "Epoch 59/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 1.0300 - accuracy: 0.6518\n",
            "Epoch 59: val_loss improved from 0.85035 to 0.83257, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.0285 - accuracy: 0.6524 - val_loss: 0.8326 - val_accuracy: 0.7275\n",
            "Epoch 60/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 1.0248 - accuracy: 0.6527\n",
            "Epoch 60: val_loss did not improve from 0.83257\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.0311 - accuracy: 0.6517 - val_loss: 0.8462 - val_accuracy: 0.7310\n",
            "Epoch 61/400\n",
            "201/219 [==========================>...] - ETA: 0s - loss: 1.0340 - accuracy: 0.6528\n",
            "Epoch 61: val_loss did not improve from 0.83257\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.0366 - accuracy: 0.6500 - val_loss: 0.8572 - val_accuracy: 0.7172\n",
            "Epoch 62/400\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 1.0405 - accuracy: 0.6482\n",
            "Epoch 62: val_loss improved from 0.83257 to 0.82241, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.0420 - accuracy: 0.6475 - val_loss: 0.8224 - val_accuracy: 0.7390\n",
            "Epoch 63/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 1.0100 - accuracy: 0.6507\n",
            "Epoch 63: val_loss improved from 0.82241 to 0.82177, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.0097 - accuracy: 0.6513 - val_loss: 0.8218 - val_accuracy: 0.7373\n",
            "Epoch 64/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 1.0146 - accuracy: 0.6567\n",
            "Epoch 64: val_loss improved from 0.82177 to 0.81185, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 1.0099 - accuracy: 0.6583 - val_loss: 0.8119 - val_accuracy: 0.7396\n",
            "Epoch 65/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.9906 - accuracy: 0.6641\n",
            "Epoch 65: val_loss improved from 0.81185 to 0.79948, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.9905 - accuracy: 0.6641 - val_loss: 0.7995 - val_accuracy: 0.7424\n",
            "Epoch 66/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 1.0001 - accuracy: 0.6587\n",
            "Epoch 66: val_loss did not improve from 0.79948\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.0024 - accuracy: 0.6571 - val_loss: 0.8168 - val_accuracy: 0.7281\n",
            "Epoch 67/400\n",
            "204/219 [==========================>...] - ETA: 0s - loss: 1.0098 - accuracy: 0.6651\n",
            "Epoch 67: val_loss did not improve from 0.79948\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.0149 - accuracy: 0.6626 - val_loss: 0.8158 - val_accuracy: 0.7447\n",
            "Epoch 68/400\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.9860 - accuracy: 0.6664\n",
            "Epoch 68: val_loss did not improve from 0.79948\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9874 - accuracy: 0.6654 - val_loss: 0.8036 - val_accuracy: 0.7481\n",
            "Epoch 69/400\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.9978 - accuracy: 0.6575\n",
            "Epoch 69: val_loss did not improve from 0.79948\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.9983 - accuracy: 0.6564 - val_loss: 0.8070 - val_accuracy: 0.7390\n",
            "Epoch 70/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.9943 - accuracy: 0.6577\n",
            "Epoch 70: val_loss improved from 0.79948 to 0.79813, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9969 - accuracy: 0.6568 - val_loss: 0.7981 - val_accuracy: 0.7418\n",
            "Epoch 71/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 1.0162 - accuracy: 0.6574\n",
            "Epoch 71: val_loss did not improve from 0.79813\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 1.0143 - accuracy: 0.6583 - val_loss: 0.8090 - val_accuracy: 0.7521\n",
            "Epoch 72/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 1.0088 - accuracy: 0.6580\n",
            "Epoch 72: val_loss did not improve from 0.79813\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.0098 - accuracy: 0.6577 - val_loss: 0.7992 - val_accuracy: 0.7424\n",
            "Epoch 73/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.9927 - accuracy: 0.6645\n",
            "Epoch 73: val_loss improved from 0.79813 to 0.79544, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9918 - accuracy: 0.6650 - val_loss: 0.7954 - val_accuracy: 0.7441\n",
            "Epoch 74/400\n",
            "201/219 [==========================>...] - ETA: 0s - loss: 0.9806 - accuracy: 0.6715\n",
            "Epoch 74: val_loss did not improve from 0.79544\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9872 - accuracy: 0.6707 - val_loss: 0.8090 - val_accuracy: 0.7499\n",
            "Epoch 75/400\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.9757 - accuracy: 0.6757\n",
            "Epoch 75: val_loss improved from 0.79544 to 0.78726, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9797 - accuracy: 0.6743 - val_loss: 0.7873 - val_accuracy: 0.7470\n",
            "Epoch 76/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.9861 - accuracy: 0.6644\n",
            "Epoch 76: val_loss did not improve from 0.78726\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9830 - accuracy: 0.6661 - val_loss: 0.7977 - val_accuracy: 0.7453\n",
            "Epoch 77/400\n",
            "202/219 [==========================>...] - ETA: 0s - loss: 0.9728 - accuracy: 0.6756\n",
            "Epoch 77: val_loss did not improve from 0.78726\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9793 - accuracy: 0.6722 - val_loss: 0.8001 - val_accuracy: 0.7355\n",
            "Epoch 78/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.9799 - accuracy: 0.6726\n",
            "Epoch 78: val_loss did not improve from 0.78726\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9799 - accuracy: 0.6726 - val_loss: 0.7884 - val_accuracy: 0.7476\n",
            "Epoch 79/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.9750 - accuracy: 0.6737\n",
            "Epoch 79: val_loss did not improve from 0.78726\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.9750 - accuracy: 0.6737 - val_loss: 0.7983 - val_accuracy: 0.7333\n",
            "Epoch 80/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.9697 - accuracy: 0.6750\n",
            "Epoch 80: val_loss improved from 0.78726 to 0.77217, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.9659 - accuracy: 0.6764 - val_loss: 0.7722 - val_accuracy: 0.7607\n",
            "Epoch 81/400\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 0.9522 - accuracy: 0.6806\n",
            "Epoch 81: val_loss improved from 0.77217 to 0.76677, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9574 - accuracy: 0.6795 - val_loss: 0.7668 - val_accuracy: 0.7556\n",
            "Epoch 82/400\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 0.9494 - accuracy: 0.6787\n",
            "Epoch 82: val_loss did not improve from 0.76677\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.9484 - accuracy: 0.6793 - val_loss: 0.8012 - val_accuracy: 0.7533\n",
            "Epoch 83/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.9747 - accuracy: 0.6666\n",
            "Epoch 83: val_loss did not improve from 0.76677\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9742 - accuracy: 0.6669 - val_loss: 0.7711 - val_accuracy: 0.7573\n",
            "Epoch 84/400\n",
            "202/219 [==========================>...] - ETA: 0s - loss: 0.9598 - accuracy: 0.6731\n",
            "Epoch 84: val_loss did not improve from 0.76677\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9636 - accuracy: 0.6723 - val_loss: 0.7747 - val_accuracy: 0.7733\n",
            "Epoch 85/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.9665 - accuracy: 0.6776\n",
            "Epoch 85: val_loss did not improve from 0.76677\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9665 - accuracy: 0.6776 - val_loss: 0.7764 - val_accuracy: 0.7607\n",
            "Epoch 86/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.9627 - accuracy: 0.6793\n",
            "Epoch 86: val_loss did not improve from 0.76677\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9670 - accuracy: 0.6797 - val_loss: 0.7719 - val_accuracy: 0.7527\n",
            "Epoch 87/400\n",
            "203/219 [==========================>...] - ETA: 0s - loss: 0.9437 - accuracy: 0.6809\n",
            "Epoch 87: val_loss did not improve from 0.76677\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9452 - accuracy: 0.6805 - val_loss: 0.7728 - val_accuracy: 0.7567\n",
            "Epoch 88/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.9587 - accuracy: 0.6763\n",
            "Epoch 88: val_loss did not improve from 0.76677\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9587 - accuracy: 0.6763 - val_loss: 0.7741 - val_accuracy: 0.7510\n",
            "Epoch 89/400\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 0.9680 - accuracy: 0.6767\n",
            "Epoch 89: val_loss improved from 0.76677 to 0.75398, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9571 - accuracy: 0.6805 - val_loss: 0.7540 - val_accuracy: 0.7710\n",
            "Epoch 90/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.9397 - accuracy: 0.6853\n",
            "Epoch 90: val_loss did not improve from 0.75398\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9416 - accuracy: 0.6852 - val_loss: 0.7662 - val_accuracy: 0.7504\n",
            "Epoch 91/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.9604 - accuracy: 0.6784\n",
            "Epoch 91: val_loss did not improve from 0.75398\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9635 - accuracy: 0.6772 - val_loss: 0.7629 - val_accuracy: 0.7481\n",
            "Epoch 92/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.9289 - accuracy: 0.6878\n",
            "Epoch 92: val_loss improved from 0.75398 to 0.73971, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9307 - accuracy: 0.6873 - val_loss: 0.7397 - val_accuracy: 0.7647\n",
            "Epoch 93/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.9597 - accuracy: 0.6783\n",
            "Epoch 93: val_loss did not improve from 0.73971\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.9597 - accuracy: 0.6786 - val_loss: 0.7585 - val_accuracy: 0.7550\n",
            "Epoch 94/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.9356 - accuracy: 0.6810\n",
            "Epoch 94: val_loss did not improve from 0.73971\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.9359 - accuracy: 0.6796 - val_loss: 0.7436 - val_accuracy: 0.7687\n",
            "Epoch 95/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.9297 - accuracy: 0.6922\n",
            "Epoch 95: val_loss did not improve from 0.73971\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9323 - accuracy: 0.6918 - val_loss: 0.7528 - val_accuracy: 0.7630\n",
            "Epoch 96/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.9476 - accuracy: 0.6816\n",
            "Epoch 96: val_loss improved from 0.73971 to 0.73286, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9456 - accuracy: 0.6820 - val_loss: 0.7329 - val_accuracy: 0.7750\n",
            "Epoch 97/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.9394 - accuracy: 0.6936\n",
            "Epoch 97: val_loss did not improve from 0.73286\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9359 - accuracy: 0.6948 - val_loss: 0.7527 - val_accuracy: 0.7613\n",
            "Epoch 98/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.9276 - accuracy: 0.6874\n",
            "Epoch 98: val_loss did not improve from 0.73286\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9236 - accuracy: 0.6895 - val_loss: 0.7350 - val_accuracy: 0.7670\n",
            "Epoch 99/400\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.9277 - accuracy: 0.6967\n",
            "Epoch 99: val_loss did not improve from 0.73286\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.9226 - accuracy: 0.6982 - val_loss: 0.7352 - val_accuracy: 0.7590\n",
            "Epoch 100/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.9105 - accuracy: 0.6940\n",
            "Epoch 100: val_loss did not improve from 0.73286\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9085 - accuracy: 0.6949 - val_loss: 0.7335 - val_accuracy: 0.7699\n",
            "Epoch 101/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.9182 - accuracy: 0.6939\n",
            "Epoch 101: val_loss did not improve from 0.73286\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.9177 - accuracy: 0.6939 - val_loss: 0.7443 - val_accuracy: 0.7687\n",
            "Epoch 102/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.9401 - accuracy: 0.6868\n",
            "Epoch 102: val_loss did not improve from 0.73286\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.9416 - accuracy: 0.6869 - val_loss: 0.7469 - val_accuracy: 0.7710\n",
            "Epoch 103/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.9318 - accuracy: 0.6848\n",
            "Epoch 103: val_loss did not improve from 0.73286\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9316 - accuracy: 0.6853 - val_loss: 0.7528 - val_accuracy: 0.7584\n",
            "Epoch 104/400\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 0.9047 - accuracy: 0.6867\n",
            "Epoch 104: val_loss did not improve from 0.73286\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9132 - accuracy: 0.6860 - val_loss: 0.7743 - val_accuracy: 0.7510\n",
            "Epoch 105/400\n",
            "201/219 [==========================>...] - ETA: 0s - loss: 0.9192 - accuracy: 0.6883\n",
            "Epoch 105: val_loss did not improve from 0.73286\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.9217 - accuracy: 0.6859 - val_loss: 0.7390 - val_accuracy: 0.7682\n",
            "Epoch 106/400\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.9567 - accuracy: 0.6803\n",
            "Epoch 106: val_loss did not improve from 0.73286\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.9530 - accuracy: 0.6815 - val_loss: 0.7620 - val_accuracy: 0.7550\n",
            "Epoch 107/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.9048 - accuracy: 0.6992\n",
            "Epoch 107: val_loss did not improve from 0.73286\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9045 - accuracy: 0.6985 - val_loss: 0.7355 - val_accuracy: 0.7596\n",
            "Epoch 108/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.9169 - accuracy: 0.6957\n",
            "Epoch 108: val_loss improved from 0.73286 to 0.72385, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.9165 - accuracy: 0.6958 - val_loss: 0.7238 - val_accuracy: 0.7716\n",
            "Epoch 109/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.9206 - accuracy: 0.6955\n",
            "Epoch 109: val_loss improved from 0.72385 to 0.71824, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.9206 - accuracy: 0.6955 - val_loss: 0.7182 - val_accuracy: 0.7825\n",
            "Epoch 110/400\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 0.9339 - accuracy: 0.6855\n",
            "Epoch 110: val_loss did not improve from 0.71824\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9301 - accuracy: 0.6862 - val_loss: 0.7313 - val_accuracy: 0.7693\n",
            "Epoch 111/400\n",
            "204/219 [==========================>...] - ETA: 0s - loss: 0.9045 - accuracy: 0.6985\n",
            "Epoch 111: val_loss did not improve from 0.71824\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9113 - accuracy: 0.6969 - val_loss: 0.7328 - val_accuracy: 0.7693\n",
            "Epoch 112/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.9122 - accuracy: 0.6943\n",
            "Epoch 112: val_loss did not improve from 0.71824\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9090 - accuracy: 0.6952 - val_loss: 0.7362 - val_accuracy: 0.7779\n",
            "Epoch 113/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.9133 - accuracy: 0.6860\n",
            "Epoch 113: val_loss did not improve from 0.71824\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9159 - accuracy: 0.6862 - val_loss: 0.7341 - val_accuracy: 0.7682\n",
            "Epoch 114/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.9196 - accuracy: 0.6884\n",
            "Epoch 114: val_loss improved from 0.71824 to 0.71398, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9192 - accuracy: 0.6886 - val_loss: 0.7140 - val_accuracy: 0.7825\n",
            "Epoch 115/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.8885 - accuracy: 0.7044\n",
            "Epoch 115: val_loss did not improve from 0.71398\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8896 - accuracy: 0.7041 - val_loss: 0.7245 - val_accuracy: 0.7733\n",
            "Epoch 116/400\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.8998 - accuracy: 0.7028\n",
            "Epoch 116: val_loss did not improve from 0.71398\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9022 - accuracy: 0.7024 - val_loss: 0.7426 - val_accuracy: 0.7676\n",
            "Epoch 117/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.9241 - accuracy: 0.6965\n",
            "Epoch 117: val_loss improved from 0.71398 to 0.71330, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9213 - accuracy: 0.6971 - val_loss: 0.7133 - val_accuracy: 0.7785\n",
            "Epoch 118/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.8970 - accuracy: 0.7026\n",
            "Epoch 118: val_loss did not improve from 0.71330\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8989 - accuracy: 0.7026 - val_loss: 0.7258 - val_accuracy: 0.7779\n",
            "Epoch 119/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.9028 - accuracy: 0.6959\n",
            "Epoch 119: val_loss did not improve from 0.71330\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9058 - accuracy: 0.6942 - val_loss: 0.7391 - val_accuracy: 0.7665\n",
            "Epoch 120/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.9044 - accuracy: 0.6956\n",
            "Epoch 120: val_loss did not improve from 0.71330\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9036 - accuracy: 0.6961 - val_loss: 0.7403 - val_accuracy: 0.7670\n",
            "Epoch 121/400\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.8999 - accuracy: 0.6914\n",
            "Epoch 121: val_loss improved from 0.71330 to 0.70863, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8964 - accuracy: 0.6906 - val_loss: 0.7086 - val_accuracy: 0.7790\n",
            "Epoch 122/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.8812 - accuracy: 0.6989\n",
            "Epoch 122: val_loss did not improve from 0.70863\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8827 - accuracy: 0.6986 - val_loss: 0.7130 - val_accuracy: 0.7825\n",
            "Epoch 123/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.8975 - accuracy: 0.6940\n",
            "Epoch 123: val_loss did not improve from 0.70863\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8991 - accuracy: 0.6928 - val_loss: 0.7407 - val_accuracy: 0.7710\n",
            "Epoch 124/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.9018 - accuracy: 0.6953\n",
            "Epoch 124: val_loss did not improve from 0.70863\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.9018 - accuracy: 0.6953 - val_loss: 0.7232 - val_accuracy: 0.7779\n",
            "Epoch 125/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.9044 - accuracy: 0.6956\n",
            "Epoch 125: val_loss did not improve from 0.70863\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9035 - accuracy: 0.6959 - val_loss: 0.7281 - val_accuracy: 0.7779\n",
            "Epoch 126/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.9207 - accuracy: 0.6918\n",
            "Epoch 126: val_loss did not improve from 0.70863\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9234 - accuracy: 0.6902 - val_loss: 0.7420 - val_accuracy: 0.7613\n",
            "Epoch 127/400\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.9088 - accuracy: 0.7034\n",
            "Epoch 127: val_loss improved from 0.70863 to 0.70789, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9035 - accuracy: 0.7039 - val_loss: 0.7079 - val_accuracy: 0.7813\n",
            "Epoch 128/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.8841 - accuracy: 0.7037\n",
            "Epoch 128: val_loss improved from 0.70789 to 0.70655, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8835 - accuracy: 0.7028 - val_loss: 0.7065 - val_accuracy: 0.7762\n",
            "Epoch 129/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.9024 - accuracy: 0.7013\n",
            "Epoch 129: val_loss did not improve from 0.70655\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9020 - accuracy: 0.7012 - val_loss: 0.7182 - val_accuracy: 0.7670\n",
            "Epoch 130/400\n",
            "203/219 [==========================>...] - ETA: 0s - loss: 0.8906 - accuracy: 0.7024\n",
            "Epoch 130: val_loss did not improve from 0.70655\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8919 - accuracy: 0.7025 - val_loss: 0.7075 - val_accuracy: 0.7779\n",
            "Epoch 131/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.8708 - accuracy: 0.7027\n",
            "Epoch 131: val_loss improved from 0.70655 to 0.69780, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8657 - accuracy: 0.7044 - val_loss: 0.6978 - val_accuracy: 0.7842\n",
            "Epoch 132/400\n",
            "202/219 [==========================>...] - ETA: 0s - loss: 0.9114 - accuracy: 0.6957\n",
            "Epoch 132: val_loss did not improve from 0.69780\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9028 - accuracy: 0.6986 - val_loss: 0.7098 - val_accuracy: 0.7796\n",
            "Epoch 133/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.9189 - accuracy: 0.6907\n",
            "Epoch 133: val_loss did not improve from 0.69780\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9164 - accuracy: 0.6921 - val_loss: 0.7128 - val_accuracy: 0.7842\n",
            "Epoch 134/400\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.8799 - accuracy: 0.7050\n",
            "Epoch 134: val_loss improved from 0.69780 to 0.68626, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8797 - accuracy: 0.7054 - val_loss: 0.6863 - val_accuracy: 0.7894\n",
            "Epoch 135/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.8762 - accuracy: 0.7054\n",
            "Epoch 135: val_loss did not improve from 0.68626\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8762 - accuracy: 0.7054 - val_loss: 0.6989 - val_accuracy: 0.7762\n",
            "Epoch 136/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.8735 - accuracy: 0.7061\n",
            "Epoch 136: val_loss improved from 0.68626 to 0.68481, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8762 - accuracy: 0.7055 - val_loss: 0.6848 - val_accuracy: 0.7842\n",
            "Epoch 137/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.8913 - accuracy: 0.7004\n",
            "Epoch 137: val_loss did not improve from 0.68481\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8892 - accuracy: 0.7006 - val_loss: 0.6993 - val_accuracy: 0.7848\n",
            "Epoch 138/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.8838 - accuracy: 0.7088\n",
            "Epoch 138: val_loss did not improve from 0.68481\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8852 - accuracy: 0.7069 - val_loss: 0.7113 - val_accuracy: 0.7836\n",
            "Epoch 139/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.8993 - accuracy: 0.6997\n",
            "Epoch 139: val_loss improved from 0.68481 to 0.67669, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8983 - accuracy: 0.7001 - val_loss: 0.6767 - val_accuracy: 0.7928\n",
            "Epoch 140/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.8711 - accuracy: 0.7080\n",
            "Epoch 140: val_loss improved from 0.67669 to 0.67653, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8740 - accuracy: 0.7065 - val_loss: 0.6765 - val_accuracy: 0.7871\n",
            "Epoch 141/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.8828 - accuracy: 0.7117\n",
            "Epoch 141: val_loss did not improve from 0.67653\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8833 - accuracy: 0.7112 - val_loss: 0.6997 - val_accuracy: 0.7745\n",
            "Epoch 142/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.8596 - accuracy: 0.7137\n",
            "Epoch 142: val_loss did not improve from 0.67653\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8637 - accuracy: 0.7118 - val_loss: 0.7123 - val_accuracy: 0.7779\n",
            "Epoch 143/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.8764 - accuracy: 0.7055\n",
            "Epoch 143: val_loss improved from 0.67653 to 0.67642, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8756 - accuracy: 0.7047 - val_loss: 0.6764 - val_accuracy: 0.7831\n",
            "Epoch 144/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.8579 - accuracy: 0.7112\n",
            "Epoch 144: val_loss did not improve from 0.67642\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8574 - accuracy: 0.7117 - val_loss: 0.6818 - val_accuracy: 0.7859\n",
            "Epoch 145/400\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.8957 - accuracy: 0.6987\n",
            "Epoch 145: val_loss did not improve from 0.67642\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8972 - accuracy: 0.6991 - val_loss: 0.7046 - val_accuracy: 0.7802\n",
            "Epoch 146/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8620 - accuracy: 0.7114\n",
            "Epoch 146: val_loss did not improve from 0.67642\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8616 - accuracy: 0.7114 - val_loss: 0.6788 - val_accuracy: 0.7922\n",
            "Epoch 147/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.8877 - accuracy: 0.7047\n",
            "Epoch 147: val_loss improved from 0.67642 to 0.66597, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8940 - accuracy: 0.7044 - val_loss: 0.6660 - val_accuracy: 0.7859\n",
            "Epoch 148/400\n",
            "202/219 [==========================>...] - ETA: 0s - loss: 0.8749 - accuracy: 0.7112\n",
            "Epoch 148: val_loss did not improve from 0.66597\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8821 - accuracy: 0.7101 - val_loss: 0.6770 - val_accuracy: 0.7962\n",
            "Epoch 149/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.8702 - accuracy: 0.7112\n",
            "Epoch 149: val_loss did not improve from 0.66597\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8734 - accuracy: 0.7102 - val_loss: 0.6854 - val_accuracy: 0.7905\n",
            "Epoch 150/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.8782 - accuracy: 0.7088\n",
            "Epoch 150: val_loss did not improve from 0.66597\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8767 - accuracy: 0.7082 - val_loss: 0.6825 - val_accuracy: 0.7911\n",
            "Epoch 151/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.8679 - accuracy: 0.7049\n",
            "Epoch 151: val_loss did not improve from 0.66597\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8639 - accuracy: 0.7065 - val_loss: 0.6940 - val_accuracy: 0.7750\n",
            "Epoch 152/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.8609 - accuracy: 0.7104\n",
            "Epoch 152: val_loss did not improve from 0.66597\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8635 - accuracy: 0.7097 - val_loss: 0.6943 - val_accuracy: 0.7665\n",
            "Epoch 153/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.8626 - accuracy: 0.7085\n",
            "Epoch 153: val_loss did not improve from 0.66597\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8595 - accuracy: 0.7099 - val_loss: 0.6788 - val_accuracy: 0.7790\n",
            "Epoch 154/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.8583 - accuracy: 0.7155\n",
            "Epoch 154: val_loss did not improve from 0.66597\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8583 - accuracy: 0.7155 - val_loss: 0.6662 - val_accuracy: 0.8071\n",
            "Epoch 155/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.8593 - accuracy: 0.7140\n",
            "Epoch 155: val_loss did not improve from 0.66597\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8657 - accuracy: 0.7137 - val_loss: 0.6813 - val_accuracy: 0.7945\n",
            "Epoch 156/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.8639 - accuracy: 0.7134\n",
            "Epoch 156: val_loss did not improve from 0.66597\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8685 - accuracy: 0.7124 - val_loss: 0.6807 - val_accuracy: 0.7905\n",
            "Epoch 157/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.8534 - accuracy: 0.7172\n",
            "Epoch 157: val_loss did not improve from 0.66597\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8542 - accuracy: 0.7174 - val_loss: 0.6848 - val_accuracy: 0.7848\n",
            "Epoch 158/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.8879 - accuracy: 0.7029\n",
            "Epoch 158: val_loss did not improve from 0.66597\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8872 - accuracy: 0.7025 - val_loss: 0.6787 - val_accuracy: 0.7848\n",
            "Epoch 159/400\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.8640 - accuracy: 0.7082\n",
            "Epoch 159: val_loss did not improve from 0.66597\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8600 - accuracy: 0.7089 - val_loss: 0.6945 - val_accuracy: 0.7796\n",
            "Epoch 160/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8734 - accuracy: 0.7031\n",
            "Epoch 160: val_loss did not improve from 0.66597\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8734 - accuracy: 0.7031 - val_loss: 0.6847 - val_accuracy: 0.7905\n",
            "Epoch 161/400\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.8785 - accuracy: 0.7051\n",
            "Epoch 161: val_loss did not improve from 0.66597\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8792 - accuracy: 0.7059 - val_loss: 0.6843 - val_accuracy: 0.7951\n",
            "Epoch 162/400\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 0.8623 - accuracy: 0.7067\n",
            "Epoch 162: val_loss did not improve from 0.66597\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8593 - accuracy: 0.7074 - val_loss: 0.6685 - val_accuracy: 0.7853\n",
            "Epoch 163/400\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.8475 - accuracy: 0.7165\n",
            "Epoch 163: val_loss did not improve from 0.66597\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8486 - accuracy: 0.7154 - val_loss: 0.6673 - val_accuracy: 0.7916\n",
            "Epoch 164/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.8560 - accuracy: 0.7151\n",
            "Epoch 164: val_loss did not improve from 0.66597\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8560 - accuracy: 0.7151 - val_loss: 0.6704 - val_accuracy: 0.7974\n",
            "Epoch 165/400\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.8489 - accuracy: 0.7169\n",
            "Epoch 165: val_loss did not improve from 0.66597\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.8447 - accuracy: 0.7193 - val_loss: 0.6847 - val_accuracy: 0.7802\n",
            "Epoch 166/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8457 - accuracy: 0.7206\n",
            "Epoch 166: val_loss did not improve from 0.66597\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8453 - accuracy: 0.7207 - val_loss: 0.6868 - val_accuracy: 0.7836\n",
            "Epoch 167/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.8560 - accuracy: 0.7120\n",
            "Epoch 167: val_loss did not improve from 0.66597\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8535 - accuracy: 0.7125 - val_loss: 0.6709 - val_accuracy: 0.7865\n",
            "Epoch 168/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.8627 - accuracy: 0.7117\n",
            "Epoch 168: val_loss did not improve from 0.66597\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8609 - accuracy: 0.7122 - val_loss: 0.6932 - val_accuracy: 0.7842\n",
            "Epoch 169/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.8648 - accuracy: 0.7107\n",
            "Epoch 169: val_loss improved from 0.66597 to 0.64898, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8644 - accuracy: 0.7107 - val_loss: 0.6490 - val_accuracy: 0.8048\n",
            "Epoch 170/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.8356 - accuracy: 0.7158\n",
            "Epoch 170: val_loss did not improve from 0.64898\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8354 - accuracy: 0.7151 - val_loss: 0.6524 - val_accuracy: 0.7968\n",
            "Epoch 171/400\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.8634 - accuracy: 0.7105\n",
            "Epoch 171: val_loss did not improve from 0.64898\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8588 - accuracy: 0.7115 - val_loss: 0.6608 - val_accuracy: 0.7842\n",
            "Epoch 172/400\n",
            "204/219 [==========================>...] - ETA: 0s - loss: 0.8318 - accuracy: 0.7183\n",
            "Epoch 172: val_loss improved from 0.64898 to 0.64237, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8300 - accuracy: 0.7193 - val_loss: 0.6424 - val_accuracy: 0.8048\n",
            "Epoch 173/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.8461 - accuracy: 0.7133\n",
            "Epoch 173: val_loss did not improve from 0.64237\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8470 - accuracy: 0.7128 - val_loss: 0.6586 - val_accuracy: 0.7997\n",
            "Epoch 174/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.8461 - accuracy: 0.7192\n",
            "Epoch 174: val_loss did not improve from 0.64237\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8498 - accuracy: 0.7183 - val_loss: 0.6827 - val_accuracy: 0.7876\n",
            "Epoch 175/400\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.8447 - accuracy: 0.7165\n",
            "Epoch 175: val_loss did not improve from 0.64237\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8478 - accuracy: 0.7157 - val_loss: 0.6615 - val_accuracy: 0.8014\n",
            "Epoch 176/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8452 - accuracy: 0.7222\n",
            "Epoch 176: val_loss did not improve from 0.64237\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8453 - accuracy: 0.7221 - val_loss: 0.6561 - val_accuracy: 0.7991\n",
            "Epoch 177/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.8486 - accuracy: 0.7217\n",
            "Epoch 177: val_loss did not improve from 0.64237\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8477 - accuracy: 0.7218 - val_loss: 0.6585 - val_accuracy: 0.7985\n",
            "Epoch 178/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.8538 - accuracy: 0.7105\n",
            "Epoch 178: val_loss did not improve from 0.64237\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8512 - accuracy: 0.7108 - val_loss: 0.6544 - val_accuracy: 0.7997\n",
            "Epoch 179/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.8484 - accuracy: 0.7183\n",
            "Epoch 179: val_loss did not improve from 0.64237\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8538 - accuracy: 0.7160 - val_loss: 0.6689 - val_accuracy: 0.7991\n",
            "Epoch 180/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.8315 - accuracy: 0.7192\n",
            "Epoch 180: val_loss did not improve from 0.64237\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8289 - accuracy: 0.7193 - val_loss: 0.6595 - val_accuracy: 0.7939\n",
            "Epoch 181/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.8526 - accuracy: 0.7142\n",
            "Epoch 181: val_loss did not improve from 0.64237\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8493 - accuracy: 0.7148 - val_loss: 0.6544 - val_accuracy: 0.7991\n",
            "Epoch 182/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.8271 - accuracy: 0.7193\n",
            "Epoch 182: val_loss did not improve from 0.64237\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8271 - accuracy: 0.7193 - val_loss: 0.6487 - val_accuracy: 0.8014\n",
            "Epoch 183/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.8691 - accuracy: 0.7058\n",
            "Epoch 183: val_loss did not improve from 0.64237\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8691 - accuracy: 0.7058 - val_loss: 0.6572 - val_accuracy: 0.7951\n",
            "Epoch 184/400\n",
            "203/219 [==========================>...] - ETA: 0s - loss: 0.8237 - accuracy: 0.7229\n",
            "Epoch 184: val_loss improved from 0.64237 to 0.64138, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8276 - accuracy: 0.7198 - val_loss: 0.6414 - val_accuracy: 0.7962\n",
            "Epoch 185/400\n",
            "203/219 [==========================>...] - ETA: 0s - loss: 0.8343 - accuracy: 0.7289\n",
            "Epoch 185: val_loss did not improve from 0.64138\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8397 - accuracy: 0.7278 - val_loss: 0.6649 - val_accuracy: 0.7979\n",
            "Epoch 186/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8368 - accuracy: 0.7183\n",
            "Epoch 186: val_loss improved from 0.64138 to 0.64020, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8372 - accuracy: 0.7181 - val_loss: 0.6402 - val_accuracy: 0.8100\n",
            "Epoch 187/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.8407 - accuracy: 0.7117\n",
            "Epoch 187: val_loss did not improve from 0.64020\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8385 - accuracy: 0.7124 - val_loss: 0.6581 - val_accuracy: 0.8031\n",
            "Epoch 188/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.8587 - accuracy: 0.7164\n",
            "Epoch 188: val_loss did not improve from 0.64020\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8586 - accuracy: 0.7167 - val_loss: 0.6730 - val_accuracy: 0.7939\n",
            "Epoch 189/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.8438 - accuracy: 0.7151\n",
            "Epoch 189: val_loss did not improve from 0.64020\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8395 - accuracy: 0.7162 - val_loss: 0.6624 - val_accuracy: 0.7911\n",
            "Epoch 190/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.8409 - accuracy: 0.7174\n",
            "Epoch 190: val_loss did not improve from 0.64020\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8409 - accuracy: 0.7174 - val_loss: 0.6534 - val_accuracy: 0.8042\n",
            "Epoch 191/400\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.8311 - accuracy: 0.7272\n",
            "Epoch 191: val_loss did not improve from 0.64020\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8297 - accuracy: 0.7266 - val_loss: 0.6445 - val_accuracy: 0.8100\n",
            "Epoch 192/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.8499 - accuracy: 0.7250\n",
            "Epoch 192: val_loss did not improve from 0.64020\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8487 - accuracy: 0.7251 - val_loss: 0.6456 - val_accuracy: 0.8082\n",
            "Epoch 193/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.8230 - accuracy: 0.7277\n",
            "Epoch 193: val_loss did not improve from 0.64020\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8263 - accuracy: 0.7270 - val_loss: 0.6592 - val_accuracy: 0.7985\n",
            "Epoch 194/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.8484 - accuracy: 0.7136\n",
            "Epoch 194: val_loss did not improve from 0.64020\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8456 - accuracy: 0.7141 - val_loss: 0.6597 - val_accuracy: 0.7991\n",
            "Epoch 195/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.8422 - accuracy: 0.7224\n",
            "Epoch 195: val_loss improved from 0.64020 to 0.64011, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8429 - accuracy: 0.7220 - val_loss: 0.6401 - val_accuracy: 0.8082\n",
            "Epoch 196/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.8613 - accuracy: 0.7153\n",
            "Epoch 196: val_loss did not improve from 0.64011\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8563 - accuracy: 0.7167 - val_loss: 0.6620 - val_accuracy: 0.7979\n",
            "Epoch 197/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8273 - accuracy: 0.7235\n",
            "Epoch 197: val_loss did not improve from 0.64011\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8267 - accuracy: 0.7237 - val_loss: 0.6717 - val_accuracy: 0.8025\n",
            "Epoch 198/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.8485 - accuracy: 0.7189\n",
            "Epoch 198: val_loss did not improve from 0.64011\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8474 - accuracy: 0.7191 - val_loss: 0.6492 - val_accuracy: 0.8077\n",
            "Epoch 199/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.8510 - accuracy: 0.7239\n",
            "Epoch 199: val_loss did not improve from 0.64011\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8457 - accuracy: 0.7263 - val_loss: 0.6537 - val_accuracy: 0.8082\n",
            "Epoch 200/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.8349 - accuracy: 0.7199\n",
            "Epoch 200: val_loss did not improve from 0.64011\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8361 - accuracy: 0.7194 - val_loss: 0.6630 - val_accuracy: 0.8031\n",
            "Epoch 201/400\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 0.8384 - accuracy: 0.7273\n",
            "Epoch 201: val_loss did not improve from 0.64011\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8399 - accuracy: 0.7258 - val_loss: 0.6472 - val_accuracy: 0.8054\n",
            "Epoch 202/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.8634 - accuracy: 0.7151\n",
            "Epoch 202: val_loss did not improve from 0.64011\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8594 - accuracy: 0.7164 - val_loss: 0.6616 - val_accuracy: 0.7899\n",
            "Epoch 203/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.8507 - accuracy: 0.7177\n",
            "Epoch 203: val_loss did not improve from 0.64011\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8511 - accuracy: 0.7175 - val_loss: 0.6682 - val_accuracy: 0.7991\n",
            "Epoch 204/400\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.8303 - accuracy: 0.7116\n",
            "Epoch 204: val_loss did not improve from 0.64011\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8269 - accuracy: 0.7144 - val_loss: 0.6505 - val_accuracy: 0.7991\n",
            "Epoch 205/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.8363 - accuracy: 0.7237\n",
            "Epoch 205: val_loss did not improve from 0.64011\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8341 - accuracy: 0.7248 - val_loss: 0.6585 - val_accuracy: 0.8014\n",
            "Epoch 206/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.8181 - accuracy: 0.7259\n",
            "Epoch 206: val_loss did not improve from 0.64011\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8175 - accuracy: 0.7256 - val_loss: 0.6516 - val_accuracy: 0.8008\n",
            "Epoch 207/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.8255 - accuracy: 0.7220\n",
            "Epoch 207: val_loss did not improve from 0.64011\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8269 - accuracy: 0.7217 - val_loss: 0.6507 - val_accuracy: 0.7894\n",
            "Epoch 208/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.8487 - accuracy: 0.7145\n",
            "Epoch 208: val_loss did not improve from 0.64011\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8464 - accuracy: 0.7152 - val_loss: 0.6596 - val_accuracy: 0.7876\n",
            "Epoch 209/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.8250 - accuracy: 0.7268\n",
            "Epoch 209: val_loss improved from 0.64011 to 0.63308, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.8250 - accuracy: 0.7268 - val_loss: 0.6331 - val_accuracy: 0.8031\n",
            "Epoch 210/400\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.7980 - accuracy: 0.7277\n",
            "Epoch 210: val_loss did not improve from 0.63308\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8048 - accuracy: 0.7256 - val_loss: 0.6950 - val_accuracy: 0.7836\n",
            "Epoch 211/400\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 0.8211 - accuracy: 0.7238\n",
            "Epoch 211: val_loss did not improve from 0.63308\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8175 - accuracy: 0.7241 - val_loss: 0.6419 - val_accuracy: 0.8031\n",
            "Epoch 212/400\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.8113 - accuracy: 0.7311\n",
            "Epoch 212: val_loss improved from 0.63308 to 0.62785, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8102 - accuracy: 0.7316 - val_loss: 0.6279 - val_accuracy: 0.8065\n",
            "Epoch 213/400\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.8406 - accuracy: 0.7221\n",
            "Epoch 213: val_loss did not improve from 0.62785\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8355 - accuracy: 0.7248 - val_loss: 0.6468 - val_accuracy: 0.7968\n",
            "Epoch 214/400\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.8438 - accuracy: 0.7200\n",
            "Epoch 214: val_loss did not improve from 0.62785\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8440 - accuracy: 0.7205 - val_loss: 0.6406 - val_accuracy: 0.7997\n",
            "Epoch 215/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.8137 - accuracy: 0.7290\n",
            "Epoch 215: val_loss did not improve from 0.62785\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8129 - accuracy: 0.7288 - val_loss: 0.6656 - val_accuracy: 0.7951\n",
            "Epoch 216/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.8402 - accuracy: 0.7111\n",
            "Epoch 216: val_loss did not improve from 0.62785\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8395 - accuracy: 0.7128 - val_loss: 0.6620 - val_accuracy: 0.7888\n",
            "Epoch 217/400\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.8347 - accuracy: 0.7157\n",
            "Epoch 217: val_loss did not improve from 0.62785\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8302 - accuracy: 0.7167 - val_loss: 0.6393 - val_accuracy: 0.8117\n",
            "Epoch 218/400\n",
            "204/219 [==========================>...] - ETA: 0s - loss: 0.8281 - accuracy: 0.7235\n",
            "Epoch 218: val_loss did not improve from 0.62785\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8248 - accuracy: 0.7248 - val_loss: 0.6472 - val_accuracy: 0.7951\n",
            "Epoch 219/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.8532 - accuracy: 0.7157\n",
            "Epoch 219: val_loss did not improve from 0.62785\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8513 - accuracy: 0.7162 - val_loss: 0.6321 - val_accuracy: 0.8088\n",
            "Epoch 220/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.8196 - accuracy: 0.7249\n",
            "Epoch 220: val_loss did not improve from 0.62785\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8226 - accuracy: 0.7238 - val_loss: 0.6399 - val_accuracy: 0.8042\n",
            "Epoch 221/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.8347 - accuracy: 0.7224\n",
            "Epoch 221: val_loss did not improve from 0.62785\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8365 - accuracy: 0.7228 - val_loss: 0.6409 - val_accuracy: 0.8042\n",
            "Epoch 222/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.8315 - accuracy: 0.7283\n",
            "Epoch 222: val_loss did not improve from 0.62785\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8321 - accuracy: 0.7280 - val_loss: 0.6559 - val_accuracy: 0.7951\n",
            "Epoch 223/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8017 - accuracy: 0.7325\n",
            "Epoch 223: val_loss did not improve from 0.62785\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8019 - accuracy: 0.7324 - val_loss: 0.6418 - val_accuracy: 0.7997\n",
            "Epoch 224/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.8389 - accuracy: 0.7212\n",
            "Epoch 224: val_loss did not improve from 0.62785\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8389 - accuracy: 0.7211 - val_loss: 0.6561 - val_accuracy: 0.7888\n",
            "Epoch 225/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.8069 - accuracy: 0.7253\n",
            "Epoch 225: val_loss did not improve from 0.62785\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8069 - accuracy: 0.7261 - val_loss: 0.6530 - val_accuracy: 0.7899\n",
            "Epoch 226/400\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.8236 - accuracy: 0.7293\n",
            "Epoch 226: val_loss did not improve from 0.62785\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8275 - accuracy: 0.7277 - val_loss: 0.6540 - val_accuracy: 0.7911\n",
            "Epoch 227/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.8017 - accuracy: 0.7303\n",
            "Epoch 227: val_loss did not improve from 0.62785\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8022 - accuracy: 0.7300 - val_loss: 0.6358 - val_accuracy: 0.7951\n",
            "Epoch 228/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.8173 - accuracy: 0.7277\n",
            "Epoch 228: val_loss did not improve from 0.62785\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8154 - accuracy: 0.7286 - val_loss: 0.6462 - val_accuracy: 0.7956\n",
            "Epoch 229/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.8100 - accuracy: 0.7271\n",
            "Epoch 229: val_loss improved from 0.62785 to 0.61306, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8101 - accuracy: 0.7273 - val_loss: 0.6131 - val_accuracy: 0.8042\n",
            "Epoch 230/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8209 - accuracy: 0.7249\n",
            "Epoch 230: val_loss did not improve from 0.61306\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8208 - accuracy: 0.7248 - val_loss: 0.6270 - val_accuracy: 0.8071\n",
            "Epoch 231/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8103 - accuracy: 0.7239\n",
            "Epoch 231: val_loss did not improve from 0.61306\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8102 - accuracy: 0.7240 - val_loss: 0.6529 - val_accuracy: 0.7962\n",
            "Epoch 232/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.8361 - accuracy: 0.7244\n",
            "Epoch 232: val_loss did not improve from 0.61306\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8363 - accuracy: 0.7240 - val_loss: 0.6427 - val_accuracy: 0.8002\n",
            "Epoch 233/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.8523 - accuracy: 0.7189\n",
            "Epoch 233: val_loss did not improve from 0.61306\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8509 - accuracy: 0.7201 - val_loss: 0.6529 - val_accuracy: 0.7962\n",
            "Epoch 234/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.8355 - accuracy: 0.7246\n",
            "Epoch 234: val_loss did not improve from 0.61306\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8362 - accuracy: 0.7246 - val_loss: 0.6392 - val_accuracy: 0.8008\n",
            "Epoch 235/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.8128 - accuracy: 0.7277\n",
            "Epoch 235: val_loss did not improve from 0.61306\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8146 - accuracy: 0.7276 - val_loss: 0.6396 - val_accuracy: 0.8025\n",
            "Epoch 236/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.8085 - accuracy: 0.7292\n",
            "Epoch 236: val_loss improved from 0.61306 to 0.60788, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8088 - accuracy: 0.7288 - val_loss: 0.6079 - val_accuracy: 0.8180\n",
            "Epoch 237/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.8173 - accuracy: 0.7305\n",
            "Epoch 237: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8209 - accuracy: 0.7296 - val_loss: 0.6296 - val_accuracy: 0.8071\n",
            "Epoch 238/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8227 - accuracy: 0.7241\n",
            "Epoch 238: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8232 - accuracy: 0.7238 - val_loss: 0.6488 - val_accuracy: 0.8042\n",
            "Epoch 239/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8180 - accuracy: 0.7315\n",
            "Epoch 239: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8176 - accuracy: 0.7317 - val_loss: 0.6223 - val_accuracy: 0.8105\n",
            "Epoch 240/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.8231 - accuracy: 0.7307\n",
            "Epoch 240: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8234 - accuracy: 0.7300 - val_loss: 0.6385 - val_accuracy: 0.8054\n",
            "Epoch 241/400\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.8319 - accuracy: 0.7222\n",
            "Epoch 241: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8299 - accuracy: 0.7230 - val_loss: 0.6144 - val_accuracy: 0.7985\n",
            "Epoch 242/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.8118 - accuracy: 0.7310\n",
            "Epoch 242: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8124 - accuracy: 0.7301 - val_loss: 0.6400 - val_accuracy: 0.8031\n",
            "Epoch 243/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8231 - accuracy: 0.7284\n",
            "Epoch 243: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8226 - accuracy: 0.7286 - val_loss: 0.6619 - val_accuracy: 0.7911\n",
            "Epoch 244/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8180 - accuracy: 0.7279\n",
            "Epoch 244: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8181 - accuracy: 0.7278 - val_loss: 0.6170 - val_accuracy: 0.8157\n",
            "Epoch 245/400\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.8342 - accuracy: 0.7228\n",
            "Epoch 245: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8283 - accuracy: 0.7238 - val_loss: 0.6474 - val_accuracy: 0.8019\n",
            "Epoch 246/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.8066 - accuracy: 0.7328\n",
            "Epoch 246: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8054 - accuracy: 0.7337 - val_loss: 0.6400 - val_accuracy: 0.8042\n",
            "Epoch 247/400\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 0.8239 - accuracy: 0.7282\n",
            "Epoch 247: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8171 - accuracy: 0.7297 - val_loss: 0.6308 - val_accuracy: 0.8037\n",
            "Epoch 248/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.8092 - accuracy: 0.7228\n",
            "Epoch 248: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8084 - accuracy: 0.7240 - val_loss: 0.6155 - val_accuracy: 0.8100\n",
            "Epoch 249/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8195 - accuracy: 0.7275\n",
            "Epoch 249: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8204 - accuracy: 0.7274 - val_loss: 0.6439 - val_accuracy: 0.8025\n",
            "Epoch 250/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.8260 - accuracy: 0.7247\n",
            "Epoch 250: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8281 - accuracy: 0.7236 - val_loss: 0.6377 - val_accuracy: 0.8048\n",
            "Epoch 251/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.8363 - accuracy: 0.7201\n",
            "Epoch 251: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8382 - accuracy: 0.7195 - val_loss: 0.6490 - val_accuracy: 0.8082\n",
            "Epoch 252/400\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.8164 - accuracy: 0.7301\n",
            "Epoch 252: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8159 - accuracy: 0.7294 - val_loss: 0.6372 - val_accuracy: 0.8111\n",
            "Epoch 253/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.8120 - accuracy: 0.7252\n",
            "Epoch 253: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8111 - accuracy: 0.7253 - val_loss: 0.6345 - val_accuracy: 0.8122\n",
            "Epoch 254/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.8120 - accuracy: 0.7277\n",
            "Epoch 254: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8128 - accuracy: 0.7284 - val_loss: 0.6460 - val_accuracy: 0.8014\n",
            "Epoch 255/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.7993 - accuracy: 0.7333\n",
            "Epoch 255: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7993 - accuracy: 0.7333 - val_loss: 0.6400 - val_accuracy: 0.7945\n",
            "Epoch 256/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.7906 - accuracy: 0.7381\n",
            "Epoch 256: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.7889 - accuracy: 0.7386 - val_loss: 0.6548 - val_accuracy: 0.7962\n",
            "Epoch 257/400\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.7936 - accuracy: 0.7396\n",
            "Epoch 257: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8016 - accuracy: 0.7370 - val_loss: 0.6458 - val_accuracy: 0.7979\n",
            "Epoch 258/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.7886 - accuracy: 0.7377\n",
            "Epoch 258: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7906 - accuracy: 0.7380 - val_loss: 0.6191 - val_accuracy: 0.8128\n",
            "Epoch 259/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8078 - accuracy: 0.7302\n",
            "Epoch 259: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8071 - accuracy: 0.7304 - val_loss: 0.6167 - val_accuracy: 0.8094\n",
            "Epoch 260/400\n",
            "204/219 [==========================>...] - ETA: 0s - loss: 0.8042 - accuracy: 0.7335\n",
            "Epoch 260: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7990 - accuracy: 0.7341 - val_loss: 0.6227 - val_accuracy: 0.8077\n",
            "Epoch 261/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.8140 - accuracy: 0.7301\n",
            "Epoch 261: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8142 - accuracy: 0.7298 - val_loss: 0.6451 - val_accuracy: 0.7905\n",
            "Epoch 262/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.8127 - accuracy: 0.7288\n",
            "Epoch 262: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8118 - accuracy: 0.7288 - val_loss: 0.6245 - val_accuracy: 0.8031\n",
            "Epoch 263/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.8224 - accuracy: 0.7291\n",
            "Epoch 263: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8224 - accuracy: 0.7291 - val_loss: 0.6414 - val_accuracy: 0.7968\n",
            "Epoch 264/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.8118 - accuracy: 0.7319\n",
            "Epoch 264: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.8127 - accuracy: 0.7313 - val_loss: 0.6205 - val_accuracy: 0.8151\n",
            "Epoch 265/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.7977 - accuracy: 0.7384\n",
            "Epoch 265: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.7977 - accuracy: 0.7384 - val_loss: 0.6163 - val_accuracy: 0.8088\n",
            "Epoch 266/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.8120 - accuracy: 0.7283\n",
            "Epoch 266: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8120 - accuracy: 0.7283 - val_loss: 0.6585 - val_accuracy: 0.7911\n",
            "Epoch 267/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.8184 - accuracy: 0.7237\n",
            "Epoch 267: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8184 - accuracy: 0.7237 - val_loss: 0.6085 - val_accuracy: 0.8065\n",
            "Epoch 268/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8115 - accuracy: 0.7309\n",
            "Epoch 268: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8111 - accuracy: 0.7311 - val_loss: 0.6348 - val_accuracy: 0.8060\n",
            "Epoch 269/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.7998 - accuracy: 0.7340\n",
            "Epoch 269: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8010 - accuracy: 0.7327 - val_loss: 0.6184 - val_accuracy: 0.8077\n",
            "Epoch 270/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.8155 - accuracy: 0.7295\n",
            "Epoch 270: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8160 - accuracy: 0.7288 - val_loss: 0.6333 - val_accuracy: 0.8014\n",
            "Epoch 271/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.8198 - accuracy: 0.7241\n",
            "Epoch 271: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8133 - accuracy: 0.7270 - val_loss: 0.6226 - val_accuracy: 0.8031\n",
            "Epoch 272/400\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.8086 - accuracy: 0.7315\n",
            "Epoch 272: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8102 - accuracy: 0.7303 - val_loss: 0.6301 - val_accuracy: 0.8060\n",
            "Epoch 273/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.8096 - accuracy: 0.7362\n",
            "Epoch 273: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8091 - accuracy: 0.7360 - val_loss: 0.6182 - val_accuracy: 0.8019\n",
            "Epoch 274/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.7917 - accuracy: 0.7327\n",
            "Epoch 274: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.7916 - accuracy: 0.7326 - val_loss: 0.6228 - val_accuracy: 0.8117\n",
            "Epoch 275/400\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.8012 - accuracy: 0.7335\n",
            "Epoch 275: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8094 - accuracy: 0.7323 - val_loss: 0.6402 - val_accuracy: 0.8117\n",
            "Epoch 276/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.7968 - accuracy: 0.7435\n",
            "Epoch 276: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.7983 - accuracy: 0.7430 - val_loss: 0.6101 - val_accuracy: 0.8082\n",
            "Epoch 277/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.7953 - accuracy: 0.7362\n",
            "Epoch 277: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.7956 - accuracy: 0.7359 - val_loss: 0.6219 - val_accuracy: 0.8071\n",
            "Epoch 278/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.7982 - accuracy: 0.7297\n",
            "Epoch 278: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.7987 - accuracy: 0.7298 - val_loss: 0.6243 - val_accuracy: 0.8025\n",
            "Epoch 279/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.7899 - accuracy: 0.7330\n",
            "Epoch 279: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7901 - accuracy: 0.7323 - val_loss: 0.6230 - val_accuracy: 0.8060\n",
            "Epoch 280/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.7855 - accuracy: 0.7426\n",
            "Epoch 280: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7829 - accuracy: 0.7436 - val_loss: 0.6403 - val_accuracy: 0.8060\n",
            "Epoch 281/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.8002 - accuracy: 0.7280\n",
            "Epoch 281: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7972 - accuracy: 0.7286 - val_loss: 0.6254 - val_accuracy: 0.8140\n",
            "Epoch 282/400\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.8029 - accuracy: 0.7390\n",
            "Epoch 282: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8026 - accuracy: 0.7383 - val_loss: 0.6300 - val_accuracy: 0.7962\n",
            "Epoch 283/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.7915 - accuracy: 0.7336\n",
            "Epoch 283: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7894 - accuracy: 0.7351 - val_loss: 0.6339 - val_accuracy: 0.7985\n",
            "Epoch 284/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8031 - accuracy: 0.7341\n",
            "Epoch 284: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8033 - accuracy: 0.7340 - val_loss: 0.6147 - val_accuracy: 0.8174\n",
            "Epoch 285/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.8154 - accuracy: 0.7276\n",
            "Epoch 285: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8153 - accuracy: 0.7281 - val_loss: 0.6096 - val_accuracy: 0.8094\n",
            "Epoch 286/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.8035 - accuracy: 0.7392\n",
            "Epoch 286: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8017 - accuracy: 0.7397 - val_loss: 0.6316 - val_accuracy: 0.8019\n",
            "Epoch 287/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.8096 - accuracy: 0.7277\n",
            "Epoch 287: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8096 - accuracy: 0.7277 - val_loss: 0.6401 - val_accuracy: 0.7979\n",
            "Epoch 288/400\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.8243 - accuracy: 0.7263\n",
            "Epoch 288: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8248 - accuracy: 0.7248 - val_loss: 0.6428 - val_accuracy: 0.8014\n",
            "Epoch 289/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.8091 - accuracy: 0.7353\n",
            "Epoch 289: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8091 - accuracy: 0.7353 - val_loss: 0.6384 - val_accuracy: 0.8060\n",
            "Epoch 290/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.7982 - accuracy: 0.7332\n",
            "Epoch 290: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.7977 - accuracy: 0.7334 - val_loss: 0.6254 - val_accuracy: 0.8060\n",
            "Epoch 291/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.7800 - accuracy: 0.7382\n",
            "Epoch 291: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.7797 - accuracy: 0.7379 - val_loss: 0.6097 - val_accuracy: 0.8151\n",
            "Epoch 292/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.7946 - accuracy: 0.7338\n",
            "Epoch 292: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.7955 - accuracy: 0.7331 - val_loss: 0.6200 - val_accuracy: 0.8031\n",
            "Epoch 293/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.8108 - accuracy: 0.7339\n",
            "Epoch 293: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8078 - accuracy: 0.7346 - val_loss: 0.6351 - val_accuracy: 0.8048\n",
            "Epoch 294/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.8278 - accuracy: 0.7307\n",
            "Epoch 294: val_loss did not improve from 0.60788\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8238 - accuracy: 0.7319 - val_loss: 0.6324 - val_accuracy: 0.8031\n",
            "Epoch 295/400\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.7983 - accuracy: 0.7353\n",
            "Epoch 295: val_loss improved from 0.60788 to 0.60520, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8031 - accuracy: 0.7343 - val_loss: 0.6052 - val_accuracy: 0.8168\n",
            "Epoch 296/400\n",
            "203/219 [==========================>...] - ETA: 0s - loss: 0.7788 - accuracy: 0.7465\n",
            "Epoch 296: val_loss did not improve from 0.60520\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7780 - accuracy: 0.7459 - val_loss: 0.6103 - val_accuracy: 0.8151\n",
            "Epoch 297/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.7967 - accuracy: 0.7361\n",
            "Epoch 297: val_loss did not improve from 0.60520\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7999 - accuracy: 0.7343 - val_loss: 0.6321 - val_accuracy: 0.8088\n",
            "Epoch 298/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.7888 - accuracy: 0.7342\n",
            "Epoch 298: val_loss did not improve from 0.60520\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7882 - accuracy: 0.7354 - val_loss: 0.6100 - val_accuracy: 0.8100\n",
            "Epoch 299/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.8216 - accuracy: 0.7302\n",
            "Epoch 299: val_loss improved from 0.60520 to 0.60267, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8205 - accuracy: 0.7303 - val_loss: 0.6027 - val_accuracy: 0.8060\n",
            "Epoch 300/400\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.7918 - accuracy: 0.7318\n",
            "Epoch 300: val_loss did not improve from 0.60267\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7893 - accuracy: 0.7326 - val_loss: 0.6279 - val_accuracy: 0.8031\n",
            "Epoch 301/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.7909 - accuracy: 0.7307\n",
            "Epoch 301: val_loss did not improve from 0.60267\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7892 - accuracy: 0.7307 - val_loss: 0.6073 - val_accuracy: 0.8128\n",
            "Epoch 302/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.7911 - accuracy: 0.7373\n",
            "Epoch 302: val_loss did not improve from 0.60267\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7920 - accuracy: 0.7377 - val_loss: 0.6141 - val_accuracy: 0.8065\n",
            "Epoch 303/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.7854 - accuracy: 0.7429\n",
            "Epoch 303: val_loss did not improve from 0.60267\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7854 - accuracy: 0.7429 - val_loss: 0.6073 - val_accuracy: 0.8060\n",
            "Epoch 304/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.7933 - accuracy: 0.7416\n",
            "Epoch 304: val_loss did not improve from 0.60267\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.7927 - accuracy: 0.7412 - val_loss: 0.6121 - val_accuracy: 0.8185\n",
            "Epoch 305/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.7957 - accuracy: 0.7297\n",
            "Epoch 305: val_loss did not improve from 0.60267\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.7972 - accuracy: 0.7293 - val_loss: 0.6112 - val_accuracy: 0.8071\n",
            "Epoch 306/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.8109 - accuracy: 0.7282\n",
            "Epoch 306: val_loss did not improve from 0.60267\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8103 - accuracy: 0.7287 - val_loss: 0.6324 - val_accuracy: 0.8105\n",
            "Epoch 307/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.7911 - accuracy: 0.7376\n",
            "Epoch 307: val_loss did not improve from 0.60267\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.7911 - accuracy: 0.7376 - val_loss: 0.6272 - val_accuracy: 0.8060\n",
            "Epoch 308/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.7895 - accuracy: 0.7347\n",
            "Epoch 308: val_loss did not improve from 0.60267\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7901 - accuracy: 0.7347 - val_loss: 0.6412 - val_accuracy: 0.8037\n",
            "Epoch 309/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.8027 - accuracy: 0.7319\n",
            "Epoch 309: val_loss did not improve from 0.60267\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8002 - accuracy: 0.7327 - val_loss: 0.6037 - val_accuracy: 0.8122\n",
            "Epoch 310/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.8016 - accuracy: 0.7317\n",
            "Epoch 310: val_loss did not improve from 0.60267\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7994 - accuracy: 0.7326 - val_loss: 0.6278 - val_accuracy: 0.8037\n",
            "Epoch 311/400\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 0.7741 - accuracy: 0.7473\n",
            "Epoch 311: val_loss did not improve from 0.60267\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7797 - accuracy: 0.7450 - val_loss: 0.6032 - val_accuracy: 0.8185\n",
            "Epoch 312/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.7967 - accuracy: 0.7355\n",
            "Epoch 312: val_loss did not improve from 0.60267\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.7973 - accuracy: 0.7351 - val_loss: 0.6174 - val_accuracy: 0.8077\n",
            "Epoch 313/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.7821 - accuracy: 0.7400\n",
            "Epoch 313: val_loss did not improve from 0.60267\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7847 - accuracy: 0.7394 - val_loss: 0.6158 - val_accuracy: 0.8088\n",
            "Epoch 314/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.7835 - accuracy: 0.7405\n",
            "Epoch 314: val_loss did not improve from 0.60267\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7837 - accuracy: 0.7403 - val_loss: 0.6434 - val_accuracy: 0.8077\n",
            "Epoch 315/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.7864 - accuracy: 0.7423\n",
            "Epoch 315: val_loss did not improve from 0.60267\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7888 - accuracy: 0.7416 - val_loss: 0.6135 - val_accuracy: 0.8140\n",
            "Epoch 316/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.7898 - accuracy: 0.7394\n",
            "Epoch 316: val_loss did not improve from 0.60267\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7918 - accuracy: 0.7382 - val_loss: 0.6064 - val_accuracy: 0.8180\n",
            "Epoch 317/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8024 - accuracy: 0.7391\n",
            "Epoch 317: val_loss did not improve from 0.60267\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8016 - accuracy: 0.7394 - val_loss: 0.6253 - val_accuracy: 0.8054\n",
            "Epoch 318/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.7949 - accuracy: 0.7398\n",
            "Epoch 318: val_loss did not improve from 0.60267\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.7961 - accuracy: 0.7406 - val_loss: 0.6100 - val_accuracy: 0.8077\n",
            "Epoch 319/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.7876 - accuracy: 0.7420\n",
            "Epoch 319: val_loss improved from 0.60267 to 0.59387, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.7872 - accuracy: 0.7422 - val_loss: 0.5939 - val_accuracy: 0.8151\n",
            "Epoch 320/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.7923 - accuracy: 0.7399\n",
            "Epoch 320: val_loss did not improve from 0.59387\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.7903 - accuracy: 0.7397 - val_loss: 0.6210 - val_accuracy: 0.8128\n",
            "Epoch 321/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.7734 - accuracy: 0.7445\n",
            "Epoch 321: val_loss improved from 0.59387 to 0.59124, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.7768 - accuracy: 0.7433 - val_loss: 0.5912 - val_accuracy: 0.8214\n",
            "Epoch 322/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.8016 - accuracy: 0.7374\n",
            "Epoch 322: val_loss did not improve from 0.59124\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.8027 - accuracy: 0.7369 - val_loss: 0.6066 - val_accuracy: 0.8174\n",
            "Epoch 323/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.7884 - accuracy: 0.7445\n",
            "Epoch 323: val_loss did not improve from 0.59124\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.7914 - accuracy: 0.7429 - val_loss: 0.6168 - val_accuracy: 0.8105\n",
            "Epoch 324/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.7701 - accuracy: 0.7461\n",
            "Epoch 324: val_loss did not improve from 0.59124\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.7706 - accuracy: 0.7460 - val_loss: 0.6264 - val_accuracy: 0.8134\n",
            "Epoch 325/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.7854 - accuracy: 0.7409\n",
            "Epoch 325: val_loss did not improve from 0.59124\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.7845 - accuracy: 0.7416 - val_loss: 0.6051 - val_accuracy: 0.8157\n",
            "Epoch 326/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8124 - accuracy: 0.7294\n",
            "Epoch 326: val_loss did not improve from 0.59124\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8122 - accuracy: 0.7293 - val_loss: 0.6305 - val_accuracy: 0.8105\n",
            "Epoch 327/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.8024 - accuracy: 0.7255\n",
            "Epoch 327: val_loss did not improve from 0.59124\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8026 - accuracy: 0.7258 - val_loss: 0.6039 - val_accuracy: 0.8151\n",
            "Epoch 328/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.7637 - accuracy: 0.7371\n",
            "Epoch 328: val_loss did not improve from 0.59124\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7652 - accuracy: 0.7373 - val_loss: 0.6198 - val_accuracy: 0.8111\n",
            "Epoch 329/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.7948 - accuracy: 0.7343\n",
            "Epoch 329: val_loss did not improve from 0.59124\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7970 - accuracy: 0.7333 - val_loss: 0.6191 - val_accuracy: 0.8117\n",
            "Epoch 330/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.7890 - accuracy: 0.7443\n",
            "Epoch 330: val_loss did not improve from 0.59124\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.7902 - accuracy: 0.7442 - val_loss: 0.6127 - val_accuracy: 0.8077\n",
            "Epoch 331/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.7965 - accuracy: 0.7354\n",
            "Epoch 331: val_loss did not improve from 0.59124\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.7970 - accuracy: 0.7354 - val_loss: 0.6386 - val_accuracy: 0.7956\n",
            "Epoch 332/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.7840 - accuracy: 0.7377\n",
            "Epoch 332: val_loss did not improve from 0.59124\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.7843 - accuracy: 0.7379 - val_loss: 0.6102 - val_accuracy: 0.8105\n",
            "Epoch 333/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.7957 - accuracy: 0.7370\n",
            "Epoch 333: val_loss did not improve from 0.59124\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.7978 - accuracy: 0.7360 - val_loss: 0.6005 - val_accuracy: 0.8163\n",
            "Epoch 334/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.7932 - accuracy: 0.7351\n",
            "Epoch 334: val_loss did not improve from 0.59124\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7916 - accuracy: 0.7357 - val_loss: 0.6293 - val_accuracy: 0.8128\n",
            "Epoch 335/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.7881 - accuracy: 0.7353\n",
            "Epoch 335: val_loss did not improve from 0.59124\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.7879 - accuracy: 0.7341 - val_loss: 0.6304 - val_accuracy: 0.8048\n",
            "Epoch 336/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.8045 - accuracy: 0.7321\n",
            "Epoch 336: val_loss did not improve from 0.59124\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8000 - accuracy: 0.7340 - val_loss: 0.6157 - val_accuracy: 0.8060\n",
            "Epoch 337/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.7705 - accuracy: 0.7412\n",
            "Epoch 337: val_loss did not improve from 0.59124\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.7703 - accuracy: 0.7413 - val_loss: 0.6131 - val_accuracy: 0.8185\n",
            "Epoch 338/400\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.7922 - accuracy: 0.7406\n",
            "Epoch 338: val_loss did not improve from 0.59124\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7912 - accuracy: 0.7406 - val_loss: 0.6300 - val_accuracy: 0.7934\n",
            "Epoch 339/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.7605 - accuracy: 0.7451\n",
            "Epoch 339: val_loss did not improve from 0.59124\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7575 - accuracy: 0.7457 - val_loss: 0.5991 - val_accuracy: 0.8077\n",
            "Epoch 340/400\n",
            "204/219 [==========================>...] - ETA: 0s - loss: 0.7621 - accuracy: 0.7402\n",
            "Epoch 340: val_loss did not improve from 0.59124\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7582 - accuracy: 0.7413 - val_loss: 0.6043 - val_accuracy: 0.8151\n",
            "Epoch 341/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.7755 - accuracy: 0.7452\n",
            "Epoch 341: val_loss did not improve from 0.59124\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7742 - accuracy: 0.7455 - val_loss: 0.6143 - val_accuracy: 0.8208\n",
            "Epoch 342/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.7808 - accuracy: 0.7366\n",
            "Epoch 342: val_loss did not improve from 0.59124\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7808 - accuracy: 0.7366 - val_loss: 0.6034 - val_accuracy: 0.8145\n",
            "Epoch 343/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.7775 - accuracy: 0.7434\n",
            "Epoch 343: val_loss did not improve from 0.59124\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.7765 - accuracy: 0.7436 - val_loss: 0.6000 - val_accuracy: 0.8237\n",
            "Epoch 344/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.7772 - accuracy: 0.7390\n",
            "Epoch 344: val_loss did not improve from 0.59124\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.7774 - accuracy: 0.7392 - val_loss: 0.6207 - val_accuracy: 0.8157\n",
            "Epoch 345/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.7728 - accuracy: 0.7413\n",
            "Epoch 345: val_loss improved from 0.59124 to 0.58928, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.7715 - accuracy: 0.7426 - val_loss: 0.5893 - val_accuracy: 0.8277\n",
            "Epoch 346/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.8030 - accuracy: 0.7331\n",
            "Epoch 346: val_loss did not improve from 0.58928\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8039 - accuracy: 0.7326 - val_loss: 0.5999 - val_accuracy: 0.8197\n",
            "Epoch 347/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.7818 - accuracy: 0.7451\n",
            "Epoch 347: val_loss did not improve from 0.58928\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.7813 - accuracy: 0.7453 - val_loss: 0.6108 - val_accuracy: 0.8168\n",
            "Epoch 348/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.7639 - accuracy: 0.7483\n",
            "Epoch 348: val_loss did not improve from 0.58928\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.7639 - accuracy: 0.7483 - val_loss: 0.5977 - val_accuracy: 0.8117\n",
            "Epoch 349/400\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.7746 - accuracy: 0.7403\n",
            "Epoch 349: val_loss did not improve from 0.58928\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7710 - accuracy: 0.7419 - val_loss: 0.5975 - val_accuracy: 0.8191\n",
            "Epoch 350/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.7595 - accuracy: 0.7521\n",
            "Epoch 350: val_loss did not improve from 0.58928\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7595 - accuracy: 0.7522 - val_loss: 0.6334 - val_accuracy: 0.8071\n",
            "Epoch 351/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.7884 - accuracy: 0.7432\n",
            "Epoch 351: val_loss did not improve from 0.58928\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.7879 - accuracy: 0.7426 - val_loss: 0.6286 - val_accuracy: 0.8140\n",
            "Epoch 352/400\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.7631 - accuracy: 0.7428\n",
            "Epoch 352: val_loss did not improve from 0.58928\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7575 - accuracy: 0.7447 - val_loss: 0.6210 - val_accuracy: 0.8122\n",
            "Epoch 353/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.7696 - accuracy: 0.7471\n",
            "Epoch 353: val_loss did not improve from 0.58928\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7681 - accuracy: 0.7470 - val_loss: 0.6158 - val_accuracy: 0.8122\n",
            "Epoch 354/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.7932 - accuracy: 0.7380\n",
            "Epoch 354: val_loss did not improve from 0.58928\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7942 - accuracy: 0.7377 - val_loss: 0.6121 - val_accuracy: 0.8082\n",
            "Epoch 355/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.7959 - accuracy: 0.7402\n",
            "Epoch 355: val_loss did not improve from 0.58928\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.7960 - accuracy: 0.7394 - val_loss: 0.6234 - val_accuracy: 0.8122\n",
            "Epoch 356/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.7758 - accuracy: 0.7400\n",
            "Epoch 356: val_loss did not improve from 0.58928\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.7758 - accuracy: 0.7400 - val_loss: 0.5969 - val_accuracy: 0.8145\n",
            "Epoch 357/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.7922 - accuracy: 0.7324\n",
            "Epoch 357: val_loss did not improve from 0.58928\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.7946 - accuracy: 0.7314 - val_loss: 0.6026 - val_accuracy: 0.8122\n",
            "Epoch 358/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.7796 - accuracy: 0.7398\n",
            "Epoch 358: val_loss did not improve from 0.58928\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.7790 - accuracy: 0.7397 - val_loss: 0.6068 - val_accuracy: 0.8122\n",
            "Epoch 359/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.8028 - accuracy: 0.7334\n",
            "Epoch 359: val_loss did not improve from 0.58928\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8071 - accuracy: 0.7324 - val_loss: 0.6208 - val_accuracy: 0.8140\n",
            "Epoch 360/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.7605 - accuracy: 0.7445\n",
            "Epoch 360: val_loss did not improve from 0.58928\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7581 - accuracy: 0.7456 - val_loss: 0.6116 - val_accuracy: 0.8151\n",
            "Epoch 361/400\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.7912 - accuracy: 0.7368\n",
            "Epoch 361: val_loss did not improve from 0.58928\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7910 - accuracy: 0.7374 - val_loss: 0.6031 - val_accuracy: 0.8203\n",
            "Epoch 362/400\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.7638 - accuracy: 0.7410\n",
            "Epoch 362: val_loss did not improve from 0.58928\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7657 - accuracy: 0.7399 - val_loss: 0.6018 - val_accuracy: 0.8117\n",
            "Epoch 363/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.7776 - accuracy: 0.7439\n",
            "Epoch 363: val_loss did not improve from 0.58928\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7773 - accuracy: 0.7443 - val_loss: 0.5944 - val_accuracy: 0.8111\n",
            "Epoch 364/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.7774 - accuracy: 0.7397\n",
            "Epoch 364: val_loss did not improve from 0.58928\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7779 - accuracy: 0.7404 - val_loss: 0.5916 - val_accuracy: 0.8208\n",
            "Epoch 365/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.7814 - accuracy: 0.7385\n",
            "Epoch 365: val_loss did not improve from 0.58928\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.7812 - accuracy: 0.7380 - val_loss: 0.6101 - val_accuracy: 0.8168\n",
            "Epoch 366/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.7800 - accuracy: 0.7418\n",
            "Epoch 366: val_loss did not improve from 0.58928\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7792 - accuracy: 0.7419 - val_loss: 0.6009 - val_accuracy: 0.8151\n",
            "Epoch 367/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.7821 - accuracy: 0.7365\n",
            "Epoch 367: val_loss did not improve from 0.58928\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.7828 - accuracy: 0.7367 - val_loss: 0.5982 - val_accuracy: 0.8100\n",
            "Epoch 368/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.7748 - accuracy: 0.7393\n",
            "Epoch 368: val_loss did not improve from 0.58928\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.7791 - accuracy: 0.7376 - val_loss: 0.5961 - val_accuracy: 0.8151\n",
            "Epoch 369/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.7759 - accuracy: 0.7358\n",
            "Epoch 369: val_loss did not improve from 0.58928\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.7774 - accuracy: 0.7357 - val_loss: 0.6202 - val_accuracy: 0.8048\n",
            "Epoch 370/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.7763 - accuracy: 0.7399\n",
            "Epoch 370: val_loss did not improve from 0.58928\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.7771 - accuracy: 0.7402 - val_loss: 0.6478 - val_accuracy: 0.7991\n",
            "Epoch 371/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.7948 - accuracy: 0.7361\n",
            "Epoch 371: val_loss did not improve from 0.58928\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.7903 - accuracy: 0.7376 - val_loss: 0.5927 - val_accuracy: 0.8208\n",
            "Epoch 372/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.7867 - accuracy: 0.7368\n",
            "Epoch 372: val_loss did not improve from 0.58928\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.7892 - accuracy: 0.7361 - val_loss: 0.6187 - val_accuracy: 0.8071\n",
            "Epoch 373/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.7714 - accuracy: 0.7426\n",
            "Epoch 373: val_loss did not improve from 0.58928\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.7742 - accuracy: 0.7422 - val_loss: 0.6246 - val_accuracy: 0.8077\n",
            "Epoch 374/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.7580 - accuracy: 0.7530\n",
            "Epoch 374: val_loss did not improve from 0.58928\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.7625 - accuracy: 0.7520 - val_loss: 0.6059 - val_accuracy: 0.8231\n",
            "Epoch 375/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.7721 - accuracy: 0.7424\n",
            "Epoch 375: val_loss did not improve from 0.58928\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7700 - accuracy: 0.7422 - val_loss: 0.5900 - val_accuracy: 0.8174\n",
            "Epoch 376/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.7886 - accuracy: 0.7424\n",
            "Epoch 376: val_loss did not improve from 0.58928\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.7898 - accuracy: 0.7413 - val_loss: 0.6174 - val_accuracy: 0.8134\n",
            "Epoch 377/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.7662 - accuracy: 0.7523\n",
            "Epoch 377: val_loss did not improve from 0.58928\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.7661 - accuracy: 0.7520 - val_loss: 0.6254 - val_accuracy: 0.8100\n",
            "Epoch 378/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.8029 - accuracy: 0.7335\n",
            "Epoch 378: val_loss did not improve from 0.58928\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8055 - accuracy: 0.7331 - val_loss: 0.6127 - val_accuracy: 0.8071\n",
            "Epoch 379/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.7751 - accuracy: 0.7411\n",
            "Epoch 379: val_loss improved from 0.58928 to 0.58432, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7755 - accuracy: 0.7409 - val_loss: 0.5843 - val_accuracy: 0.8180\n",
            "Epoch 380/400\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.7648 - accuracy: 0.7473\n",
            "Epoch 380: val_loss did not improve from 0.58432\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7643 - accuracy: 0.7480 - val_loss: 0.5915 - val_accuracy: 0.8226\n",
            "Epoch 381/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.7743 - accuracy: 0.7440\n",
            "Epoch 381: val_loss did not improve from 0.58432\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.7745 - accuracy: 0.7437 - val_loss: 0.6184 - val_accuracy: 0.8065\n",
            "Epoch 382/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.7553 - accuracy: 0.7443\n",
            "Epoch 382: val_loss did not improve from 0.58432\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7570 - accuracy: 0.7442 - val_loss: 0.5974 - val_accuracy: 0.8134\n",
            "Epoch 383/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.7953 - accuracy: 0.7406\n",
            "Epoch 383: val_loss improved from 0.58432 to 0.58122, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.7918 - accuracy: 0.7420 - val_loss: 0.5812 - val_accuracy: 0.8243\n",
            "Epoch 384/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.7565 - accuracy: 0.7499\n",
            "Epoch 384: val_loss did not improve from 0.58122\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.7606 - accuracy: 0.7487 - val_loss: 0.6120 - val_accuracy: 0.8168\n",
            "Epoch 385/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.7721 - accuracy: 0.7437\n",
            "Epoch 385: val_loss did not improve from 0.58122\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.7700 - accuracy: 0.7439 - val_loss: 0.5925 - val_accuracy: 0.8197\n",
            "Epoch 386/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.7717 - accuracy: 0.7439\n",
            "Epoch 386: val_loss did not improve from 0.58122\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.7676 - accuracy: 0.7456 - val_loss: 0.5973 - val_accuracy: 0.8174\n",
            "Epoch 387/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.7730 - accuracy: 0.7432\n",
            "Epoch 387: val_loss improved from 0.58122 to 0.57656, saving model to saved_models/audio_classification_model1.hdf5\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.7768 - accuracy: 0.7413 - val_loss: 0.5766 - val_accuracy: 0.8266\n",
            "Epoch 388/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.7678 - accuracy: 0.7481\n",
            "Epoch 388: val_loss did not improve from 0.57656\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7681 - accuracy: 0.7483 - val_loss: 0.5978 - val_accuracy: 0.8180\n",
            "Epoch 389/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.7788 - accuracy: 0.7405\n",
            "Epoch 389: val_loss did not improve from 0.57656\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7780 - accuracy: 0.7409 - val_loss: 0.6194 - val_accuracy: 0.8042\n",
            "Epoch 390/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.7765 - accuracy: 0.7412\n",
            "Epoch 390: val_loss did not improve from 0.57656\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7735 - accuracy: 0.7419 - val_loss: 0.6003 - val_accuracy: 0.8185\n",
            "Epoch 391/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.7815 - accuracy: 0.7422\n",
            "Epoch 391: val_loss did not improve from 0.57656\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.7770 - accuracy: 0.7443 - val_loss: 0.6189 - val_accuracy: 0.8065\n",
            "Epoch 392/400\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 0.7652 - accuracy: 0.7430\n",
            "Epoch 392: val_loss did not improve from 0.57656\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7598 - accuracy: 0.7447 - val_loss: 0.5899 - val_accuracy: 0.8197\n",
            "Epoch 393/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.7781 - accuracy: 0.7499\n",
            "Epoch 393: val_loss did not improve from 0.57656\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7798 - accuracy: 0.7496 - val_loss: 0.6250 - val_accuracy: 0.8157\n",
            "Epoch 394/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.7838 - accuracy: 0.7427\n",
            "Epoch 394: val_loss did not improve from 0.57656\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7838 - accuracy: 0.7427 - val_loss: 0.6061 - val_accuracy: 0.8185\n",
            "Epoch 395/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.7525 - accuracy: 0.7525\n",
            "Epoch 395: val_loss did not improve from 0.57656\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7513 - accuracy: 0.7529 - val_loss: 0.6222 - val_accuracy: 0.8060\n",
            "Epoch 396/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.7699 - accuracy: 0.7481\n",
            "Epoch 396: val_loss did not improve from 0.57656\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7739 - accuracy: 0.7467 - val_loss: 0.5799 - val_accuracy: 0.8191\n",
            "Epoch 397/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.7749 - accuracy: 0.7440\n",
            "Epoch 397: val_loss did not improve from 0.57656\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.7748 - accuracy: 0.7449 - val_loss: 0.5911 - val_accuracy: 0.8105\n",
            "Epoch 398/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.7646 - accuracy: 0.7459\n",
            "Epoch 398: val_loss did not improve from 0.57656\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.7646 - accuracy: 0.7459 - val_loss: 0.5986 - val_accuracy: 0.8231\n",
            "Epoch 399/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.7654 - accuracy: 0.7481\n",
            "Epoch 399: val_loss did not improve from 0.57656\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.7691 - accuracy: 0.7472 - val_loss: 0.5932 - val_accuracy: 0.8122\n",
            "Epoch 400/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.7845 - accuracy: 0.7442\n",
            "Epoch 400: val_loss did not improve from 0.57656\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.7846 - accuracy: 0.7443 - val_loss: 0.5871 - val_accuracy: 0.8208\n",
            "Training completed in time:  0:07:22.729938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from datetime import datetime \n",
        "\n",
        "num_epochs = 400\n",
        "num_batch_size = 32\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='saved_models/audio_classification_MODEL2.hdf5', \n",
        "                               verbose=1, save_best_only=True)\n",
        "start = datetime.now()\n",
        "\n",
        "model2.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n",
        "\n",
        "\n",
        "duration = datetime.now() - start\n",
        "print(\"Training completed in time: \", duration)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAqn7SnBb8m8",
        "outputId": "3e6a136d-59d2-48dc-908e-893f8ed8003b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 8.1734 - accuracy: 0.1075\n",
            "Epoch 1: val_loss improved from inf to 2.29130, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 8.1659 - accuracy: 0.1075 - val_loss: 2.2913 - val_accuracy: 0.1225\n",
            "Epoch 2/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 2.6319 - accuracy: 0.1318\n",
            "Epoch 2: val_loss improved from 2.29130 to 2.26667, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 2.6261 - accuracy: 0.1330 - val_loss: 2.2667 - val_accuracy: 0.1173\n",
            "Epoch 3/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 2.3504 - accuracy: 0.1426\n",
            "Epoch 3: val_loss improved from 2.26667 to 2.23336, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 2.3507 - accuracy: 0.1420 - val_loss: 2.2334 - val_accuracy: 0.1214\n",
            "Epoch 4/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 2.2650 - accuracy: 0.1599\n",
            "Epoch 4: val_loss improved from 2.23336 to 2.19684, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 2.2629 - accuracy: 0.1611 - val_loss: 2.1968 - val_accuracy: 0.1494\n",
            "Epoch 5/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 2.2016 - accuracy: 0.1693\n",
            "Epoch 5: val_loss improved from 2.19684 to 2.13515, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 2.2010 - accuracy: 0.1705 - val_loss: 2.1352 - val_accuracy: 0.1729\n",
            "Epoch 6/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 2.1541 - accuracy: 0.1882\n",
            "Epoch 6: val_loss improved from 2.13515 to 2.08848, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 2.1536 - accuracy: 0.1873 - val_loss: 2.0885 - val_accuracy: 0.2106\n",
            "Epoch 7/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 2.1080 - accuracy: 0.2083\n",
            "Epoch 7: val_loss improved from 2.08848 to 2.03938, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 2.1066 - accuracy: 0.2063 - val_loss: 2.0394 - val_accuracy: 0.2496\n",
            "Epoch 8/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 2.0718 - accuracy: 0.2183\n",
            "Epoch 8: val_loss improved from 2.03938 to 1.99926, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 2.0698 - accuracy: 0.2186 - val_loss: 1.9993 - val_accuracy: 0.2639\n",
            "Epoch 9/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 2.0206 - accuracy: 0.2488\n",
            "Epoch 9: val_loss improved from 1.99926 to 1.92745, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 2.0202 - accuracy: 0.2490 - val_loss: 1.9275 - val_accuracy: 0.3246\n",
            "Epoch 10/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 1.9674 - accuracy: 0.2727\n",
            "Epoch 10: val_loss improved from 1.92745 to 1.88484, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.9693 - accuracy: 0.2726 - val_loss: 1.8848 - val_accuracy: 0.2965\n",
            "Epoch 11/400\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 1.9091 - accuracy: 0.2970\n",
            "Epoch 11: val_loss improved from 1.88484 to 1.80462, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.9047 - accuracy: 0.2984 - val_loss: 1.8046 - val_accuracy: 0.3675\n",
            "Epoch 12/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 1.8426 - accuracy: 0.3302\n",
            "Epoch 12: val_loss improved from 1.80462 to 1.75007, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.8416 - accuracy: 0.3304 - val_loss: 1.7501 - val_accuracy: 0.3681\n",
            "Epoch 13/400\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 1.7874 - accuracy: 0.3486\n",
            "Epoch 13: val_loss improved from 1.75007 to 1.67461, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.7872 - accuracy: 0.3503 - val_loss: 1.6746 - val_accuracy: 0.4282\n",
            "Epoch 14/400\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 1.7576 - accuracy: 0.3603\n",
            "Epoch 14: val_loss improved from 1.67461 to 1.61770, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.7543 - accuracy: 0.3629 - val_loss: 1.6177 - val_accuracy: 0.4493\n",
            "Epoch 15/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 1.7074 - accuracy: 0.3789\n",
            "Epoch 15: val_loss improved from 1.61770 to 1.53659, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 1.7069 - accuracy: 0.3794 - val_loss: 1.5366 - val_accuracy: 0.4734\n",
            "Epoch 16/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 1.6629 - accuracy: 0.4038\n",
            "Epoch 16: val_loss did not improve from 1.53659\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 1.6626 - accuracy: 0.4037 - val_loss: 1.5395 - val_accuracy: 0.4528\n",
            "Epoch 17/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 1.6198 - accuracy: 0.4134\n",
            "Epoch 17: val_loss improved from 1.53659 to 1.46798, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.6190 - accuracy: 0.4125 - val_loss: 1.4680 - val_accuracy: 0.5209\n",
            "Epoch 18/400\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 1.6125 - accuracy: 0.4321\n",
            "Epoch 18: val_loss improved from 1.46798 to 1.46139, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.6094 - accuracy: 0.4352 - val_loss: 1.4614 - val_accuracy: 0.5054\n",
            "Epoch 19/400\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 1.5606 - accuracy: 0.4522\n",
            "Epoch 19: val_loss improved from 1.46139 to 1.41895, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.5609 - accuracy: 0.4507 - val_loss: 1.4190 - val_accuracy: 0.5146\n",
            "Epoch 20/400\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 1.5319 - accuracy: 0.4544\n",
            "Epoch 20: val_loss improved from 1.41895 to 1.37819, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.5310 - accuracy: 0.4548 - val_loss: 1.3782 - val_accuracy: 0.5575\n",
            "Epoch 21/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 1.4914 - accuracy: 0.4715\n",
            "Epoch 21: val_loss improved from 1.37819 to 1.35092, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.4914 - accuracy: 0.4719 - val_loss: 1.3509 - val_accuracy: 0.5570\n",
            "Epoch 22/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 1.4866 - accuracy: 0.4754\n",
            "Epoch 22: val_loss improved from 1.35092 to 1.34036, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.4866 - accuracy: 0.4754 - val_loss: 1.3404 - val_accuracy: 0.5495\n",
            "Epoch 23/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 1.4483 - accuracy: 0.4878\n",
            "Epoch 23: val_loss improved from 1.34036 to 1.27454, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.4478 - accuracy: 0.4879 - val_loss: 1.2745 - val_accuracy: 0.5930\n",
            "Epoch 24/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 1.4281 - accuracy: 0.5012\n",
            "Epoch 24: val_loss did not improve from 1.27454\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.4307 - accuracy: 0.5022 - val_loss: 1.2978 - val_accuracy: 0.5741\n",
            "Epoch 25/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 1.4174 - accuracy: 0.5146\n",
            "Epoch 25: val_loss improved from 1.27454 to 1.25340, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.4163 - accuracy: 0.5148 - val_loss: 1.2534 - val_accuracy: 0.5861\n",
            "Epoch 26/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 1.3940 - accuracy: 0.5194\n",
            "Epoch 26: val_loss did not improve from 1.25340\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3930 - accuracy: 0.5194 - val_loss: 1.2727 - val_accuracy: 0.5707\n",
            "Epoch 27/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 1.3848 - accuracy: 0.5230\n",
            "Epoch 27: val_loss improved from 1.25340 to 1.22166, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3824 - accuracy: 0.5238 - val_loss: 1.2217 - val_accuracy: 0.5930\n",
            "Epoch 28/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 1.3667 - accuracy: 0.5261\n",
            "Epoch 28: val_loss improved from 1.22166 to 1.20555, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3658 - accuracy: 0.5264 - val_loss: 1.2056 - val_accuracy: 0.5970\n",
            "Epoch 29/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 1.3561 - accuracy: 0.5357\n",
            "Epoch 29: val_loss improved from 1.20555 to 1.20503, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 1.3545 - accuracy: 0.5359 - val_loss: 1.2050 - val_accuracy: 0.6010\n",
            "Epoch 30/400\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 1.3271 - accuracy: 0.5437\n",
            "Epoch 30: val_loss did not improve from 1.20503\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 1.3289 - accuracy: 0.5417 - val_loss: 1.2053 - val_accuracy: 0.6142\n",
            "Epoch 31/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 1.3229 - accuracy: 0.5534\n",
            "Epoch 31: val_loss improved from 1.20503 to 1.17094, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3202 - accuracy: 0.5538 - val_loss: 1.1709 - val_accuracy: 0.6199\n",
            "Epoch 32/400\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 1.2932 - accuracy: 0.5581\n",
            "Epoch 32: val_loss did not improve from 1.17094\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3029 - accuracy: 0.5558 - val_loss: 1.1773 - val_accuracy: 0.6171\n",
            "Epoch 33/400\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 1.3007 - accuracy: 0.5584\n",
            "Epoch 33: val_loss did not improve from 1.17094\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.3005 - accuracy: 0.5578 - val_loss: 1.1974 - val_accuracy: 0.6033\n",
            "Epoch 34/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 1.2713 - accuracy: 0.5595\n",
            "Epoch 34: val_loss improved from 1.17094 to 1.13971, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.2782 - accuracy: 0.5581 - val_loss: 1.1397 - val_accuracy: 0.6165\n",
            "Epoch 35/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 1.2671 - accuracy: 0.5655\n",
            "Epoch 35: val_loss improved from 1.13971 to 1.12341, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2661 - accuracy: 0.5658 - val_loss: 1.1234 - val_accuracy: 0.6274\n",
            "Epoch 36/400\n",
            "202/219 [==========================>...] - ETA: 0s - loss: 1.2562 - accuracy: 0.5774\n",
            "Epoch 36: val_loss did not improve from 1.12341\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2588 - accuracy: 0.5767 - val_loss: 1.1361 - val_accuracy: 0.6211\n",
            "Epoch 37/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 1.2259 - accuracy: 0.5804\n",
            "Epoch 37: val_loss improved from 1.12341 to 1.08507, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2256 - accuracy: 0.5805 - val_loss: 1.0851 - val_accuracy: 0.6342\n",
            "Epoch 38/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 1.2421 - accuracy: 0.5745\n",
            "Epoch 38: val_loss did not improve from 1.08507\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2391 - accuracy: 0.5761 - val_loss: 1.1194 - val_accuracy: 0.6216\n",
            "Epoch 39/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 1.2124 - accuracy: 0.5935\n",
            "Epoch 39: val_loss improved from 1.08507 to 1.07998, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2119 - accuracy: 0.5933 - val_loss: 1.0800 - val_accuracy: 0.6394\n",
            "Epoch 40/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 1.2078 - accuracy: 0.5888\n",
            "Epoch 40: val_loss did not improve from 1.07998\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2122 - accuracy: 0.5881 - val_loss: 1.0934 - val_accuracy: 0.6365\n",
            "Epoch 41/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 1.1992 - accuracy: 0.5955\n",
            "Epoch 41: val_loss did not improve from 1.07998\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.2015 - accuracy: 0.5947 - val_loss: 1.0803 - val_accuracy: 0.6457\n",
            "Epoch 42/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 1.1963 - accuracy: 0.6000\n",
            "Epoch 42: val_loss improved from 1.07998 to 1.05716, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 1.1981 - accuracy: 0.5997 - val_loss: 1.0572 - val_accuracy: 0.6560\n",
            "Epoch 43/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 1.1780 - accuracy: 0.6036\n",
            "Epoch 43: val_loss did not improve from 1.05716\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 1.1780 - accuracy: 0.6036 - val_loss: 1.0971 - val_accuracy: 0.6302\n",
            "Epoch 44/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 1.1959 - accuracy: 0.6012\n",
            "Epoch 44: val_loss improved from 1.05716 to 1.05452, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1959 - accuracy: 0.6003 - val_loss: 1.0545 - val_accuracy: 0.6428\n",
            "Epoch 45/400\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 1.1629 - accuracy: 0.6089\n",
            "Epoch 45: val_loss improved from 1.05452 to 1.04767, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1652 - accuracy: 0.6070 - val_loss: 1.0477 - val_accuracy: 0.6508\n",
            "Epoch 46/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 1.1582 - accuracy: 0.6096\n",
            "Epoch 46: val_loss improved from 1.04767 to 1.03839, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1600 - accuracy: 0.6087 - val_loss: 1.0384 - val_accuracy: 0.6531\n",
            "Epoch 47/400\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 1.1557 - accuracy: 0.6185\n",
            "Epoch 47: val_loss improved from 1.03839 to 1.02670, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1569 - accuracy: 0.6170 - val_loss: 1.0267 - val_accuracy: 0.6669\n",
            "Epoch 48/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 1.1618 - accuracy: 0.6123\n",
            "Epoch 48: val_loss did not improve from 1.02670\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1617 - accuracy: 0.6116 - val_loss: 1.0523 - val_accuracy: 0.6480\n",
            "Epoch 49/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 1.1422 - accuracy: 0.6246\n",
            "Epoch 49: val_loss improved from 1.02670 to 1.01569, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1422 - accuracy: 0.6246 - val_loss: 1.0157 - val_accuracy: 0.6611\n",
            "Epoch 50/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 1.1393 - accuracy: 0.6208\n",
            "Epoch 50: val_loss improved from 1.01569 to 1.01444, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1448 - accuracy: 0.6189 - val_loss: 1.0144 - val_accuracy: 0.6634\n",
            "Epoch 51/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 1.1265 - accuracy: 0.6314\n",
            "Epoch 51: val_loss improved from 1.01444 to 0.97374, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1301 - accuracy: 0.6299 - val_loss: 0.9737 - val_accuracy: 0.6749\n",
            "Epoch 52/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 1.1232 - accuracy: 0.6280\n",
            "Epoch 52: val_loss did not improve from 0.97374\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1272 - accuracy: 0.6268 - val_loss: 0.9764 - val_accuracy: 0.6743\n",
            "Epoch 53/400\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 1.1161 - accuracy: 0.6221\n",
            "Epoch 53: val_loss did not improve from 0.97374\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1247 - accuracy: 0.6208 - val_loss: 0.9923 - val_accuracy: 0.6623\n",
            "Epoch 54/400\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 1.1184 - accuracy: 0.6355\n",
            "Epoch 54: val_loss did not improve from 0.97374\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1221 - accuracy: 0.6336 - val_loss: 1.0079 - val_accuracy: 0.6611\n",
            "Epoch 55/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 1.1215 - accuracy: 0.6292\n",
            "Epoch 55: val_loss did not improve from 0.97374\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1215 - accuracy: 0.6292 - val_loss: 0.9828 - val_accuracy: 0.6777\n",
            "Epoch 56/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 1.1232 - accuracy: 0.6241\n",
            "Epoch 56: val_loss did not improve from 0.97374\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 1.1203 - accuracy: 0.6249 - val_loss: 0.9773 - val_accuracy: 0.6840\n",
            "Epoch 57/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 1.1115 - accuracy: 0.6349\n",
            "Epoch 57: val_loss improved from 0.97374 to 0.96522, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 1.1108 - accuracy: 0.6348 - val_loss: 0.9652 - val_accuracy: 0.6869\n",
            "Epoch 58/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 1.1116 - accuracy: 0.6310\n",
            "Epoch 58: val_loss improved from 0.96522 to 0.95620, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1092 - accuracy: 0.6326 - val_loss: 0.9562 - val_accuracy: 0.6903\n",
            "Epoch 59/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 1.0893 - accuracy: 0.6334\n",
            "Epoch 59: val_loss did not improve from 0.95620\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.0911 - accuracy: 0.6334 - val_loss: 0.9749 - val_accuracy: 0.6857\n",
            "Epoch 60/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 1.1012 - accuracy: 0.6286\n",
            "Epoch 60: val_loss improved from 0.95620 to 0.95362, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1019 - accuracy: 0.6283 - val_loss: 0.9536 - val_accuracy: 0.6989\n",
            "Epoch 61/400\n",
            "203/219 [==========================>...] - ETA: 0s - loss: 1.0842 - accuracy: 0.6393\n",
            "Epoch 61: val_loss did not improve from 0.95362\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.0791 - accuracy: 0.6421 - val_loss: 0.9544 - val_accuracy: 0.6869\n",
            "Epoch 62/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 1.1024 - accuracy: 0.6317\n",
            "Epoch 62: val_loss improved from 0.95362 to 0.95334, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1008 - accuracy: 0.6312 - val_loss: 0.9533 - val_accuracy: 0.6795\n",
            "Epoch 63/400\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 1.0762 - accuracy: 0.6443\n",
            "Epoch 63: val_loss improved from 0.95334 to 0.94396, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.0744 - accuracy: 0.6448 - val_loss: 0.9440 - val_accuracy: 0.6829\n",
            "Epoch 64/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 1.0690 - accuracy: 0.6444\n",
            "Epoch 64: val_loss did not improve from 0.94396\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.0696 - accuracy: 0.6445 - val_loss: 0.9602 - val_accuracy: 0.6938\n",
            "Epoch 65/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 1.0888 - accuracy: 0.6373\n",
            "Epoch 65: val_loss improved from 0.94396 to 0.91717, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.0872 - accuracy: 0.6381 - val_loss: 0.9172 - val_accuracy: 0.7006\n",
            "Epoch 66/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 1.0808 - accuracy: 0.6420\n",
            "Epoch 66: val_loss did not improve from 0.91717\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.0798 - accuracy: 0.6425 - val_loss: 0.9308 - val_accuracy: 0.6972\n",
            "Epoch 67/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 1.0663 - accuracy: 0.6460\n",
            "Epoch 67: val_loss did not improve from 0.91717\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.0663 - accuracy: 0.6460 - val_loss: 0.9330 - val_accuracy: 0.7069\n",
            "Epoch 68/400\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 1.1017 - accuracy: 0.6381\n",
            "Epoch 68: val_loss did not improve from 0.91717\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.0988 - accuracy: 0.6387 - val_loss: 0.9194 - val_accuracy: 0.6898\n",
            "Epoch 69/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 1.0661 - accuracy: 0.6437\n",
            "Epoch 69: val_loss improved from 0.91717 to 0.90679, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 1.0636 - accuracy: 0.6448 - val_loss: 0.9068 - val_accuracy: 0.7092\n",
            "Epoch 70/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 1.0668 - accuracy: 0.6489\n",
            "Epoch 70: val_loss did not improve from 0.90679\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 1.0687 - accuracy: 0.6484 - val_loss: 0.9320 - val_accuracy: 0.6949\n",
            "Epoch 71/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 1.0573 - accuracy: 0.6516\n",
            "Epoch 71: val_loss improved from 0.90679 to 0.89030, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 1.0562 - accuracy: 0.6517 - val_loss: 0.8903 - val_accuracy: 0.7218\n",
            "Epoch 72/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 1.0568 - accuracy: 0.6541\n",
            "Epoch 72: val_loss did not improve from 0.89030\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 1.0549 - accuracy: 0.6557 - val_loss: 0.9250 - val_accuracy: 0.6926\n",
            "Epoch 73/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 1.0423 - accuracy: 0.6576\n",
            "Epoch 73: val_loss did not improve from 0.89030\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.0445 - accuracy: 0.6577 - val_loss: 0.9052 - val_accuracy: 0.7115\n",
            "Epoch 74/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 1.0580 - accuracy: 0.6533\n",
            "Epoch 74: val_loss did not improve from 0.89030\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.0587 - accuracy: 0.6527 - val_loss: 0.9105 - val_accuracy: 0.7023\n",
            "Epoch 75/400\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 1.0313 - accuracy: 0.6570\n",
            "Epoch 75: val_loss improved from 0.89030 to 0.87434, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 1.0317 - accuracy: 0.6563 - val_loss: 0.8743 - val_accuracy: 0.7104\n",
            "Epoch 76/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 1.0511 - accuracy: 0.6565\n",
            "Epoch 76: val_loss did not improve from 0.87434\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 1.0491 - accuracy: 0.6551 - val_loss: 0.9021 - val_accuracy: 0.7041\n",
            "Epoch 77/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 1.0503 - accuracy: 0.6533\n",
            "Epoch 77: val_loss did not improve from 0.87434\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.0472 - accuracy: 0.6554 - val_loss: 0.9017 - val_accuracy: 0.7075\n",
            "Epoch 78/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 1.0452 - accuracy: 0.6551\n",
            "Epoch 78: val_loss improved from 0.87434 to 0.86854, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.0452 - accuracy: 0.6551 - val_loss: 0.8685 - val_accuracy: 0.7298\n",
            "Epoch 79/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 1.0303 - accuracy: 0.6646\n",
            "Epoch 79: val_loss did not improve from 0.86854\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.0306 - accuracy: 0.6646 - val_loss: 0.8708 - val_accuracy: 0.7161\n",
            "Epoch 80/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 1.0204 - accuracy: 0.6661\n",
            "Epoch 80: val_loss did not improve from 0.86854\n",
            "219/219 [==============================] - 2s 8ms/step - loss: 1.0200 - accuracy: 0.6659 - val_loss: 0.8748 - val_accuracy: 0.7155\n",
            "Epoch 81/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 1.0307 - accuracy: 0.6558\n",
            "Epoch 81: val_loss did not improve from 0.86854\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 1.0316 - accuracy: 0.6545 - val_loss: 0.8769 - val_accuracy: 0.7212\n",
            "Epoch 82/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 1.0226 - accuracy: 0.6630\n",
            "Epoch 82: val_loss improved from 0.86854 to 0.85232, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.0202 - accuracy: 0.6630 - val_loss: 0.8523 - val_accuracy: 0.7218\n",
            "Epoch 83/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 1.0419 - accuracy: 0.6589\n",
            "Epoch 83: val_loss did not improve from 0.85232\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.0427 - accuracy: 0.6583 - val_loss: 0.8819 - val_accuracy: 0.7241\n",
            "Epoch 84/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 1.0262 - accuracy: 0.6652\n",
            "Epoch 84: val_loss improved from 0.85232 to 0.85226, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.0276 - accuracy: 0.6654 - val_loss: 0.8523 - val_accuracy: 0.7281\n",
            "Epoch 85/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 1.0102 - accuracy: 0.6730\n",
            "Epoch 85: val_loss did not improve from 0.85226\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.0135 - accuracy: 0.6727 - val_loss: 0.8768 - val_accuracy: 0.7001\n",
            "Epoch 86/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 1.0253 - accuracy: 0.6557\n",
            "Epoch 86: val_loss did not improve from 0.85226\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.0218 - accuracy: 0.6568 - val_loss: 0.8614 - val_accuracy: 0.7384\n",
            "Epoch 87/400\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 1.0250 - accuracy: 0.6611\n",
            "Epoch 87: val_loss did not improve from 0.85226\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.0190 - accuracy: 0.6654 - val_loss: 0.8680 - val_accuracy: 0.7149\n",
            "Epoch 88/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 1.0130 - accuracy: 0.6656\n",
            "Epoch 88: val_loss did not improve from 0.85226\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.0135 - accuracy: 0.6656 - val_loss: 0.8644 - val_accuracy: 0.7218\n",
            "Epoch 89/400\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 1.0088 - accuracy: 0.6613\n",
            "Epoch 89: val_loss improved from 0.85226 to 0.85025, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.0153 - accuracy: 0.6608 - val_loss: 0.8503 - val_accuracy: 0.7344\n",
            "Epoch 90/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 1.0017 - accuracy: 0.6702\n",
            "Epoch 90: val_loss improved from 0.85025 to 0.83289, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.0038 - accuracy: 0.6702 - val_loss: 0.8329 - val_accuracy: 0.7476\n",
            "Epoch 91/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 1.0011 - accuracy: 0.6697\n",
            "Epoch 91: val_loss did not improve from 0.83289\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.0011 - accuracy: 0.6697 - val_loss: 0.8514 - val_accuracy: 0.7298\n",
            "Epoch 92/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 1.0154 - accuracy: 0.6669\n",
            "Epoch 92: val_loss did not improve from 0.83289\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.0173 - accuracy: 0.6660 - val_loss: 0.8660 - val_accuracy: 0.7241\n",
            "Epoch 93/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.9996 - accuracy: 0.6706\n",
            "Epoch 93: val_loss did not improve from 0.83289\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.0004 - accuracy: 0.6700 - val_loss: 0.8748 - val_accuracy: 0.7315\n",
            "Epoch 94/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.9871 - accuracy: 0.6751\n",
            "Epoch 94: val_loss did not improve from 0.83289\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.9877 - accuracy: 0.6749 - val_loss: 0.8398 - val_accuracy: 0.7367\n",
            "Epoch 95/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 1.0058 - accuracy: 0.6734\n",
            "Epoch 95: val_loss did not improve from 0.83289\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 1.0073 - accuracy: 0.6732 - val_loss: 0.8350 - val_accuracy: 0.7350\n",
            "Epoch 96/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.9932 - accuracy: 0.6770\n",
            "Epoch 96: val_loss improved from 0.83289 to 0.81454, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9991 - accuracy: 0.6756 - val_loss: 0.8145 - val_accuracy: 0.7476\n",
            "Epoch 97/400\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 1.0143 - accuracy: 0.6680\n",
            "Epoch 97: val_loss did not improve from 0.81454\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.0224 - accuracy: 0.6660 - val_loss: 0.8908 - val_accuracy: 0.7207\n",
            "Epoch 98/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 1.0032 - accuracy: 0.6722\n",
            "Epoch 98: val_loss did not improve from 0.81454\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.0063 - accuracy: 0.6710 - val_loss: 0.8224 - val_accuracy: 0.7407\n",
            "Epoch 99/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.9744 - accuracy: 0.6825\n",
            "Epoch 99: val_loss improved from 0.81454 to 0.80804, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9711 - accuracy: 0.6842 - val_loss: 0.8080 - val_accuracy: 0.7516\n",
            "Epoch 100/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.9925 - accuracy: 0.6741\n",
            "Epoch 100: val_loss improved from 0.80804 to 0.80660, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9901 - accuracy: 0.6742 - val_loss: 0.8066 - val_accuracy: 0.7401\n",
            "Epoch 101/400\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.9965 - accuracy: 0.6777\n",
            "Epoch 101: val_loss did not improve from 0.80660\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9862 - accuracy: 0.6815 - val_loss: 0.8254 - val_accuracy: 0.7401\n",
            "Epoch 102/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.9716 - accuracy: 0.6753\n",
            "Epoch 102: val_loss did not improve from 0.80660\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9718 - accuracy: 0.6754 - val_loss: 0.8185 - val_accuracy: 0.7390\n",
            "Epoch 103/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.9934 - accuracy: 0.6766\n",
            "Epoch 103: val_loss did not improve from 0.80660\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9932 - accuracy: 0.6764 - val_loss: 0.8393 - val_accuracy: 0.7315\n",
            "Epoch 104/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.9655 - accuracy: 0.6885\n",
            "Epoch 104: val_loss did not improve from 0.80660\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9655 - accuracy: 0.6885 - val_loss: 0.8278 - val_accuracy: 0.7304\n",
            "Epoch 105/400\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.9674 - accuracy: 0.6857\n",
            "Epoch 105: val_loss did not improve from 0.80660\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9644 - accuracy: 0.6868 - val_loss: 0.8105 - val_accuracy: 0.7436\n",
            "Epoch 106/400\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.9701 - accuracy: 0.6845\n",
            "Epoch 106: val_loss did not improve from 0.80660\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9745 - accuracy: 0.6830 - val_loss: 0.8069 - val_accuracy: 0.7327\n",
            "Epoch 107/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.9760 - accuracy: 0.6827\n",
            "Epoch 107: val_loss did not improve from 0.80660\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.9760 - accuracy: 0.6827 - val_loss: 0.8406 - val_accuracy: 0.7396\n",
            "Epoch 108/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.9826 - accuracy: 0.6777\n",
            "Epoch 108: val_loss improved from 0.80660 to 0.79965, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.9814 - accuracy: 0.6785 - val_loss: 0.7996 - val_accuracy: 0.7464\n",
            "Epoch 109/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.9890 - accuracy: 0.6833\n",
            "Epoch 109: val_loss did not improve from 0.79965\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.9859 - accuracy: 0.6838 - val_loss: 0.8031 - val_accuracy: 0.7527\n",
            "Epoch 110/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.9801 - accuracy: 0.6802\n",
            "Epoch 110: val_loss did not improve from 0.79965\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9789 - accuracy: 0.6805 - val_loss: 0.8108 - val_accuracy: 0.7373\n",
            "Epoch 111/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.9765 - accuracy: 0.6835\n",
            "Epoch 111: val_loss improved from 0.79965 to 0.79435, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9737 - accuracy: 0.6836 - val_loss: 0.7943 - val_accuracy: 0.7441\n",
            "Epoch 112/400\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.9715 - accuracy: 0.6877\n",
            "Epoch 112: val_loss did not improve from 0.79435\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9669 - accuracy: 0.6878 - val_loss: 0.8311 - val_accuracy: 0.7384\n",
            "Epoch 113/400\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.9708 - accuracy: 0.6827\n",
            "Epoch 113: val_loss did not improve from 0.79435\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9724 - accuracy: 0.6817 - val_loss: 0.8119 - val_accuracy: 0.7447\n",
            "Epoch 114/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.9833 - accuracy: 0.6800\n",
            "Epoch 114: val_loss did not improve from 0.79435\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9834 - accuracy: 0.6803 - val_loss: 0.8057 - val_accuracy: 0.7493\n",
            "Epoch 115/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.9673 - accuracy: 0.6884\n",
            "Epoch 115: val_loss did not improve from 0.79435\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9631 - accuracy: 0.6896 - val_loss: 0.8478 - val_accuracy: 0.7252\n",
            "Epoch 116/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.9683 - accuracy: 0.6933\n",
            "Epoch 116: val_loss did not improve from 0.79435\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9683 - accuracy: 0.6933 - val_loss: 0.8054 - val_accuracy: 0.7459\n",
            "Epoch 117/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.9576 - accuracy: 0.6859\n",
            "Epoch 117: val_loss improved from 0.79435 to 0.79261, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9555 - accuracy: 0.6876 - val_loss: 0.7926 - val_accuracy: 0.7499\n",
            "Epoch 118/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.9645 - accuracy: 0.6843\n",
            "Epoch 118: val_loss improved from 0.79261 to 0.78710, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9620 - accuracy: 0.6846 - val_loss: 0.7871 - val_accuracy: 0.7619\n",
            "Epoch 119/400\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.9499 - accuracy: 0.6907\n",
            "Epoch 119: val_loss did not improve from 0.78710\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9527 - accuracy: 0.6886 - val_loss: 0.8124 - val_accuracy: 0.7418\n",
            "Epoch 120/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.9589 - accuracy: 0.6884\n",
            "Epoch 120: val_loss did not improve from 0.78710\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.9586 - accuracy: 0.6883 - val_loss: 0.8091 - val_accuracy: 0.7436\n",
            "Epoch 121/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.9456 - accuracy: 0.6912\n",
            "Epoch 121: val_loss did not improve from 0.78710\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.9486 - accuracy: 0.6906 - val_loss: 0.7944 - val_accuracy: 0.7573\n",
            "Epoch 122/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.9581 - accuracy: 0.6942\n",
            "Epoch 122: val_loss did not improve from 0.78710\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.9552 - accuracy: 0.6945 - val_loss: 0.8214 - val_accuracy: 0.7476\n",
            "Epoch 123/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.9584 - accuracy: 0.6856\n",
            "Epoch 123: val_loss improved from 0.78710 to 0.78547, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.9569 - accuracy: 0.6870 - val_loss: 0.7855 - val_accuracy: 0.7613\n",
            "Epoch 124/400\n",
            "204/219 [==========================>...] - ETA: 0s - loss: 0.9509 - accuracy: 0.6939\n",
            "Epoch 124: val_loss did not improve from 0.78547\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9517 - accuracy: 0.6939 - val_loss: 0.8090 - val_accuracy: 0.7424\n",
            "Epoch 125/400\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.9856 - accuracy: 0.6738\n",
            "Epoch 125: val_loss did not improve from 0.78547\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9850 - accuracy: 0.6732 - val_loss: 0.8243 - val_accuracy: 0.7350\n",
            "Epoch 126/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.9648 - accuracy: 0.6820\n",
            "Epoch 126: val_loss improved from 0.78547 to 0.77643, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9633 - accuracy: 0.6820 - val_loss: 0.7764 - val_accuracy: 0.7579\n",
            "Epoch 127/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.9854 - accuracy: 0.6805\n",
            "Epoch 127: val_loss did not improve from 0.77643\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9856 - accuracy: 0.6805 - val_loss: 0.8380 - val_accuracy: 0.7424\n",
            "Epoch 128/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.9574 - accuracy: 0.6897\n",
            "Epoch 128: val_loss did not improve from 0.77643\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9589 - accuracy: 0.6896 - val_loss: 0.7924 - val_accuracy: 0.7533\n",
            "Epoch 129/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.9639 - accuracy: 0.6868\n",
            "Epoch 129: val_loss did not improve from 0.77643\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9674 - accuracy: 0.6863 - val_loss: 0.8148 - val_accuracy: 0.7436\n",
            "Epoch 130/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.9625 - accuracy: 0.6866\n",
            "Epoch 130: val_loss did not improve from 0.77643\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9634 - accuracy: 0.6860 - val_loss: 0.7813 - val_accuracy: 0.7544\n",
            "Epoch 131/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.9703 - accuracy: 0.6838\n",
            "Epoch 131: val_loss did not improve from 0.77643\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9674 - accuracy: 0.6848 - val_loss: 0.7843 - val_accuracy: 0.7590\n",
            "Epoch 132/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.9357 - accuracy: 0.6950\n",
            "Epoch 132: val_loss improved from 0.77643 to 0.76365, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9329 - accuracy: 0.6963 - val_loss: 0.7637 - val_accuracy: 0.7739\n",
            "Epoch 133/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.9232 - accuracy: 0.6972\n",
            "Epoch 133: val_loss did not improve from 0.76365\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9189 - accuracy: 0.6985 - val_loss: 0.7744 - val_accuracy: 0.7647\n",
            "Epoch 134/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.9530 - accuracy: 0.6925\n",
            "Epoch 134: val_loss did not improve from 0.76365\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.9551 - accuracy: 0.6929 - val_loss: 0.7840 - val_accuracy: 0.7584\n",
            "Epoch 135/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.9616 - accuracy: 0.6814\n",
            "Epoch 135: val_loss did not improve from 0.76365\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.9619 - accuracy: 0.6813 - val_loss: 0.8012 - val_accuracy: 0.7476\n",
            "Epoch 136/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.9488 - accuracy: 0.6851\n",
            "Epoch 136: val_loss did not improve from 0.76365\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.9454 - accuracy: 0.6869 - val_loss: 0.7834 - val_accuracy: 0.7550\n",
            "Epoch 137/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.9434 - accuracy: 0.6970\n",
            "Epoch 137: val_loss did not improve from 0.76365\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9428 - accuracy: 0.6969 - val_loss: 0.7771 - val_accuracy: 0.7579\n",
            "Epoch 138/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.9519 - accuracy: 0.6889\n",
            "Epoch 138: val_loss did not improve from 0.76365\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9519 - accuracy: 0.6889 - val_loss: 0.7706 - val_accuracy: 0.7630\n",
            "Epoch 139/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.9374 - accuracy: 0.6945\n",
            "Epoch 139: val_loss did not improve from 0.76365\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9379 - accuracy: 0.6958 - val_loss: 0.7748 - val_accuracy: 0.7613\n",
            "Epoch 140/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.9280 - accuracy: 0.6984\n",
            "Epoch 140: val_loss did not improve from 0.76365\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9280 - accuracy: 0.6984 - val_loss: 0.7797 - val_accuracy: 0.7556\n",
            "Epoch 141/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.9314 - accuracy: 0.6920\n",
            "Epoch 141: val_loss did not improve from 0.76365\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9355 - accuracy: 0.6902 - val_loss: 0.7713 - val_accuracy: 0.7567\n",
            "Epoch 142/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.9212 - accuracy: 0.6924\n",
            "Epoch 142: val_loss did not improve from 0.76365\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9222 - accuracy: 0.6929 - val_loss: 0.8116 - val_accuracy: 0.7459\n",
            "Epoch 143/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.9359 - accuracy: 0.6978\n",
            "Epoch 143: val_loss did not improve from 0.76365\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9370 - accuracy: 0.6974 - val_loss: 0.7883 - val_accuracy: 0.7584\n",
            "Epoch 144/400\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.9422 - accuracy: 0.6914\n",
            "Epoch 144: val_loss did not improve from 0.76365\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9433 - accuracy: 0.6911 - val_loss: 0.7778 - val_accuracy: 0.7579\n",
            "Epoch 145/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.9435 - accuracy: 0.6885\n",
            "Epoch 145: val_loss did not improve from 0.76365\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9448 - accuracy: 0.6888 - val_loss: 0.7794 - val_accuracy: 0.7670\n",
            "Epoch 146/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.9161 - accuracy: 0.7035\n",
            "Epoch 146: val_loss improved from 0.76365 to 0.76090, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9136 - accuracy: 0.7038 - val_loss: 0.7609 - val_accuracy: 0.7584\n",
            "Epoch 147/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.9243 - accuracy: 0.6938\n",
            "Epoch 147: val_loss did not improve from 0.76090\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.9257 - accuracy: 0.6932 - val_loss: 0.7730 - val_accuracy: 0.7567\n",
            "Epoch 148/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.9289 - accuracy: 0.6957\n",
            "Epoch 148: val_loss did not improve from 0.76090\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.9288 - accuracy: 0.6955 - val_loss: 0.7972 - val_accuracy: 0.7521\n",
            "Epoch 149/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.9277 - accuracy: 0.7004\n",
            "Epoch 149: val_loss did not improve from 0.76090\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.9262 - accuracy: 0.6999 - val_loss: 0.7771 - val_accuracy: 0.7590\n",
            "Epoch 150/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.9549 - accuracy: 0.6916\n",
            "Epoch 150: val_loss did not improve from 0.76090\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9587 - accuracy: 0.6905 - val_loss: 0.7851 - val_accuracy: 0.7653\n",
            "Epoch 151/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.9559 - accuracy: 0.6854\n",
            "Epoch 151: val_loss did not improve from 0.76090\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9553 - accuracy: 0.6859 - val_loss: 0.7985 - val_accuracy: 0.7516\n",
            "Epoch 152/400\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.9170 - accuracy: 0.7004\n",
            "Epoch 152: val_loss improved from 0.76090 to 0.74504, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9174 - accuracy: 0.6996 - val_loss: 0.7450 - val_accuracy: 0.7716\n",
            "Epoch 153/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.9393 - accuracy: 0.6866\n",
            "Epoch 153: val_loss improved from 0.74504 to 0.74494, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.9386 - accuracy: 0.6869 - val_loss: 0.7449 - val_accuracy: 0.7733\n",
            "Epoch 154/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.9238 - accuracy: 0.6987\n",
            "Epoch 154: val_loss did not improve from 0.74494\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9212 - accuracy: 0.6994 - val_loss: 0.7550 - val_accuracy: 0.7699\n",
            "Epoch 155/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.9193 - accuracy: 0.6984\n",
            "Epoch 155: val_loss did not improve from 0.74494\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9187 - accuracy: 0.6994 - val_loss: 0.7586 - val_accuracy: 0.7699\n",
            "Epoch 156/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.9345 - accuracy: 0.6979\n",
            "Epoch 156: val_loss did not improve from 0.74494\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9342 - accuracy: 0.6978 - val_loss: 0.7875 - val_accuracy: 0.7630\n",
            "Epoch 157/400\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.9329 - accuracy: 0.6974\n",
            "Epoch 157: val_loss did not improve from 0.74494\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9357 - accuracy: 0.6971 - val_loss: 0.7777 - val_accuracy: 0.7602\n",
            "Epoch 158/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.9333 - accuracy: 0.6962\n",
            "Epoch 158: val_loss did not improve from 0.74494\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9320 - accuracy: 0.6963 - val_loss: 0.7717 - val_accuracy: 0.7676\n",
            "Epoch 159/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.9400 - accuracy: 0.6967\n",
            "Epoch 159: val_loss did not improve from 0.74494\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9345 - accuracy: 0.6994 - val_loss: 0.7813 - val_accuracy: 0.7556\n",
            "Epoch 160/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.9348 - accuracy: 0.6990\n",
            "Epoch 160: val_loss did not improve from 0.74494\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.9347 - accuracy: 0.6992 - val_loss: 0.7718 - val_accuracy: 0.7607\n",
            "Epoch 161/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.9068 - accuracy: 0.7043\n",
            "Epoch 161: val_loss improved from 0.74494 to 0.72793, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.9087 - accuracy: 0.7032 - val_loss: 0.7279 - val_accuracy: 0.7733\n",
            "Epoch 162/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.9459 - accuracy: 0.6957\n",
            "Epoch 162: val_loss did not improve from 0.72793\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.9425 - accuracy: 0.6969 - val_loss: 0.7391 - val_accuracy: 0.7745\n",
            "Epoch 163/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.9342 - accuracy: 0.7002\n",
            "Epoch 163: val_loss did not improve from 0.72793\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9337 - accuracy: 0.7002 - val_loss: 0.7915 - val_accuracy: 0.7607\n",
            "Epoch 164/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.9325 - accuracy: 0.7004\n",
            "Epoch 164: val_loss did not improve from 0.72793\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9344 - accuracy: 0.7002 - val_loss: 0.7675 - val_accuracy: 0.7590\n",
            "Epoch 165/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.9046 - accuracy: 0.7076\n",
            "Epoch 165: val_loss did not improve from 0.72793\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9033 - accuracy: 0.7078 - val_loss: 0.7441 - val_accuracy: 0.7773\n",
            "Epoch 166/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.9241 - accuracy: 0.6995\n",
            "Epoch 166: val_loss did not improve from 0.72793\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9240 - accuracy: 0.6995 - val_loss: 0.7852 - val_accuracy: 0.7510\n",
            "Epoch 167/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.9353 - accuracy: 0.6976\n",
            "Epoch 167: val_loss did not improve from 0.72793\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9350 - accuracy: 0.6976 - val_loss: 0.7519 - val_accuracy: 0.7876\n",
            "Epoch 168/400\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.9154 - accuracy: 0.7015\n",
            "Epoch 168: val_loss did not improve from 0.72793\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9151 - accuracy: 0.7021 - val_loss: 0.7531 - val_accuracy: 0.7607\n",
            "Epoch 169/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.9120 - accuracy: 0.7025\n",
            "Epoch 169: val_loss did not improve from 0.72793\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9155 - accuracy: 0.7021 - val_loss: 0.7600 - val_accuracy: 0.7636\n",
            "Epoch 170/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.9034 - accuracy: 0.7061\n",
            "Epoch 170: val_loss did not improve from 0.72793\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9041 - accuracy: 0.7059 - val_loss: 0.7726 - val_accuracy: 0.7687\n",
            "Epoch 171/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.9036 - accuracy: 0.7001\n",
            "Epoch 171: val_loss did not improve from 0.72793\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9044 - accuracy: 0.7008 - val_loss: 0.7389 - val_accuracy: 0.7699\n",
            "Epoch 172/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.9249 - accuracy: 0.7015\n",
            "Epoch 172: val_loss did not improve from 0.72793\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9247 - accuracy: 0.7016 - val_loss: 0.7428 - val_accuracy: 0.7728\n",
            "Epoch 173/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.9102 - accuracy: 0.7013\n",
            "Epoch 173: val_loss did not improve from 0.72793\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.9103 - accuracy: 0.7014 - val_loss: 0.7704 - val_accuracy: 0.7579\n",
            "Epoch 174/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.9249 - accuracy: 0.6976\n",
            "Epoch 174: val_loss did not improve from 0.72793\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.9249 - accuracy: 0.6976 - val_loss: 0.7852 - val_accuracy: 0.7556\n",
            "Epoch 175/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.9204 - accuracy: 0.6976\n",
            "Epoch 175: val_loss did not improve from 0.72793\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.9210 - accuracy: 0.6974 - val_loss: 0.7544 - val_accuracy: 0.7584\n",
            "Epoch 176/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.9402 - accuracy: 0.6957\n",
            "Epoch 176: val_loss did not improve from 0.72793\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9402 - accuracy: 0.6958 - val_loss: 0.7687 - val_accuracy: 0.7785\n",
            "Epoch 177/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.9115 - accuracy: 0.7089\n",
            "Epoch 177: val_loss improved from 0.72793 to 0.71894, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.9188 - accuracy: 0.7074 - val_loss: 0.7189 - val_accuracy: 0.7779\n",
            "Epoch 178/400\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.9000 - accuracy: 0.7037\n",
            "Epoch 178: val_loss did not improve from 0.71894\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8951 - accuracy: 0.7052 - val_loss: 0.7332 - val_accuracy: 0.7733\n",
            "Epoch 179/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.9088 - accuracy: 0.7079\n",
            "Epoch 179: val_loss did not improve from 0.71894\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9099 - accuracy: 0.7077 - val_loss: 0.7481 - val_accuracy: 0.7613\n",
            "Epoch 180/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.9108 - accuracy: 0.7106\n",
            "Epoch 180: val_loss did not improve from 0.71894\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9104 - accuracy: 0.7099 - val_loss: 0.7224 - val_accuracy: 0.7779\n",
            "Epoch 181/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.9452 - accuracy: 0.6996\n",
            "Epoch 181: val_loss did not improve from 0.71894\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9448 - accuracy: 0.6998 - val_loss: 0.7505 - val_accuracy: 0.7596\n",
            "Epoch 182/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.8971 - accuracy: 0.7099\n",
            "Epoch 182: val_loss did not improve from 0.71894\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9021 - accuracy: 0.7084 - val_loss: 0.7453 - val_accuracy: 0.7745\n",
            "Epoch 183/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.9164 - accuracy: 0.7029\n",
            "Epoch 183: val_loss did not improve from 0.71894\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9133 - accuracy: 0.7034 - val_loss: 0.7359 - val_accuracy: 0.7699\n",
            "Epoch 184/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.8999 - accuracy: 0.7073\n",
            "Epoch 184: val_loss did not improve from 0.71894\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9021 - accuracy: 0.7062 - val_loss: 0.7416 - val_accuracy: 0.7550\n",
            "Epoch 185/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.8945 - accuracy: 0.7107\n",
            "Epoch 185: val_loss did not improve from 0.71894\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8999 - accuracy: 0.7087 - val_loss: 0.7584 - val_accuracy: 0.7699\n",
            "Epoch 186/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.9123 - accuracy: 0.7057\n",
            "Epoch 186: val_loss did not improve from 0.71894\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.9124 - accuracy: 0.7059 - val_loss: 0.7386 - val_accuracy: 0.7682\n",
            "Epoch 187/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.9114 - accuracy: 0.7107\n",
            "Epoch 187: val_loss did not improve from 0.71894\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.9116 - accuracy: 0.7107 - val_loss: 0.7767 - val_accuracy: 0.7607\n",
            "Epoch 188/400\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 0.9057 - accuracy: 0.7110\n",
            "Epoch 188: val_loss did not improve from 0.71894\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.9095 - accuracy: 0.7088 - val_loss: 0.7337 - val_accuracy: 0.7802\n",
            "Epoch 189/400\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.9018 - accuracy: 0.7054\n",
            "Epoch 189: val_loss did not improve from 0.71894\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9000 - accuracy: 0.7062 - val_loss: 0.7472 - val_accuracy: 0.7728\n",
            "Epoch 190/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.8972 - accuracy: 0.7049\n",
            "Epoch 190: val_loss did not improve from 0.71894\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8993 - accuracy: 0.7048 - val_loss: 0.7356 - val_accuracy: 0.7699\n",
            "Epoch 191/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.8965 - accuracy: 0.7065\n",
            "Epoch 191: val_loss did not improve from 0.71894\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8947 - accuracy: 0.7072 - val_loss: 0.7417 - val_accuracy: 0.7665\n",
            "Epoch 192/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.9020 - accuracy: 0.7068\n",
            "Epoch 192: val_loss did not improve from 0.71894\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9060 - accuracy: 0.7055 - val_loss: 0.7328 - val_accuracy: 0.7745\n",
            "Epoch 193/400\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.9150 - accuracy: 0.7121\n",
            "Epoch 193: val_loss did not improve from 0.71894\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9108 - accuracy: 0.7138 - val_loss: 0.7384 - val_accuracy: 0.7642\n",
            "Epoch 194/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.8994 - accuracy: 0.7033\n",
            "Epoch 194: val_loss did not improve from 0.71894\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8988 - accuracy: 0.7037 - val_loss: 0.7280 - val_accuracy: 0.7659\n",
            "Epoch 195/400\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.9023 - accuracy: 0.7065\n",
            "Epoch 195: val_loss did not improve from 0.71894\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9010 - accuracy: 0.7071 - val_loss: 0.7349 - val_accuracy: 0.7602\n",
            "Epoch 196/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.8950 - accuracy: 0.7096\n",
            "Epoch 196: val_loss did not improve from 0.71894\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8974 - accuracy: 0.7085 - val_loss: 0.8000 - val_accuracy: 0.7424\n",
            "Epoch 197/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.9276 - accuracy: 0.7033\n",
            "Epoch 197: val_loss did not improve from 0.71894\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9289 - accuracy: 0.7026 - val_loss: 0.7352 - val_accuracy: 0.7665\n",
            "Epoch 198/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.9005 - accuracy: 0.7067\n",
            "Epoch 198: val_loss did not improve from 0.71894\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8998 - accuracy: 0.7065 - val_loss: 0.7512 - val_accuracy: 0.7687\n",
            "Epoch 199/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.8907 - accuracy: 0.7050\n",
            "Epoch 199: val_loss did not improve from 0.71894\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8950 - accuracy: 0.7035 - val_loss: 0.7518 - val_accuracy: 0.7670\n",
            "Epoch 200/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.8904 - accuracy: 0.7052\n",
            "Epoch 200: val_loss did not improve from 0.71894\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8945 - accuracy: 0.7039 - val_loss: 0.7511 - val_accuracy: 0.7647\n",
            "Epoch 201/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8863 - accuracy: 0.7097\n",
            "Epoch 201: val_loss did not improve from 0.71894\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8866 - accuracy: 0.7097 - val_loss: 0.7508 - val_accuracy: 0.7716\n",
            "Epoch 202/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.9109 - accuracy: 0.7029\n",
            "Epoch 202: val_loss did not improve from 0.71894\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9088 - accuracy: 0.7034 - val_loss: 0.7238 - val_accuracy: 0.7859\n",
            "Epoch 203/400\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.9026 - accuracy: 0.7003\n",
            "Epoch 203: val_loss did not improve from 0.71894\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9012 - accuracy: 0.7008 - val_loss: 0.7381 - val_accuracy: 0.7733\n",
            "Epoch 204/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.8971 - accuracy: 0.7109\n",
            "Epoch 204: val_loss improved from 0.71894 to 0.71515, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8947 - accuracy: 0.7112 - val_loss: 0.7152 - val_accuracy: 0.7790\n",
            "Epoch 205/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.9204 - accuracy: 0.7055\n",
            "Epoch 205: val_loss did not improve from 0.71515\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9160 - accuracy: 0.7065 - val_loss: 0.7538 - val_accuracy: 0.7699\n",
            "Epoch 206/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.9209 - accuracy: 0.7013\n",
            "Epoch 206: val_loss did not improve from 0.71515\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9234 - accuracy: 0.7006 - val_loss: 0.7254 - val_accuracy: 0.7802\n",
            "Epoch 207/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.8995 - accuracy: 0.7048\n",
            "Epoch 207: val_loss improved from 0.71515 to 0.70026, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8995 - accuracy: 0.7048 - val_loss: 0.7003 - val_accuracy: 0.7836\n",
            "Epoch 208/400\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.9015 - accuracy: 0.7041\n",
            "Epoch 208: val_loss did not improve from 0.70026\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9110 - accuracy: 0.7031 - val_loss: 0.7476 - val_accuracy: 0.7699\n",
            "Epoch 209/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.9003 - accuracy: 0.7055\n",
            "Epoch 209: val_loss did not improve from 0.70026\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8988 - accuracy: 0.7069 - val_loss: 0.7299 - val_accuracy: 0.7808\n",
            "Epoch 210/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.8883 - accuracy: 0.7090\n",
            "Epoch 210: val_loss did not improve from 0.70026\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8890 - accuracy: 0.7088 - val_loss: 0.7233 - val_accuracy: 0.7779\n",
            "Epoch 211/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.8914 - accuracy: 0.7092\n",
            "Epoch 211: val_loss did not improve from 0.70026\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8911 - accuracy: 0.7082 - val_loss: 0.7428 - val_accuracy: 0.7722\n",
            "Epoch 212/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8885 - accuracy: 0.7126\n",
            "Epoch 212: val_loss did not improve from 0.70026\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8886 - accuracy: 0.7125 - val_loss: 0.7367 - val_accuracy: 0.7728\n",
            "Epoch 213/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.9041 - accuracy: 0.7054\n",
            "Epoch 213: val_loss did not improve from 0.70026\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.9041 - accuracy: 0.7054 - val_loss: 0.7187 - val_accuracy: 0.7739\n",
            "Epoch 214/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.9208 - accuracy: 0.7053\n",
            "Epoch 214: val_loss did not improve from 0.70026\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.9213 - accuracy: 0.7051 - val_loss: 0.7228 - val_accuracy: 0.7813\n",
            "Epoch 215/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.8939 - accuracy: 0.7120\n",
            "Epoch 215: val_loss did not improve from 0.70026\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8953 - accuracy: 0.7117 - val_loss: 0.7322 - val_accuracy: 0.7762\n",
            "Epoch 216/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.8800 - accuracy: 0.7148\n",
            "Epoch 216: val_loss did not improve from 0.70026\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8765 - accuracy: 0.7154 - val_loss: 0.7126 - val_accuracy: 0.7882\n",
            "Epoch 217/400\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.8933 - accuracy: 0.7132\n",
            "Epoch 217: val_loss did not improve from 0.70026\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8964 - accuracy: 0.7122 - val_loss: 0.7361 - val_accuracy: 0.7796\n",
            "Epoch 218/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.9102 - accuracy: 0.7019\n",
            "Epoch 218: val_loss did not improve from 0.70026\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.9096 - accuracy: 0.7016 - val_loss: 0.7071 - val_accuracy: 0.7808\n",
            "Epoch 219/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.8926 - accuracy: 0.7084\n",
            "Epoch 219: val_loss did not improve from 0.70026\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8926 - accuracy: 0.7075 - val_loss: 0.7237 - val_accuracy: 0.7733\n",
            "Epoch 220/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.9106 - accuracy: 0.7035\n",
            "Epoch 220: val_loss did not improve from 0.70026\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9072 - accuracy: 0.7042 - val_loss: 0.7319 - val_accuracy: 0.7756\n",
            "Epoch 221/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.9002 - accuracy: 0.7124\n",
            "Epoch 221: val_loss did not improve from 0.70026\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8969 - accuracy: 0.7132 - val_loss: 0.7309 - val_accuracy: 0.7687\n",
            "Epoch 222/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.8963 - accuracy: 0.7094\n",
            "Epoch 222: val_loss did not improve from 0.70026\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8937 - accuracy: 0.7087 - val_loss: 0.7081 - val_accuracy: 0.7705\n",
            "Epoch 223/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.8941 - accuracy: 0.7079\n",
            "Epoch 223: val_loss did not improve from 0.70026\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8966 - accuracy: 0.7058 - val_loss: 0.7279 - val_accuracy: 0.7756\n",
            "Epoch 224/400\n",
            "204/219 [==========================>...] - ETA: 0s - loss: 0.8982 - accuracy: 0.7091\n",
            "Epoch 224: val_loss improved from 0.70026 to 0.70017, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9001 - accuracy: 0.7107 - val_loss: 0.7002 - val_accuracy: 0.7813\n",
            "Epoch 225/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.9067 - accuracy: 0.7045\n",
            "Epoch 225: val_loss did not improve from 0.70017\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.9047 - accuracy: 0.7058 - val_loss: 0.7308 - val_accuracy: 0.7642\n",
            "Epoch 226/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8818 - accuracy: 0.7173\n",
            "Epoch 226: val_loss did not improve from 0.70017\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8825 - accuracy: 0.7171 - val_loss: 0.7085 - val_accuracy: 0.7836\n",
            "Epoch 227/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.9008 - accuracy: 0.7117\n",
            "Epoch 227: val_loss did not improve from 0.70017\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.9011 - accuracy: 0.7112 - val_loss: 0.7289 - val_accuracy: 0.7710\n",
            "Epoch 228/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.8923 - accuracy: 0.7110\n",
            "Epoch 228: val_loss did not improve from 0.70017\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8883 - accuracy: 0.7125 - val_loss: 0.7331 - val_accuracy: 0.7659\n",
            "Epoch 229/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.8910 - accuracy: 0.7029\n",
            "Epoch 229: val_loss did not improve from 0.70017\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8910 - accuracy: 0.7029 - val_loss: 0.7291 - val_accuracy: 0.7659\n",
            "Epoch 230/400\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.9075 - accuracy: 0.7114\n",
            "Epoch 230: val_loss did not improve from 0.70017\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.9086 - accuracy: 0.7111 - val_loss: 0.7304 - val_accuracy: 0.7779\n",
            "Epoch 231/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.9009 - accuracy: 0.7091\n",
            "Epoch 231: val_loss did not improve from 0.70017\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.9007 - accuracy: 0.7094 - val_loss: 0.7188 - val_accuracy: 0.7813\n",
            "Epoch 232/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8783 - accuracy: 0.7155\n",
            "Epoch 232: val_loss improved from 0.70017 to 0.69967, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8775 - accuracy: 0.7157 - val_loss: 0.6997 - val_accuracy: 0.7802\n",
            "Epoch 233/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.8777 - accuracy: 0.7147\n",
            "Epoch 233: val_loss did not improve from 0.69967\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8760 - accuracy: 0.7155 - val_loss: 0.7008 - val_accuracy: 0.7876\n",
            "Epoch 234/400\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.8783 - accuracy: 0.7171\n",
            "Epoch 234: val_loss did not improve from 0.69967\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8828 - accuracy: 0.7145 - val_loss: 0.7336 - val_accuracy: 0.7836\n",
            "Epoch 235/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.9147 - accuracy: 0.7024\n",
            "Epoch 235: val_loss did not improve from 0.69967\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9139 - accuracy: 0.7026 - val_loss: 0.7209 - val_accuracy: 0.7808\n",
            "Epoch 236/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.8915 - accuracy: 0.7198\n",
            "Epoch 236: val_loss did not improve from 0.69967\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8900 - accuracy: 0.7194 - val_loss: 0.7200 - val_accuracy: 0.7859\n",
            "Epoch 237/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.8867 - accuracy: 0.7091\n",
            "Epoch 237: val_loss did not improve from 0.69967\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8827 - accuracy: 0.7111 - val_loss: 0.7097 - val_accuracy: 0.7779\n",
            "Epoch 238/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8877 - accuracy: 0.7103\n",
            "Epoch 238: val_loss did not improve from 0.69967\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8873 - accuracy: 0.7104 - val_loss: 0.7316 - val_accuracy: 0.7722\n",
            "Epoch 239/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.8897 - accuracy: 0.7148\n",
            "Epoch 239: val_loss did not improve from 0.69967\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.8927 - accuracy: 0.7142 - val_loss: 0.7132 - val_accuracy: 0.7790\n",
            "Epoch 240/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8951 - accuracy: 0.7086\n",
            "Epoch 240: val_loss improved from 0.69967 to 0.69885, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.8949 - accuracy: 0.7087 - val_loss: 0.6989 - val_accuracy: 0.7831\n",
            "Epoch 241/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.8798 - accuracy: 0.7175\n",
            "Epoch 241: val_loss did not improve from 0.69885\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8798 - accuracy: 0.7175 - val_loss: 0.7246 - val_accuracy: 0.7705\n",
            "Epoch 242/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.8823 - accuracy: 0.7192\n",
            "Epoch 242: val_loss did not improve from 0.69885\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8836 - accuracy: 0.7190 - val_loss: 0.7082 - val_accuracy: 0.7779\n",
            "Epoch 243/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.8810 - accuracy: 0.7106\n",
            "Epoch 243: val_loss did not improve from 0.69885\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8784 - accuracy: 0.7111 - val_loss: 0.7105 - val_accuracy: 0.7768\n",
            "Epoch 244/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.8592 - accuracy: 0.7198\n",
            "Epoch 244: val_loss did not improve from 0.69885\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8680 - accuracy: 0.7180 - val_loss: 0.7012 - val_accuracy: 0.7882\n",
            "Epoch 245/400\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.8986 - accuracy: 0.7079\n",
            "Epoch 245: val_loss did not improve from 0.69885\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8985 - accuracy: 0.7077 - val_loss: 0.7289 - val_accuracy: 0.7693\n",
            "Epoch 246/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.8878 - accuracy: 0.7128\n",
            "Epoch 246: val_loss did not improve from 0.69885\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8878 - accuracy: 0.7128 - val_loss: 0.7006 - val_accuracy: 0.7836\n",
            "Epoch 247/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.8905 - accuracy: 0.7060\n",
            "Epoch 247: val_loss did not improve from 0.69885\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8949 - accuracy: 0.7047 - val_loss: 0.7185 - val_accuracy: 0.7813\n",
            "Epoch 248/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.8939 - accuracy: 0.7094\n",
            "Epoch 248: val_loss did not improve from 0.69885\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8960 - accuracy: 0.7092 - val_loss: 0.7210 - val_accuracy: 0.7705\n",
            "Epoch 249/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8813 - accuracy: 0.7122\n",
            "Epoch 249: val_loss did not improve from 0.69885\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8821 - accuracy: 0.7118 - val_loss: 0.7410 - val_accuracy: 0.7653\n",
            "Epoch 250/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.8785 - accuracy: 0.7128\n",
            "Epoch 250: val_loss did not improve from 0.69885\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8799 - accuracy: 0.7127 - val_loss: 0.7208 - val_accuracy: 0.7762\n",
            "Epoch 251/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.9078 - accuracy: 0.7043\n",
            "Epoch 251: val_loss did not improve from 0.69885\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.9084 - accuracy: 0.7039 - val_loss: 0.7447 - val_accuracy: 0.7739\n",
            "Epoch 252/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.8634 - accuracy: 0.7236\n",
            "Epoch 252: val_loss improved from 0.69885 to 0.69237, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.8650 - accuracy: 0.7233 - val_loss: 0.6924 - val_accuracy: 0.7928\n",
            "Epoch 253/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.8811 - accuracy: 0.7173\n",
            "Epoch 253: val_loss did not improve from 0.69237\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8815 - accuracy: 0.7167 - val_loss: 0.7004 - val_accuracy: 0.7790\n",
            "Epoch 254/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8959 - accuracy: 0.7104\n",
            "Epoch 254: val_loss did not improve from 0.69237\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8949 - accuracy: 0.7108 - val_loss: 0.6972 - val_accuracy: 0.7865\n",
            "Epoch 255/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.8834 - accuracy: 0.7154\n",
            "Epoch 255: val_loss did not improve from 0.69237\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.8849 - accuracy: 0.7148 - val_loss: 0.6956 - val_accuracy: 0.7825\n",
            "Epoch 256/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.8940 - accuracy: 0.7103\n",
            "Epoch 256: val_loss did not improve from 0.69237\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8943 - accuracy: 0.7101 - val_loss: 0.6945 - val_accuracy: 0.7916\n",
            "Epoch 257/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.8655 - accuracy: 0.7189\n",
            "Epoch 257: val_loss did not improve from 0.69237\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8674 - accuracy: 0.7185 - val_loss: 0.7398 - val_accuracy: 0.7745\n",
            "Epoch 258/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.8797 - accuracy: 0.7124\n",
            "Epoch 258: val_loss did not improve from 0.69237\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8789 - accuracy: 0.7121 - val_loss: 0.7174 - val_accuracy: 0.7825\n",
            "Epoch 259/400\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.8802 - accuracy: 0.7204\n",
            "Epoch 259: val_loss did not improve from 0.69237\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8781 - accuracy: 0.7211 - val_loss: 0.7304 - val_accuracy: 0.7762\n",
            "Epoch 260/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.8879 - accuracy: 0.7074\n",
            "Epoch 260: val_loss did not improve from 0.69237\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8866 - accuracy: 0.7075 - val_loss: 0.7294 - val_accuracy: 0.7785\n",
            "Epoch 261/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.8857 - accuracy: 0.7150\n",
            "Epoch 261: val_loss improved from 0.69237 to 0.68937, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8857 - accuracy: 0.7150 - val_loss: 0.6894 - val_accuracy: 0.7796\n",
            "Epoch 262/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.8571 - accuracy: 0.7197\n",
            "Epoch 262: val_loss did not improve from 0.68937\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8571 - accuracy: 0.7197 - val_loss: 0.7088 - val_accuracy: 0.7779\n",
            "Epoch 263/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8907 - accuracy: 0.7137\n",
            "Epoch 263: val_loss did not improve from 0.68937\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8909 - accuracy: 0.7135 - val_loss: 0.7009 - val_accuracy: 0.7802\n",
            "Epoch 264/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8612 - accuracy: 0.7196\n",
            "Epoch 264: val_loss did not improve from 0.68937\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8608 - accuracy: 0.7197 - val_loss: 0.7440 - val_accuracy: 0.7602\n",
            "Epoch 265/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.8700 - accuracy: 0.7233\n",
            "Epoch 265: val_loss did not improve from 0.68937\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8724 - accuracy: 0.7217 - val_loss: 0.7087 - val_accuracy: 0.7825\n",
            "Epoch 266/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.8745 - accuracy: 0.7131\n",
            "Epoch 266: val_loss did not improve from 0.68937\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8776 - accuracy: 0.7125 - val_loss: 0.6997 - val_accuracy: 0.7819\n",
            "Epoch 267/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.8572 - accuracy: 0.7206\n",
            "Epoch 267: val_loss did not improve from 0.68937\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.8567 - accuracy: 0.7208 - val_loss: 0.7047 - val_accuracy: 0.7871\n",
            "Epoch 268/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.8653 - accuracy: 0.7220\n",
            "Epoch 268: val_loss did not improve from 0.68937\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8652 - accuracy: 0.7223 - val_loss: 0.7053 - val_accuracy: 0.7802\n",
            "Epoch 269/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.8864 - accuracy: 0.7110\n",
            "Epoch 269: val_loss did not improve from 0.68937\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8812 - accuracy: 0.7134 - val_loss: 0.7089 - val_accuracy: 0.7848\n",
            "Epoch 270/400\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.8739 - accuracy: 0.7156\n",
            "Epoch 270: val_loss did not improve from 0.68937\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8723 - accuracy: 0.7157 - val_loss: 0.7018 - val_accuracy: 0.7876\n",
            "Epoch 271/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.8772 - accuracy: 0.7193\n",
            "Epoch 271: val_loss did not improve from 0.68937\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8799 - accuracy: 0.7184 - val_loss: 0.7321 - val_accuracy: 0.7802\n",
            "Epoch 272/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.9030 - accuracy: 0.7103\n",
            "Epoch 272: val_loss did not improve from 0.68937\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9016 - accuracy: 0.7107 - val_loss: 0.7247 - val_accuracy: 0.7790\n",
            "Epoch 273/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.8802 - accuracy: 0.7185\n",
            "Epoch 273: val_loss did not improve from 0.68937\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8734 - accuracy: 0.7205 - val_loss: 0.6899 - val_accuracy: 0.7911\n",
            "Epoch 274/400\n",
            "204/219 [==========================>...] - ETA: 0s - loss: 0.8659 - accuracy: 0.7214\n",
            "Epoch 274: val_loss did not improve from 0.68937\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8679 - accuracy: 0.7200 - val_loss: 0.6936 - val_accuracy: 0.7899\n",
            "Epoch 275/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.8795 - accuracy: 0.7179\n",
            "Epoch 275: val_loss improved from 0.68937 to 0.68547, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8807 - accuracy: 0.7173 - val_loss: 0.6855 - val_accuracy: 0.7979\n",
            "Epoch 276/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8794 - accuracy: 0.7146\n",
            "Epoch 276: val_loss did not improve from 0.68547\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8801 - accuracy: 0.7145 - val_loss: 0.7033 - val_accuracy: 0.7945\n",
            "Epoch 277/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.8640 - accuracy: 0.7265\n",
            "Epoch 277: val_loss did not improve from 0.68547\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8717 - accuracy: 0.7234 - val_loss: 0.6931 - val_accuracy: 0.7916\n",
            "Epoch 278/400\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.8714 - accuracy: 0.7144\n",
            "Epoch 278: val_loss did not improve from 0.68547\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8730 - accuracy: 0.7127 - val_loss: 0.7096 - val_accuracy: 0.7842\n",
            "Epoch 279/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.8778 - accuracy: 0.7154\n",
            "Epoch 279: val_loss improved from 0.68547 to 0.68466, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8782 - accuracy: 0.7161 - val_loss: 0.6847 - val_accuracy: 0.7876\n",
            "Epoch 280/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.8959 - accuracy: 0.7122\n",
            "Epoch 280: val_loss did not improve from 0.68466\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8953 - accuracy: 0.7125 - val_loss: 0.7366 - val_accuracy: 0.7808\n",
            "Epoch 281/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.8714 - accuracy: 0.7174\n",
            "Epoch 281: val_loss did not improve from 0.68466\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.8722 - accuracy: 0.7170 - val_loss: 0.6990 - val_accuracy: 0.7865\n",
            "Epoch 282/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.8730 - accuracy: 0.7193\n",
            "Epoch 282: val_loss did not improve from 0.68466\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8739 - accuracy: 0.7194 - val_loss: 0.6969 - val_accuracy: 0.7928\n",
            "Epoch 283/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.8769 - accuracy: 0.7133\n",
            "Epoch 283: val_loss improved from 0.68466 to 0.68227, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8782 - accuracy: 0.7131 - val_loss: 0.6823 - val_accuracy: 0.7956\n",
            "Epoch 284/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8671 - accuracy: 0.7202\n",
            "Epoch 284: val_loss did not improve from 0.68227\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8664 - accuracy: 0.7203 - val_loss: 0.7097 - val_accuracy: 0.7796\n",
            "Epoch 285/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.8709 - accuracy: 0.7218\n",
            "Epoch 285: val_loss did not improve from 0.68227\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8708 - accuracy: 0.7215 - val_loss: 0.7032 - val_accuracy: 0.7836\n",
            "Epoch 286/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.8788 - accuracy: 0.7180\n",
            "Epoch 286: val_loss did not improve from 0.68227\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8800 - accuracy: 0.7174 - val_loss: 0.6987 - val_accuracy: 0.7911\n",
            "Epoch 287/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.8722 - accuracy: 0.7210\n",
            "Epoch 287: val_loss did not improve from 0.68227\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8700 - accuracy: 0.7224 - val_loss: 0.6927 - val_accuracy: 0.7894\n",
            "Epoch 288/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.8756 - accuracy: 0.7190\n",
            "Epoch 288: val_loss did not improve from 0.68227\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8721 - accuracy: 0.7205 - val_loss: 0.6965 - val_accuracy: 0.7831\n",
            "Epoch 289/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8702 - accuracy: 0.7253\n",
            "Epoch 289: val_loss did not improve from 0.68227\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8700 - accuracy: 0.7256 - val_loss: 0.6961 - val_accuracy: 0.7819\n",
            "Epoch 290/400\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.8676 - accuracy: 0.7257\n",
            "Epoch 290: val_loss did not improve from 0.68227\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8733 - accuracy: 0.7228 - val_loss: 0.7030 - val_accuracy: 0.7871\n",
            "Epoch 291/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.8632 - accuracy: 0.7170\n",
            "Epoch 291: val_loss did not improve from 0.68227\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8634 - accuracy: 0.7165 - val_loss: 0.6972 - val_accuracy: 0.7911\n",
            "Epoch 292/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.8647 - accuracy: 0.7177\n",
            "Epoch 292: val_loss did not improve from 0.68227\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.8668 - accuracy: 0.7183 - val_loss: 0.7058 - val_accuracy: 0.7882\n",
            "Epoch 293/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.8657 - accuracy: 0.7193\n",
            "Epoch 293: val_loss did not improve from 0.68227\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.8678 - accuracy: 0.7195 - val_loss: 0.7082 - val_accuracy: 0.7768\n",
            "Epoch 294/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8664 - accuracy: 0.7203\n",
            "Epoch 294: val_loss did not improve from 0.68227\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.8656 - accuracy: 0.7207 - val_loss: 0.7241 - val_accuracy: 0.7842\n",
            "Epoch 295/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.8705 - accuracy: 0.7211\n",
            "Epoch 295: val_loss did not improve from 0.68227\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8671 - accuracy: 0.7225 - val_loss: 0.7262 - val_accuracy: 0.7831\n",
            "Epoch 296/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.8835 - accuracy: 0.7134\n",
            "Epoch 296: val_loss did not improve from 0.68227\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8840 - accuracy: 0.7134 - val_loss: 0.7169 - val_accuracy: 0.7762\n",
            "Epoch 297/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.8761 - accuracy: 0.7170\n",
            "Epoch 297: val_loss did not improve from 0.68227\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8779 - accuracy: 0.7164 - val_loss: 0.7013 - val_accuracy: 0.7905\n",
            "Epoch 298/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.8715 - accuracy: 0.7258\n",
            "Epoch 298: val_loss did not improve from 0.68227\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8713 - accuracy: 0.7264 - val_loss: 0.7040 - val_accuracy: 0.7796\n",
            "Epoch 299/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.8600 - accuracy: 0.7253\n",
            "Epoch 299: val_loss did not improve from 0.68227\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8612 - accuracy: 0.7251 - val_loss: 0.6969 - val_accuracy: 0.7871\n",
            "Epoch 300/400\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 0.8546 - accuracy: 0.7238\n",
            "Epoch 300: val_loss did not improve from 0.68227\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8581 - accuracy: 0.7233 - val_loss: 0.6890 - val_accuracy: 0.7905\n",
            "Epoch 301/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.8711 - accuracy: 0.7190\n",
            "Epoch 301: val_loss did not improve from 0.68227\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8694 - accuracy: 0.7194 - val_loss: 0.6907 - val_accuracy: 0.7888\n",
            "Epoch 302/400\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.8595 - accuracy: 0.7204\n",
            "Epoch 302: val_loss did not improve from 0.68227\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8580 - accuracy: 0.7208 - val_loss: 0.7114 - val_accuracy: 0.7853\n",
            "Epoch 303/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.8764 - accuracy: 0.7151\n",
            "Epoch 303: val_loss did not improve from 0.68227\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8761 - accuracy: 0.7151 - val_loss: 0.6857 - val_accuracy: 0.7928\n",
            "Epoch 304/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.8770 - accuracy: 0.7209\n",
            "Epoch 304: val_loss did not improve from 0.68227\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8764 - accuracy: 0.7210 - val_loss: 0.6972 - val_accuracy: 0.7871\n",
            "Epoch 305/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.8774 - accuracy: 0.7212\n",
            "Epoch 305: val_loss did not improve from 0.68227\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.8736 - accuracy: 0.7217 - val_loss: 0.6903 - val_accuracy: 0.7974\n",
            "Epoch 306/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8673 - accuracy: 0.7223\n",
            "Epoch 306: val_loss did not improve from 0.68227\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8669 - accuracy: 0.7224 - val_loss: 0.6992 - val_accuracy: 0.7911\n",
            "Epoch 307/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.8715 - accuracy: 0.7156\n",
            "Epoch 307: val_loss did not improve from 0.68227\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8710 - accuracy: 0.7158 - val_loss: 0.6863 - val_accuracy: 0.7865\n",
            "Epoch 308/400\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.8720 - accuracy: 0.7213\n",
            "Epoch 308: val_loss did not improve from 0.68227\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8743 - accuracy: 0.7198 - val_loss: 0.7135 - val_accuracy: 0.7819\n",
            "Epoch 309/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8490 - accuracy: 0.7232\n",
            "Epoch 309: val_loss did not improve from 0.68227\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8483 - accuracy: 0.7234 - val_loss: 0.7023 - val_accuracy: 0.7871\n",
            "Epoch 310/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.8543 - accuracy: 0.7253\n",
            "Epoch 310: val_loss did not improve from 0.68227\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8519 - accuracy: 0.7258 - val_loss: 0.7147 - val_accuracy: 0.7825\n",
            "Epoch 311/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.8693 - accuracy: 0.7226\n",
            "Epoch 311: val_loss did not improve from 0.68227\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8697 - accuracy: 0.7225 - val_loss: 0.7249 - val_accuracy: 0.7831\n",
            "Epoch 312/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.8700 - accuracy: 0.7193\n",
            "Epoch 312: val_loss did not improve from 0.68227\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8698 - accuracy: 0.7188 - val_loss: 0.6933 - val_accuracy: 0.7859\n",
            "Epoch 313/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.8677 - accuracy: 0.7208\n",
            "Epoch 313: val_loss did not improve from 0.68227\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8651 - accuracy: 0.7213 - val_loss: 0.6878 - val_accuracy: 0.7894\n",
            "Epoch 314/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.8894 - accuracy: 0.7163\n",
            "Epoch 314: val_loss did not improve from 0.68227\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8879 - accuracy: 0.7170 - val_loss: 0.7134 - val_accuracy: 0.7733\n",
            "Epoch 315/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.8799 - accuracy: 0.7137\n",
            "Epoch 315: val_loss did not improve from 0.68227\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8751 - accuracy: 0.7160 - val_loss: 0.6965 - val_accuracy: 0.7865\n",
            "Epoch 316/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.8500 - accuracy: 0.7237\n",
            "Epoch 316: val_loss did not improve from 0.68227\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8557 - accuracy: 0.7224 - val_loss: 0.6993 - val_accuracy: 0.7842\n",
            "Epoch 317/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.8600 - accuracy: 0.7247\n",
            "Epoch 317: val_loss did not improve from 0.68227\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8589 - accuracy: 0.7247 - val_loss: 0.6972 - val_accuracy: 0.7945\n",
            "Epoch 318/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.8565 - accuracy: 0.7285\n",
            "Epoch 318: val_loss did not improve from 0.68227\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8559 - accuracy: 0.7280 - val_loss: 0.6936 - val_accuracy: 0.7876\n",
            "Epoch 319/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.8643 - accuracy: 0.7208\n",
            "Epoch 319: val_loss did not improve from 0.68227\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8636 - accuracy: 0.7205 - val_loss: 0.7208 - val_accuracy: 0.7756\n",
            "Epoch 320/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.8867 - accuracy: 0.7119\n",
            "Epoch 320: val_loss did not improve from 0.68227\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8863 - accuracy: 0.7121 - val_loss: 0.7060 - val_accuracy: 0.7825\n",
            "Epoch 321/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8680 - accuracy: 0.7183\n",
            "Epoch 321: val_loss did not improve from 0.68227\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8683 - accuracy: 0.7181 - val_loss: 0.7143 - val_accuracy: 0.7768\n",
            "Epoch 322/400\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 0.8587 - accuracy: 0.7227\n",
            "Epoch 322: val_loss did not improve from 0.68227\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8570 - accuracy: 0.7231 - val_loss: 0.6989 - val_accuracy: 0.7911\n",
            "Epoch 323/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8662 - accuracy: 0.7180\n",
            "Epoch 323: val_loss did not improve from 0.68227\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8677 - accuracy: 0.7175 - val_loss: 0.7171 - val_accuracy: 0.7779\n",
            "Epoch 324/400\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.8571 - accuracy: 0.7307\n",
            "Epoch 324: val_loss did not improve from 0.68227\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8570 - accuracy: 0.7298 - val_loss: 0.7227 - val_accuracy: 0.7779\n",
            "Epoch 325/400\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.8388 - accuracy: 0.7295\n",
            "Epoch 325: val_loss improved from 0.68227 to 0.67512, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8379 - accuracy: 0.7297 - val_loss: 0.6751 - val_accuracy: 0.7939\n",
            "Epoch 326/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.8779 - accuracy: 0.7203\n",
            "Epoch 326: val_loss did not improve from 0.67512\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8763 - accuracy: 0.7207 - val_loss: 0.7112 - val_accuracy: 0.7773\n",
            "Epoch 327/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.8500 - accuracy: 0.7186\n",
            "Epoch 327: val_loss did not improve from 0.67512\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8503 - accuracy: 0.7187 - val_loss: 0.6971 - val_accuracy: 0.7905\n",
            "Epoch 328/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.8524 - accuracy: 0.7268\n",
            "Epoch 328: val_loss did not improve from 0.67512\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8550 - accuracy: 0.7264 - val_loss: 0.6941 - val_accuracy: 0.7888\n",
            "Epoch 329/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.8516 - accuracy: 0.7291\n",
            "Epoch 329: val_loss did not improve from 0.67512\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8541 - accuracy: 0.7288 - val_loss: 0.6849 - val_accuracy: 0.7888\n",
            "Epoch 330/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.8561 - accuracy: 0.7195\n",
            "Epoch 330: val_loss did not improve from 0.67512\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8543 - accuracy: 0.7210 - val_loss: 0.6970 - val_accuracy: 0.7956\n",
            "Epoch 331/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.8664 - accuracy: 0.7160\n",
            "Epoch 331: val_loss improved from 0.67512 to 0.66696, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.8663 - accuracy: 0.7161 - val_loss: 0.6670 - val_accuracy: 0.7894\n",
            "Epoch 332/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.8735 - accuracy: 0.7201\n",
            "Epoch 332: val_loss did not improve from 0.66696\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.8704 - accuracy: 0.7210 - val_loss: 0.6855 - val_accuracy: 0.7916\n",
            "Epoch 333/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.8446 - accuracy: 0.7234\n",
            "Epoch 333: val_loss did not improve from 0.66696\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8448 - accuracy: 0.7231 - val_loss: 0.6954 - val_accuracy: 0.7876\n",
            "Epoch 334/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.8377 - accuracy: 0.7223\n",
            "Epoch 334: val_loss did not improve from 0.66696\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8409 - accuracy: 0.7223 - val_loss: 0.6977 - val_accuracy: 0.7842\n",
            "Epoch 335/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.8683 - accuracy: 0.7250\n",
            "Epoch 335: val_loss did not improve from 0.66696\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8714 - accuracy: 0.7233 - val_loss: 0.6952 - val_accuracy: 0.7911\n",
            "Epoch 336/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.8679 - accuracy: 0.7204\n",
            "Epoch 336: val_loss did not improve from 0.66696\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8670 - accuracy: 0.7211 - val_loss: 0.6772 - val_accuracy: 0.7939\n",
            "Epoch 337/400\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.8445 - accuracy: 0.7255\n",
            "Epoch 337: val_loss did not improve from 0.66696\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8421 - accuracy: 0.7270 - val_loss: 0.6831 - val_accuracy: 0.7865\n",
            "Epoch 338/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.8542 - accuracy: 0.7237\n",
            "Epoch 338: val_loss did not improve from 0.66696\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8548 - accuracy: 0.7240 - val_loss: 0.7145 - val_accuracy: 0.7842\n",
            "Epoch 339/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.8366 - accuracy: 0.7276\n",
            "Epoch 339: val_loss did not improve from 0.66696\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8374 - accuracy: 0.7274 - val_loss: 0.6844 - val_accuracy: 0.7956\n",
            "Epoch 340/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.8731 - accuracy: 0.7198\n",
            "Epoch 340: val_loss did not improve from 0.66696\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8722 - accuracy: 0.7200 - val_loss: 0.7065 - val_accuracy: 0.7876\n",
            "Epoch 341/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8567 - accuracy: 0.7238\n",
            "Epoch 341: val_loss did not improve from 0.66696\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8566 - accuracy: 0.7237 - val_loss: 0.6894 - val_accuracy: 0.7916\n",
            "Epoch 342/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8510 - accuracy: 0.7241\n",
            "Epoch 342: val_loss did not improve from 0.66696\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8502 - accuracy: 0.7244 - val_loss: 0.7107 - val_accuracy: 0.7819\n",
            "Epoch 343/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.8612 - accuracy: 0.7256\n",
            "Epoch 343: val_loss did not improve from 0.66696\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8621 - accuracy: 0.7251 - val_loss: 0.6959 - val_accuracy: 0.7842\n",
            "Epoch 344/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.8376 - accuracy: 0.7295\n",
            "Epoch 344: val_loss did not improve from 0.66696\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.8394 - accuracy: 0.7287 - val_loss: 0.6953 - val_accuracy: 0.7876\n",
            "Epoch 345/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.8613 - accuracy: 0.7155\n",
            "Epoch 345: val_loss did not improve from 0.66696\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.8613 - accuracy: 0.7155 - val_loss: 0.7138 - val_accuracy: 0.7831\n",
            "Epoch 346/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.8568 - accuracy: 0.7207\n",
            "Epoch 346: val_loss did not improve from 0.66696\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8542 - accuracy: 0.7214 - val_loss: 0.7071 - val_accuracy: 0.7848\n",
            "Epoch 347/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.8279 - accuracy: 0.7330\n",
            "Epoch 347: val_loss improved from 0.66696 to 0.66013, saving model to saved_models/audio_classification_MODEL2.hdf5\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8297 - accuracy: 0.7330 - val_loss: 0.6601 - val_accuracy: 0.7974\n",
            "Epoch 348/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.8541 - accuracy: 0.7259\n",
            "Epoch 348: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8545 - accuracy: 0.7256 - val_loss: 0.6753 - val_accuracy: 0.7962\n",
            "Epoch 349/400\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.8570 - accuracy: 0.7247\n",
            "Epoch 349: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8519 - accuracy: 0.7251 - val_loss: 0.7071 - val_accuracy: 0.7876\n",
            "Epoch 350/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.8659 - accuracy: 0.7234\n",
            "Epoch 350: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8650 - accuracy: 0.7233 - val_loss: 0.7161 - val_accuracy: 0.7802\n",
            "Epoch 351/400\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.8751 - accuracy: 0.7171\n",
            "Epoch 351: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8747 - accuracy: 0.7170 - val_loss: 0.6853 - val_accuracy: 0.7979\n",
            "Epoch 352/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.8618 - accuracy: 0.7225\n",
            "Epoch 352: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8613 - accuracy: 0.7227 - val_loss: 0.6868 - val_accuracy: 0.7934\n",
            "Epoch 353/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.8747 - accuracy: 0.7205\n",
            "Epoch 353: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8727 - accuracy: 0.7208 - val_loss: 0.6918 - val_accuracy: 0.7916\n",
            "Epoch 354/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.8359 - accuracy: 0.7241\n",
            "Epoch 354: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8373 - accuracy: 0.7240 - val_loss: 0.6749 - val_accuracy: 0.7934\n",
            "Epoch 355/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.8470 - accuracy: 0.7290\n",
            "Epoch 355: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8462 - accuracy: 0.7294 - val_loss: 0.6761 - val_accuracy: 0.7848\n",
            "Epoch 356/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.8489 - accuracy: 0.7217\n",
            "Epoch 356: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.8533 - accuracy: 0.7214 - val_loss: 0.7117 - val_accuracy: 0.7865\n",
            "Epoch 357/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.8705 - accuracy: 0.7216\n",
            "Epoch 357: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.8692 - accuracy: 0.7220 - val_loss: 0.7032 - val_accuracy: 0.7888\n",
            "Epoch 358/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8383 - accuracy: 0.7269\n",
            "Epoch 358: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8381 - accuracy: 0.7270 - val_loss: 0.6819 - val_accuracy: 0.7911\n",
            "Epoch 359/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.8484 - accuracy: 0.7305\n",
            "Epoch 359: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8489 - accuracy: 0.7293 - val_loss: 0.6804 - val_accuracy: 0.7859\n",
            "Epoch 360/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.8489 - accuracy: 0.7244\n",
            "Epoch 360: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8479 - accuracy: 0.7248 - val_loss: 0.6970 - val_accuracy: 0.7836\n",
            "Epoch 361/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.8531 - accuracy: 0.7237\n",
            "Epoch 361: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8542 - accuracy: 0.7237 - val_loss: 0.6850 - val_accuracy: 0.7831\n",
            "Epoch 362/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8604 - accuracy: 0.7173\n",
            "Epoch 362: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8608 - accuracy: 0.7171 - val_loss: 0.6926 - val_accuracy: 0.7876\n",
            "Epoch 363/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.8705 - accuracy: 0.7173\n",
            "Epoch 363: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8677 - accuracy: 0.7184 - val_loss: 0.6740 - val_accuracy: 0.7922\n",
            "Epoch 364/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.8415 - accuracy: 0.7296\n",
            "Epoch 364: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8386 - accuracy: 0.7321 - val_loss: 0.6919 - val_accuracy: 0.7911\n",
            "Epoch 365/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.8416 - accuracy: 0.7313\n",
            "Epoch 365: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8409 - accuracy: 0.7313 - val_loss: 0.6893 - val_accuracy: 0.7916\n",
            "Epoch 366/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.8722 - accuracy: 0.7174\n",
            "Epoch 366: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8712 - accuracy: 0.7183 - val_loss: 0.6955 - val_accuracy: 0.7905\n",
            "Epoch 367/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.8532 - accuracy: 0.7295\n",
            "Epoch 367: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8515 - accuracy: 0.7303 - val_loss: 0.6877 - val_accuracy: 0.7951\n",
            "Epoch 368/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.8380 - accuracy: 0.7297\n",
            "Epoch 368: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.8364 - accuracy: 0.7298 - val_loss: 0.6779 - val_accuracy: 0.7888\n",
            "Epoch 369/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.8327 - accuracy: 0.7321\n",
            "Epoch 369: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.8302 - accuracy: 0.7329 - val_loss: 0.6712 - val_accuracy: 0.7962\n",
            "Epoch 370/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8505 - accuracy: 0.7248\n",
            "Epoch 370: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8499 - accuracy: 0.7248 - val_loss: 0.6677 - val_accuracy: 0.7968\n",
            "Epoch 371/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.8580 - accuracy: 0.7199\n",
            "Epoch 371: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8591 - accuracy: 0.7195 - val_loss: 0.6900 - val_accuracy: 0.7934\n",
            "Epoch 372/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8605 - accuracy: 0.7219\n",
            "Epoch 372: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8599 - accuracy: 0.7221 - val_loss: 0.6997 - val_accuracy: 0.7825\n",
            "Epoch 373/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.8566 - accuracy: 0.7221\n",
            "Epoch 373: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8566 - accuracy: 0.7221 - val_loss: 0.6787 - val_accuracy: 0.7888\n",
            "Epoch 374/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.8370 - accuracy: 0.7279\n",
            "Epoch 374: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8419 - accuracy: 0.7267 - val_loss: 0.6979 - val_accuracy: 0.7779\n",
            "Epoch 375/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.8656 - accuracy: 0.7201\n",
            "Epoch 375: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8685 - accuracy: 0.7194 - val_loss: 0.6901 - val_accuracy: 0.7911\n",
            "Epoch 376/400\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.8590 - accuracy: 0.7223\n",
            "Epoch 376: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8597 - accuracy: 0.7225 - val_loss: 0.6963 - val_accuracy: 0.7865\n",
            "Epoch 377/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.8457 - accuracy: 0.7226\n",
            "Epoch 377: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8456 - accuracy: 0.7218 - val_loss: 0.6749 - val_accuracy: 0.7974\n",
            "Epoch 378/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.8526 - accuracy: 0.7301\n",
            "Epoch 378: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8520 - accuracy: 0.7304 - val_loss: 0.6624 - val_accuracy: 0.7962\n",
            "Epoch 379/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.8525 - accuracy: 0.7252\n",
            "Epoch 379: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8507 - accuracy: 0.7254 - val_loss: 0.6987 - val_accuracy: 0.7894\n",
            "Epoch 380/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8803 - accuracy: 0.7159\n",
            "Epoch 380: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8802 - accuracy: 0.7158 - val_loss: 0.6830 - val_accuracy: 0.7916\n",
            "Epoch 381/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.8612 - accuracy: 0.7227\n",
            "Epoch 381: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8589 - accuracy: 0.7240 - val_loss: 0.6961 - val_accuracy: 0.7956\n",
            "Epoch 382/400\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.8298 - accuracy: 0.7314\n",
            "Epoch 382: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8303 - accuracy: 0.7319 - val_loss: 0.6790 - val_accuracy: 0.7905\n",
            "Epoch 383/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.8438 - accuracy: 0.7339\n",
            "Epoch 383: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8449 - accuracy: 0.7337 - val_loss: 0.6870 - val_accuracy: 0.7905\n",
            "Epoch 384/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.8374 - accuracy: 0.7315\n",
            "Epoch 384: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8377 - accuracy: 0.7320 - val_loss: 0.6805 - val_accuracy: 0.7962\n",
            "Epoch 385/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.8533 - accuracy: 0.7205\n",
            "Epoch 385: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8533 - accuracy: 0.7205 - val_loss: 0.6855 - val_accuracy: 0.7945\n",
            "Epoch 386/400\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.8218 - accuracy: 0.7311\n",
            "Epoch 386: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8200 - accuracy: 0.7320 - val_loss: 0.6608 - val_accuracy: 0.7968\n",
            "Epoch 387/400\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.8341 - accuracy: 0.7314\n",
            "Epoch 387: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8315 - accuracy: 0.7330 - val_loss: 0.6864 - val_accuracy: 0.7934\n",
            "Epoch 388/400\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.8565 - accuracy: 0.7308\n",
            "Epoch 388: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8524 - accuracy: 0.7313 - val_loss: 0.6870 - val_accuracy: 0.7865\n",
            "Epoch 389/400\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.8349 - accuracy: 0.7320\n",
            "Epoch 389: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8360 - accuracy: 0.7319 - val_loss: 0.6797 - val_accuracy: 0.7928\n",
            "Epoch 390/400\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.8376 - accuracy: 0.7292\n",
            "Epoch 390: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8413 - accuracy: 0.7283 - val_loss: 0.7038 - val_accuracy: 0.7831\n",
            "Epoch 391/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.8591 - accuracy: 0.7211\n",
            "Epoch 391: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8520 - accuracy: 0.7225 - val_loss: 0.6908 - val_accuracy: 0.7825\n",
            "Epoch 392/400\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.8326 - accuracy: 0.7285\n",
            "Epoch 392: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8324 - accuracy: 0.7287 - val_loss: 0.6704 - val_accuracy: 0.7956\n",
            "Epoch 393/400\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.8378 - accuracy: 0.7292\n",
            "Epoch 393: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.8338 - accuracy: 0.7303 - val_loss: 0.6669 - val_accuracy: 0.7848\n",
            "Epoch 394/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.8611 - accuracy: 0.7234\n",
            "Epoch 394: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.8544 - accuracy: 0.7251 - val_loss: 0.6808 - val_accuracy: 0.7922\n",
            "Epoch 395/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.8586 - accuracy: 0.7213\n",
            "Epoch 395: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.8592 - accuracy: 0.7217 - val_loss: 0.6872 - val_accuracy: 0.7831\n",
            "Epoch 396/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.8362 - accuracy: 0.7336\n",
            "Epoch 396: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8355 - accuracy: 0.7333 - val_loss: 0.6870 - val_accuracy: 0.7882\n",
            "Epoch 397/400\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.8239 - accuracy: 0.7353\n",
            "Epoch 397: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8316 - accuracy: 0.7327 - val_loss: 0.6991 - val_accuracy: 0.7848\n",
            "Epoch 398/400\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.8362 - accuracy: 0.7357\n",
            "Epoch 398: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8351 - accuracy: 0.7357 - val_loss: 0.6793 - val_accuracy: 0.7928\n",
            "Epoch 399/400\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.8624 - accuracy: 0.7301\n",
            "Epoch 399: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8624 - accuracy: 0.7301 - val_loss: 0.6798 - val_accuracy: 0.8037\n",
            "Epoch 400/400\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.8390 - accuracy: 0.7238\n",
            "Epoch 400: val_loss did not improve from 0.66013\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.8370 - accuracy: 0.7246 - val_loss: 0.6888 - val_accuracy: 0.7956\n",
            "Training completed in time:  0:07:08.207351\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy=model1.evaluate(X_test,y_test,verbose=0)\n",
        "print(test_accuracy[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5fgGGSudNtX",
        "outputId": "cf9f7417-c549-4c08-eb28-6ec850cd7fdb"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8208357095718384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy=model2.evaluate(X_test,y_test,verbose=0)\n",
        "print(test_accuracy[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3zRIVdOp5rh",
        "outputId": "cf8cecbb-14d8-421d-ef13-649069b5bd8a"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7956497073173523\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "model3 = keras.models.load_model('/content/audio_classification_new.hdf5')#TRAINED BEFORE,NOTHING SPECIAL JUST SOME DIFFERENT PARAMETERS"
      ],
      "metadata": {
        "id": "etBlWMi8XQAX"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy=model3.evaluate(X_test,y_test,verbose=0)\n",
        "print(test_accuracy[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEPtMN4FXXjt",
        "outputId": "4a8be78b-1061-4caa-8791-bcbda910f1ce"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8219805359840393\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL 3 GAVE THE BEST RESULT ON VALIDATION SET"
      ],
      "metadata": {
        "id": "rmo8INsEekzi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8O% ACCURACY, HMMMMMM"
      ],
      "metadata": {
        "id": "174ucJgrdYU_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets try predicting"
      ],
      "metadata": {
        "id": "n50NXm0gfZGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=model3.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03wiZY9ZdhTS",
        "outputId": "f4cb188d-5223-4626-fd18-afb9c801b1c9"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55/55 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred[0]#probability of each class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ97foPbhew-",
        "outputId": "99a63619-8480-4d66-ce8e-27ad94e812d7"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.9730111e-09, 1.1759921e-04, 4.8617119e-07, 2.0573107e-05,\n",
              "       1.5266306e-08, 9.9885052e-01, 5.8019118e-09, 9.0926734e-13,\n",
              "       1.8785363e-06, 1.0089552e-03], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict = np.argmax(model3.predict(X_test), axis=-1)#entire test set with class with max probability\n",
        "y_predict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3xcPHlndd9_",
        "outputId": "fe5a2b39-4ccf-4fee-8f58-3b9c4fda3e66"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55/55 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 4, 4, ..., 1, 2, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max(y_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtRoEu4ydfbe",
        "outputId": "bd61c514-d823-417e-aea7-2c5c42e957dc"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min(y_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ok0zDwgNhzeX",
        "outputId": "86fee3a1-ecd2-4d91-b678-9e70a610912a"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzjPoAPYe8Kr",
        "outputId": "aa871b14-705c-4efa-e30c-0767d411df6d"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[0]#THIS IS CLASS_ENGINE_IDLING"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fB6CXF8aiJPP",
        "outputId": "facdac70-5f14-4016-b570-97abf0aed2c1"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_encoded_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "-8NfhKwUtv0w",
        "outputId": "5caa45d8-3cdf-448d-827a-f8ff61ea2435"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      class_air_conditioner  class_car_horn  class_children_playing  \\\n",
              "0                         0               0                       0   \n",
              "1                         0               0                       1   \n",
              "2                         0               0                       1   \n",
              "3                         0               0                       1   \n",
              "4                         0               0                       1   \n",
              "...                     ...             ...                     ...   \n",
              "8727                      0               1                       0   \n",
              "8728                      0               1                       0   \n",
              "8729                      0               1                       0   \n",
              "8730                      0               1                       0   \n",
              "8731                      0               1                       0   \n",
              "\n",
              "      class_dog_bark  class_drilling  class_engine_idling  class_gun_shot  \\\n",
              "0                  1               0                    0               0   \n",
              "1                  0               0                    0               0   \n",
              "2                  0               0                    0               0   \n",
              "3                  0               0                    0               0   \n",
              "4                  0               0                    0               0   \n",
              "...              ...             ...                  ...             ...   \n",
              "8727               0               0                    0               0   \n",
              "8728               0               0                    0               0   \n",
              "8729               0               0                    0               0   \n",
              "8730               0               0                    0               0   \n",
              "8731               0               0                    0               0   \n",
              "\n",
              "      class_jackhammer  class_siren  class_street_music  \n",
              "0                    0            0                   0  \n",
              "1                    0            0                   0  \n",
              "2                    0            0                   0  \n",
              "3                    0            0                   0  \n",
              "4                    0            0                   0  \n",
              "...                ...          ...                 ...  \n",
              "8727                 0            0                   0  \n",
              "8728                 0            0                   0  \n",
              "8729                 0            0                   0  \n",
              "8730                 0            0                   0  \n",
              "8731                 0            0                   0  \n",
              "\n",
              "[8732 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-772fef9a-f633-45ef-8302-027354fb71f4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class_air_conditioner</th>\n",
              "      <th>class_car_horn</th>\n",
              "      <th>class_children_playing</th>\n",
              "      <th>class_dog_bark</th>\n",
              "      <th>class_drilling</th>\n",
              "      <th>class_engine_idling</th>\n",
              "      <th>class_gun_shot</th>\n",
              "      <th>class_jackhammer</th>\n",
              "      <th>class_siren</th>\n",
              "      <th>class_street_music</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8727</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8728</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8729</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8730</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8731</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8732 rows Ã— 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-772fef9a-f633-45ef-8302-027354fb71f4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-772fef9a-f633-45ef-8302-027354fb71f4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-772fef9a-f633-45ef-8302-027354fb71f4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_encoded_data.columns[y_predict[0]]#PREDICTION IS SAME"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "KwxGARg8tWNC",
        "outputId": "e366dea9-4bab-4391-a00d-9d6f947becb1"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'class_engine_idling'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "predicted and actual class is same"
      ],
      "metadata": {
        "id": "A886kmkxiON0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict[11]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4sWX-cakwTF",
        "outputId": "3d945125-0986-4429-a6b6-81684aa5d524"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[11]"
      ],
      "metadata": {
        "id": "d4yaWL-EC5tb",
        "outputId": "b1f043a1-240b-4f90-edd3-350b9cabd292",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LETS TRY A NEW EXAMPLE"
      ],
      "metadata": {
        "id": "NciDRQREf3IT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "metadata": {
        "id": "bxKaw7YvfTCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "YTK2Pgojf7B0"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "our example"
      ],
      "metadata": {
        "id": "LrCwo9y8goF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename='/content/dog_bark.wav'"
      ],
      "metadata": {
        "id": "RMGz8RbSf8uX"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importing librosa for visualisation\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display"
      ],
      "metadata": {
        "id": "1lwfHnsmgEuN"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio, sample_rate = librosa.load(filename, res_type='kaiser_fast') "
      ],
      "metadata": {
        "id": "xQOirP8egGA1"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 4))\n",
        "librosa.display.waveshow(audio,sr=sample_rate)\n",
        "ipd.Audio(filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "GELSYwMVgHRR",
        "outputId": "c3887b1e-bf6c-4680-f6de-6bb438853ba7"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ],
            "text/html": [
              "\n",
              "                <audio  controls=\"controls\" >\n",
              "                    <source src=\"data:audio/x-wav;base64,UklGRiR2AgBXQVZFZm10IBAAAAABAAEAgLsAAAB3AQACABAAZGF0YQB2AgADAP3/8f/r/+b/3//l/+L/5P/h/9X/0v/V/9//4//h/+L/4P/j/+j/7f/2//X/9f/7/wIAAwANAA0AEgAUABQAGgAYAB0AJQAoACgAJgAiACEAFwAPABAACgAGAAAA+P/v/+v/4//f/9n/1v/Q/8n/yf/B/7v/t/+r/5//nf+j/6v/qP+g/5v/mf+U/43/jP+P/5P/mv+d/5//rf+4/8L/yP/S/9//3v/i/+n/4v/j/+f/3//R/87/zv/P/8r/uP+v/6f/pP+j/6D/mf+X/4//h/+A/3X/cf9o/2n/Zv9n/23/b/92/3b/d/95/3r/dv96/4T/hf+O/5j/l/+g/6f/pf+n/6//uP+9/8H/wf/C/8f/yP/E/8D/uv+9/7r/uf+8/8r/y//H/8z/yv/H/8n/xf/N/9b/4//q//T/+/8DAAQADQAWACAAHwAhACcAJAAZABYAGwAZABIAGAAZABUADwAIAAgAFAAVAB0AHwAcACAAHAAXABAADAAOAAkABAD9//f/AAACAAIABAAKAAcABwAHAAUAAQAEAAUA/P8AAAUADAANABYAEwANAAoAEAAZABwAIAAsAC8AMAAwACoAJAAVABAADwAQAAgA//8AAAUABwAEAAMABgANABIAGQAXABkAGgAZABMADQAHAAQA+//4//T/7//r/+n/5P/b/83/vv+s/6H/l/+N/4r/hP+H/4T/e/99/3n/g/9+/4H/fP92/3f/f/+F/4r/j/+Y/5v/mv+i/67/sf+v/6b/nf+k/6n/pf+o/6r/qv+s/63/qP+f/5z/n/+g/57/ov+o/6r/tv++/8T/zP/X/+b/6f/0//n//v/+//r/+v/7//j/9v/6//j/+f8FAAgADAAcACIAIwAeABkAFwASAA8ACwAKAAgABgADAAQACgAHAAUA/v/2//D/7v/7/wQABwAOABEADAAFAAEA9P/u/+3/7//s/+f/6f/n/+7/7v/u/+7/8v/t//H/7v/z//b//f/4/+z/6//l/+r/8f/1/+//5v/d/9P/z//M/9b/2P/W/8r/xf/I/9f/5f/t/+//5v/m/+j/6//1//f/9v/u/+b/5//o/+v/9f/4//r/AAD6//f/9P/3//r//f/8/////P/3//j/8f/1/+3/5P/c/83/yf/F/8n/x//N/8j/wv/F/8D/zP/U/+L/5P/p/+z/7//v//H/8//3//L/7//0/wMABwADAAgADgATABAAEQAHAP7/+f/t/+v/7//v/+3/7//n/9z/1v/b/9T/0v/M/83/yP/G/8T/yv/X/9r/3f/a/9v/4//o/+D/4v/j/+n/8v/4//n/+v/3/wEACAAOABUAFgAcABwAGgAXABcAHgAlACUAHwAhABwAKAApACgAMAAtACwAKwAoACAAFwARAAcAAwD8//f/9f/x/+v/5//k/+T/3v/Z/+T/5P/k/9//3v/d/9r/3//f/93/3//a/97/2P/c/9//4P/f/9//3P/d/9r/3f/f/+D/4f/p/+j/4P/l/+T/2P/K/8f/xv/P/9v/3f/c/9n/1P/K/8r/yf/U/9z/6P/y////BgAHAAgACgAQABgAIwAXABAACwANAAcABwAAAP//+f/w/+v/6//o/+X/5P/l/+P/5P/q/+f/5P/h/9n/0v/K/8j/0f/R/9P/0P/P/83/0f/O/9T/1P/U/9n/3P/g/+b/6//s/+r/4//n/+X/6v/j/+H/1f/Q/9j/2v/i/+r/7f/r/+z/6//m/+j/3v/g/+H/3v/f/+L/6//u//f/9v/9//3//P/8//z////3//f/8f/1/wIAAgAMABMAGAAbABsAGwAXABcAFQAVAA4ABwD///n/+v/0/+7/4//Z/9H/0f/L/8b/vf+9/7v/yP/K/8j/zf/X/+H/6//8/wYADwAPAA0AEAATABkAGgAgACcAIgAjACsALwAqAC8AKAAeABsADwAMAA0ABwAFAAcAAwD/////9//v/+b/5v/j/+f/6P/z//v/+P/2//L/6v/e/9P/yv/H/8n/2P/i//D/+/8QACMAMQAxACwAHQARAA4AAgD2//b/+f/4//r/AQADAAIA+v/z/+f/1v/G/7z/sf+m/6z/rv+4/7//yf/g/+3/AwARABcAEAAMAAIA9f/x/+r/7v/9/xAAIAAuADIAMwAuACkAKQAhABcACgD///T/7//p/+n/7P/l/+P/6P/s/+n/5P/c/9z/3P/Z/9T/1f/a/9X/2P/d/+X/6//3//7///////r/+v/5////BgARABAACwAPAA4AEQANABQAEwAQAAoABQAFAP3/AQD8/wEAAAD9//L/8//z//P/8//1//T/7f/t//L/7f/u/+7/6//n/+T/6P/o/+b/3v/a/9v/2f/b/9b/1f/U/8//z//S/9j/2v/Z/9//4v/f/93/2P/S/8X/tv+r/6D/lf+X/5P/kP+b/6f/s//E/9j/4//s/+z/6P/p/+f/4P/f/9z/1v/c/93/5f/n//b//P8MAB0AJwAoACsAJgAXABAAAQD3/+n/2v/X/9X/2P/d/+P/4f/l/+L/3P/b/87/xv+5/7D/qf+p/6z/tv/I/9P/2v/n/+///P8CAPv/+P/y//T/+P///wEA//8HAAIA+//z/+7/8P/5//r/+v/7/wIACQAFAAIABwAIAA0ABwANAA0ACwAKAP//+v///wcACwAdACAAHQAWABEAAgD7//H/7v/p/+L/6P/3/wAABQAFAAYACQARABQADAAIAAYABwAFAAUA///8//T/7v/q//H/6f/u/+n/6//m/+r/6P/p//D/+P/4//z//P8BAAcADAAOABEAEwAQABMAHAApACcALAAxADYANwA3ADwAQQBAAD0AOgA6ADIAIwAWAAQA/f/+//z//////wMABAD+//f/7//t/+b/5P/Z/9D/xf/J/9D/1f/X/9v/6//t/+7/8//x//D/7P/o/+//9f/u/+j/5//q//D/8P/u/+//7P/p/+r/5P/Y/8r/yf/K/8n/yv/P/9P/4P/k/+P/6P/r//H/6P/t/+7/9f/x//b//f8MAA0AGAAgACcALQA8AEYAQgBCADkAMQAiABUADAALAAEA/v/5/+3/7f/r/+b/6f/u//P/8P/p/+L/7//s//D/4//e/9b/0//P/9P/1//V/87/1//i/+z/9f/7/wcACQAGABIAGwAqAC4AOABCAEsAWQBlAHMAeAB4AHoAdwBxAGoAZgBoAFwAWwBVAFYAUABSAFAAUABLAEwAUAA+ADYALAArACYAJgAoACkAMQA1AD4AQgBBAD0APwA8ADcAPQA4AC4ALwAzADkAPgBFAEQATABNAEcARQBFADwAOAAwACcAIQAiACoAOQBCAEAARgBGAEgASABCADgANQA6ADsAOQA+AEkAUQBcAGAAagBrAHMAbgBpAGYAZABjAGAAWgBUAEcAQABDAEoATgBPAEYASABJAEQAPQA2ADIAMQAvADIANAA3AEcAVABTAFQAVABLAEUAOQA0ACsALgAuAC0AKwApACMAHwAdABsAIAAnACwALgAuACwAKgAeABoAFwAWAB4AHQAeABoAFgAdABcADgAPAAcABgAGAPj/9P/w/+3/7v/y//z/+f/6//j/9//2//b/9v/+//f/8f/z//j/AAAFAP//+v8BAAgACgANAA0ACgANAAoAAgD+//j/8v/u/+v/7P/n/+L/3//e/97/3f/c/9z/3//e/+X/7f/q/+z/6//x//L/8//v/+z/8P/5//f//P/8//3/AwAAAPr/9v/6/wEACgAUABgAGQAOAAYAAgD+////BgALAAsAEgAYAAYADAAMAAoADgAIAPz/+v/v/+T/3//h/+n/5f/t/+j/4f/y/+//AAAFANf/pv+p/8n/7P8OACEAKAAJAMr/qf/A/+T/AwAdADEANwAGAL3/l/+X/6z/3v8VAC0AJQAIAN//1P/q/+f/7P8HABYABgDy/+T/yv+w/5z/rf/N/+b/9v/+//H/0/+v/7T/wP/A/+D/+f/x//X/BgD7/97/2P/V/9j/3//n//b/AAD2/+T/sf+e/7L/zf/r//v/9P/Z/8T/sP+g/7r/4v/o//X/DwATAAYAAADv/+T/6v/8/wgADAATAA8ABAD0/+v/6//s/+3/CQApADoALQAbAAoA+f/q//r/DwAlADYANgAsABoAEwASAA8AAwADAAUADQAXABMABQDy/+7/6f/h/+H/6v/1//D/7v/s/+H/0v/T/9j/6f/5//n/9f/5//r/8P/l/+f/6f/n//D/+/8AAAEA/f/z/+n/5f/q//j/+P/8//3/+P/4//n/+f/0/wUAAQD9//r//v/8//b/8f/5/wEABgARAA4AGAAcABwAHQAuADEALwA7AEMASwBPAE4ASwBGAEYASgBLAFEATABJAEUARgA5AC8AJgAlACUAJAAjACAAJQAkACAAIQAdACMALwAvABwACAD//wAAAwAIABUAIAAgABoAHgAcABgAGAASABMAHQAfACcAMQAsACQAIwAjAB8AIAAhACAAGQAUAAAA9//t/+v/6f/q//D/7v/4/wEABgAJAAQAAAABAAEA///6//r//P/1//D/8P/y/+j/6P/q/+f/4P/X/9D/z//Z/9f/0f/W/9P/0P/h/+r/5P/T/9f/2P/U/87/0f/T/9r/4v/r/+n/7v/u/+n/6v/x//f/8//q/+n/6f/p//v/CwAHAPn/DgAXAAcA9/8DAAkAAAD2/+//3//g/+X/2f/V/97/4P/c/+f/8v/i/+L/4//e/9r/4//l/+H/5P/d/+n/7v/y//f/+f/9/wAACQAPABwAIQAUAA0AEAASAA4AFgAqAC8AJAAkABwAEgAPABUAFwARABUADgAMAAwAEAAUABoAIwAoADQAOwBEAEkASQBHAEoAVwBTAFUAXABiAFwAXABgAF0AXgBbAFYASwBIAEEAPAA7AC8AIgAgACcAHwAdABwAGgAVABEAGAAbABkAHgAhABUAEwAVABQACAAFAAYABQAIAPj/8//t/+f/4v/k/+7/6//j/+L/3v/l/+b/5P/m/+T/4//c/9r/2P/a/+L/6f/w//j//P/9//r/7f/k/+z/8P/z/+r/6P/o/+b/5f/m/93/4//o//f//v8HABIAFAARAAcABAAHAAYAAgAJAAwADAALAAgAEAAZABUAEgARABAACQADAAYABAAEAP3//f/7//r//f8DAAMA+v/4////+f/0//n/+f/9//z/BQAPABQAGQAYABoAEQANAAcABgACAP7//P/+//X/8f/w/+r/7f/p/+z/6//0//j/+//+//f/+P/3//D/8f/3//X/8//v//X//P/+/wMA+//z/+f/2f/G/8X/wf/I/8n/zf/U/93/4P/g/9n/1v/c/9r/1f/Q/8z/0v/O/8v/yP/K/8v/zv/Q/9X/1f/f/+r/7v/y//f//P/4//z/9//6/wIAAgAAAPz/8P/s/+z/8f/2//j/8//w/+f/4P/e/9v/1//N/8z/y//S/9X/2v/l/+r/6P/k/9v/4P/o/+v/6P/h/+D/5v/u//j//v/8/wUADQASAB8AKwAqACYAMAAuACYAIwApACMAJQAlADEANgA3ADoAOQA2AC8ANwAqADYAPAA+AEMATgBaAGEAZABiAGEAXABZAFQAUQBMAEYASABLAEkAQQBAAEIASwBEAEAAPAAsACAAFwARAAoAAgADAP//+v/1//j//P/0/+T/3P/d/9T/z//G/7z/tP+u/7r/yf/X/9r/2v/Z/9f/zP/A/6z/m/+X/5L/j/+X/6D/mv+e/6//tf/E/8v/zf/K/8j/xv/F/8n/x//K/8n/0f/Q/9X/y/+9/7//vf+8/7f/tP+6/7H/t/+4/7j/wf/E/8j/xP/C/8f/xf/H/8T/vv/A/8j/2v/a/9//7v/u/+3/8P/o/+T/4f/f/9z/4P/k/9//3v/o/+b/4v/k/+n/7P/k/+j/5//e/+D/6f/v//T/9/8DABQAGgAeABcAEgAMAAYABQAIAAgAAwACAAYACgAVABIACAADAPz/+P/0/+//6P/j/93/4//q//n/9//y//T/9P/9/wYACwALAAkACgALAAMAAAD1//L///8NABQAEwANAAMA7//f/9j/1//c/97/1//h/+v/6f/i/93/2v/e/9b/0//Y/9z/1P/M/87/xP/C/8H/vv++/73/xP/K/8v/zf/G/8X/xP/K/83/0f/Q/8v/yf/A/7T/p/+k/6P/pP+h/6D/pv+n/6v/sf+z/7T/uf+6/7f/vf+8/7r/wf+9/8L/u//F/8f/y//S/83/1v/g/+X/7v/x//X/+v/9/wIA9//1//T//v8IAAwAFAAWABkAHAAjACgALQAvAC8AJQAnAC4AKQAmAB0AJQAoADAANQA3AD4ANwAwACwAIwAYABAADgAOAAwACwAMABAAIQAnACoAMAA0ADcAOgBBAD8AOQA1ACoAIAAiAC4APQBBAEEANwAvADAAMQAvADYAPwA9ADsANQAxACsAMQA0AC8ANQAwACcAIAAWAAgA/f/0//j/9//0//X/8//0/+7/8P/p//L///8KABUAHgAdABgAGAAjACEAHAAaABkAFwAQABAABwANABYAHQAiABoAFAAUABEADQAMAAMAAAABAPv/9//4//j/+f/4//b//v/9//7/9v/x//P/8//0//H/9f/z//D/8v/y/+n/6P/l/+L/3P/e/+D/6//y//7/DAAaACMAHgAWAA0ACAD3/+//8v/v/+r/7//p/+L/4//t/+b/3P/a/9j/1P/T/8r/wv+9/7j/tf+4/7r/tP+w/7b/uP+1/7v/xP/C/8T/0P/g/+v/8//u/+z/7v/y//X/6f/i/9b/1f/V/9r/4f/n/+v/5P/n/+T/3f/Y/9H/0v/J/8b/y//L/8//0P/R/87/yf/F/8P/wf+4/7L/r/+u/67/sP+x/7L/r/+y/7T/sv+4/73/yP/O/8//0f/K/8v/yv/I/8X/w//E/8b/xv/C/77/wf++/8L/zP/S/9f/2//n/+7/+/8CAAYABAAIAAgAEgASABUAIgAnACoALQAwAC8ALAAvADMAPgA2ADEAMAA6ADMALAAmAC4ANAA6AD0APABKAEQAQAA9AEAAQQA+ADsALQArAC8AOQA6ADMANwA2ADUAMAAqACoALQAuACYAKAAnAC4ANwA4ADoALwAsACcAJAAgABsAFAAOAA8ADwAWABoAHAAdACgAMwAzADAALwAtACYAKgAnACMAKwAyADAAKgAgABwAHAAbABgAGAAVAA8ACQACAPX/9P/v//L/6//c/9j/2f/U/9D/yf/M/8f/zP/C/8L/xv/G/8X/vv/B/8L/vv+8/8D/vv/D/8f/xP/B/7r/tf+v/7D/r/+1/7z/wP/I/87/xv+9/7//wP+9/7X/sP+r/67/vf/I/9X/5f/r//L/8v/w/+T/3v/k/+D/5f/h/+z/+v/9/wMABgAIAAkAFwAlACoALAAiAB0AJAAnACkAKAAwAC8ALAAmACIAGwAbACAAHAAcACQAHgAdAB4AHQAbABkAGAAUABsAIgAqACkAKAAsACwAHQALAAcA/v/0//f/AwAKABkALQA8AEMARwBPAFMATwBGAEIAOgA3AD8ANwA4AD0AOQA2ADEAMgAlABoAHgAWABsAIwAsACgAJwAsACgAIgAdABUAFQAPAAsABwAGAAoAEAAaABMAGAATABEADwD5/+b/1v/T/9L/1P/d/+j/6f/y//T/8v/w/+f/4P/f/+f/6//w//L/8f/1//r/9P/t/+j/4v/b/9T/3f/j/+j/8//+/wkABgAGAPv/9//x/+v/6P/j/+L/5f/u//P/9P/+/w8AGAAgAB0AGgAPAA0ADAADAAIAAgAIAAoACgD8//n/9//3//X/8v/w////DQAPABUADAALAAQA+v/1/+///P8HAAoAFwAdABsAHAAUABEADQAPAA8ACgAWACQAKwAzADYAPwA+ADoANgAwACcAJAAlACEAJAAiACkANAA0AC4ALwAzAC4AMwA2ADcAPQA7ADUANQA8ADwAOQAqACYAJgAdABoAEAAXABcAGwAbACAAKAAbABQABgD///f/5//c/8n/xP/I/8P/w/+//7f/qf+d/5n/mP+f/67/u//P/9z/6f/v//H/5f/Z/87/yP/J/8P/zf/W/+X/9f8BAAQACAAHAAgABgABAAYACAAFAPj/8//1//X/8//m/+H/4f/d/9n/3v/n//T/+P8BAAcADgAYAA4ADAAIAAEA9v/p/+f/4P/a/9T/x/+//7n/t/+z/73/x//V/+j/9f8JABQAIAAoACAAEQAEAPP/4f/U/8//0f/V/+b/7f/m/+T/3f/a/9H/0v/S/8z/1//l//n/CAAGAAoA+//u/97/0f/K/8L/w//F/83/1f/e/+z/8f/x/+r/4f/k/+n/7//8/wsAGQAfACUAKgAlABQABAD5//j/9//w/wEABwAHAAwADAAPAAMA9//v//P/9v/6/wEABgAOABwAJwAqACUAEQAIAP7/9f/z//j/BQAcADAANgA7AD0AMwAkABMAAgD9//j/BgAfADEAQABGAFAATwBBADQAKAAhABkAFwAeACMAKAAvACwAKwAkABUABgDz/+3/7P/y//j/AwAPABUAGwAgABYACAD4/+v/5f/l//T//f8JAA8ACAAAAPX/8P/p/+X/3//j/+v/9f8IABcAIwAgABIABgD+//z/+/8EAAgADQAVAB8AKgAhACIAHQAQAP7/6v/c/9L/2f/i/+n/8//1//X/+f/4/+n/4//h/+P/8v8LABoALwBBAEMAOwAtACcAFgAGAAUACAASACMALQAzADUALAAlABsACgAJAAoACwATACIALgAwADIAMAAsACEAGgAaABoAHAAmACsAIwAjACQAGgATAAkA/f8GAAoAFgAjACMAKgAuADMAOQA5ADYALwAnAB0AFgAQAA0AEQAIAPf/4//Z/8z/u/+5/63/rv+y/7n/yP/L/8v/xv+8/7f/uf++/7L/nv+J/3//nf/b//L/w/+N/4n/o/+t/6f/lf+J/4T/n//L/+r/3//I/7b/qf+v/7r/tf+6/9n/4//c/9D/3f/q/9//zv+4/6r/r//B/87/2f/j//P/AAANABUACQD1/+L/6f/v/+3/7P/1/wIADgAEAAAA9f/X/8H/u//L/9f/9/8IABUAHwAZAAAA8/8KABUACQD4//X/CAAgACEAFQAFAP7/+//y/+j/4v/l//n/BAD9/+//7f/5////9v/t//r/CAAWABoAIgArADIANQA3ADEAMQA0ADIAOQBFAEwATABPAFYAYABjAFsAVABGAD8APAA8AEAARQBSAFgAYgBXAD4ALAAcABYAEAAOAA0ADAAAAPz/BQADAAIA8v/m/+P/2P/T/9H/0P/M/8j/yf/L/9X/3f/a/9H/xP+5/7f/q/+v/7b/vP+//7z/vP+4/7T/q/+x/7j/zP/i/+7/9f/7//X/6f/W/8b/yv/O/9X/3f/v/wYAEwATAAwA/v/u/+P/3//k//H/BwAUABgAGQAVAAwACAAGAAoAEwAiADIANgA2AC8AJQATAAsAAwD+//7//v8JABIAEwAIAPP/6//m/93/3P/b/9r/3P/V/9T/3f/q/+v/5//e/9f/0P/M/9P/2v/p//T/BQAbACUAIwAkAB8AEAAFAAgAEAATAAsADgAVABcAHgAeABcAEgAOAAoAAwADAAgADQAUABMAFQANAAQABwD7/+7/4f/a/+L/6P/u//P//P/+//b/8v/0//r//f8CAAAABQAKAA8ADgD///D/3P/X/97/5f/q/+//8f/6//z//v/2/+X/2P/Y/9T/2v/q/wMACQAFAP//5f/P/9T/4P/j/+H/3v/i/+T/8P/y/+f/5v/t//n/DQAWABsAJQAhABsAFAAMAAkAAQD8//L/7P/r/+j/6v/w//f/+P/3//X//v8AAPn/8f/n/+j/6v/x//L/9P/4//f/7f/o//D/+P8AABIAKAAzADkAMwAtACUAFQAHAPf/7v/0/wcAHAAoACcAKAAiACIAIQAZABoAHAAyAEoAVABXAFgAWgBXAEgAQAA7ADgAQQBMAFYAWQBbAFoATwBAADEAHgAQAA4ADwASABYAHAAeABQABwD9/+7/6P/g/+X/6P/2/wkAFgAkACIAHQARAPn/7P/m/+n/7v/0//v/+f/2//b/8v/t/+3/4f/V/9H/0//e/+T/8f8DAAcAAwACAPn/7//z/+3/7f/u//T/9//5//7/9v/u/9b/vP+t/6j/tv/L/93/8P/4//j/6v/T/7v/oP+d/6v/uP/K/93/3//Z/8f/tf+z/7L/wP/M/+T/7P/u//b//P////T/7f/h/+D/2f/W/9H/1//M/83/0f/P/9b/2f/m/+n/6P/f/9r/3P/e/+X/5P/r//L/+f/z/+7/7v/s/+v/7P/x//n/BQAFAAMAAgD///v/BQASABkAIwA5AEEANwArACUAJQAfAB0AHwAeABEACwAMAA0ABwD///n/8f/r/+b/5f/q/+X/5//p/+D/3f/W/9L/zP/N/9L/1//i/+n/9//+//L/4//j/9j/0P/P/9n/5f/w/wAADQAPAAsACwD///L/8v/2/wIAEAAaABwAEQAJAPL/4f/X/9D/1//h/+j/7v/z//X/8//r/+r/6P/p//D/+P/8/wEACQAIAAIA/P/7//j/+//5//P/7v/p/+P/3P/a/9v/5//t//P//P8AAAQABwAQABoAHgAuAD8ARgBDAD0ANgArACAAKQAuADIANQA4ADQALAAXAAkABQAGAAwAFAAfACQALAAvACsAFwAHAP7/+//+/wIABAAOABcAFgARAA0AAgD3//f//v8FAAUACgARAA8ABAD2/+//8P/r/+7/8//3//3/AAAGAAwACgAJAAAA+f/r/+D/4v/t//n/+v/8////AgD9//j/+P/9//T/7v/x/wAACgD6/+b/5v/x/+7/8////xMAEgAPABYAGQAbABcAFwAXABcAHgApAC0AJgAlACMAHwAhAC4APQA8ACsAJwAmACwAKgAwADsAQgBFAEcATwBPAE0AOgAtACoAMQA3AD0AQgBBADUAIwAZAA0ACAAOABsAIwAwADYAMwAbAA0AAwD3//X/+f8OAB8ALQApACYAGAACAPr//f8IABYAKgA4AD8ANwArAB8ADwAFAAYACAAKAA4AGwAYABoAEQAFAAEA+//w/+T/8//4/+3/5//d/83/xf+//7n/sf+i/6L/qv+s/7D/qf+u/8L/yf+9/67/q/+v/6r/ov+k/6v/s/+2/7T/qf+W/4v/hv+I/5H/n/+1/83/5f/0//T/6f/S/83/2f/s/wgAFAAdABkAHQAeABkAKAA8AEcARwBNAEMAOwAsABUACgATACEAPQBKAEYAMwAJAOr/5v/k/93/2//c/93/1P+0/4//c/9o/2z/gf+b/7v/yP/G/7L/jf9w/2n/b/9t/27/eP+F/4//jv+K/3z/dv+G/5b/pv+w/6z/rf+j/5j/k/+k/7b/zP/q////EwAmADQAOAAyACgAJQApADcASwBbAGMAbQB1AHEAYwBRAEwATQBNAEwATwBZAF4AWgBPAEgAPwBFAEgAOwAsACIAGgAUAAoABAD///T/7v/b/8f/of+G/3f/c/94/4j/lf+M/4b/bf9N/z7/SP9g/3j/kf+d/6z/uv+9/6r/mv+f/6H/q/+1/8L/zP/L/7r/rP+m/6H/pP+s/7j/xf/T/+L/7f/y//D/8//0/+z/1f/C/7n/xP/g//f/DAAcAB8AEgABAPL/9/8CABAAGgAjADYAPAA9ADkAOQA2ADsAPAA9AEsAYACAAJAAowC4AMkA1ADVANkA3wDsAAYBKwFDAVYBWwFZAUoBOgEuAS0BMQEtATcBNQEkAQoB9ADbAMEArwCkAKcAqwClAJYAegBXAEEAOgAwACYAJAAlACYAHQASAAAA8P/h/9H/xP+1/6n/kf+B/3P/af9r/3P/f/98/3n/bf9m/2H/Xf9W/1z/Xv90/5H/pv+s/6H/kv+S/5b/p/+9/8r/0P/S/9X/yf++/7T/t/+4/8b/4v8AABMADAD5/+X/1P/J/77/u/+9/8X/4f/4//v/9P/h/8n/r/+Y/5D/j/+W/5z/nf+W/4r/d/9v/2D/Tf8//zz/Q/9Q/1r/Xf9h/1//YP9h/2z/Zv9X/0X/O/9B/0r/Wv9t/3T/av9Y/0P/Pf8+/0L/T/9g/3P/fP+H/5H/l/+c/57/of+i/6D/rv+0/7L/vf/K/9n/3f/c/97/4//p//v/FAAxAEkAVgBbAFgAUQBOAFYAYwBvAJYAvgDjAPsABgEBAfAA2wDYANoA5QDwAPkACgEZASkBKwEUAf0A6ADiAOAA6gDxAPgA/AD3APEA6ADYAMAApwCaAIUAewB6AI0AkgCLAHYAXwBBACwAHAAVAA4ABgAEAAIABQD///n/5v/P/8H/wP/N/9X/0P/H/8z/0P/F/7L/of+T/4z/lf+h/6z/vv/E/8r/xf+//7T/qf+l/6j/tP/D/9T/4//2////AgD3/+f/5P/p/+r/9/8HABQAHQAkACoAJQAjAB8AKQAvADAAOgBAAEMAQQA0ADAAJAAVAAgABwAQABEAFwAaABgAEQABAP//9//t/+v/4//e/+D/4v/j/9v/xf+z/6b/o/+n/6T/pv+m/57/lP95/1//Qv8u/xb/Cf8K/xT/GP8Z/yH/GP8Q/wX/+f7o/uT+5f7f/uX+8v7//gX/B//6/u/+5P7m/u3+7/7+/v3+Av8I/wf/BP8E/w3/Fv8b/zH/SP9c/3H/fP+K/4z/jv+S/43/lv+t/73/1f/g/9//5f/f/8//s/+i/5X/kP+Y/7T/0f/q/+z/2P++/7L/sv+w/7r/5P8CAA4AFgAWABoAFAALAA0AHQA5AFwAfACUAK8AugC8AL0AxADHAMYA0gDeAPMADAEoAT4BTQFcAWABXgFoAXgBhwGWAZ0BnwGnAbABpAGLAWMBSQE2AS4BMAE1AT8BNwEhAfkA0QCkAHAAQQAsABgABQADAAwAAgDd/6f/g/9k/03/SP8z/yb/HP8V/xD/Af/q/sv+u/6m/p3+nP6o/q/+vv7J/s3+zv7I/sH+uf65/sL+2P4A/y3/Sf9j/2n/Y/9r/3r/mf+7/9//BQAyAE0AWgBiAFoARwA9AEAATABhAHMAgwCVAJcAhABsAFMARwBCAEgATwBWAGIAcAB7AHkAdABeAD8AIgARAAgA8f/k/9L/xP+z/6D/fv9S/xz/8P7e/uj++/4M/xv/Gf8A/+D+uf6S/nn+bv5+/pX+sf7H/r/+rP6T/oD+bP5j/mX+bv5u/mv+aP5//qv+zP7W/s7+xv7D/uD+Df8x/0L/Vf93/6f/4P8YAEsAbwCLAK4A4QAyAZUB9gFHAnYCfQKKAqkC1wIRA0ADZwOKA6cDwwPHA7kDmwNrA0ADHAMWAxUDEAMEA9YCnQJjAiwC7gGtAX8BXwFMAT4BNAEdAfkAtQBmABkA1f+o/4L/Zf9C/x///P7T/qb+a/41/v790v3C/b79v/24/bz9u/25/bL9tf28/cf92/3s/fr9Df4p/k7+bf59/o7+j/6X/qf+vf7Y/vv+K/9Y/3r/jf+f/6r/sv/C/9b/9P8cAEwAhACuAM8A2QDWANUA0wDgAPcAEwEhATUBRAFMAUUBNgEhAQgB+ADrAOUA7gD7ABIBHwEZAQgB9wD6AAEB/QD5APgAAQEGAf8A8wDiANUAvwCwAJYAfgBqAFMANgAKAOD/vP+d/3z/V/8y/wf/4f60/oX+Y/5H/jn+K/4i/hL+/P3o/c79vf21/bj9tv2//bn9s/2x/bX9uf2+/cf91/3v/Qb+Hv4x/kr+av6W/sn++/4v/1r/gf+n/9P/BQA7AHYApwDSAPQAEwE+AWABfgGdAbEBxgHWAeoB9AHuAfAB8gH3AfMB6QHlAdgByQG4AbIBrgGjAZgBfwFhATwBHgEMAfQA4ADXANAAyACrAIQAXgBDACEADAD///X/7v/Y/73/n/+G/3H/YP9S/1H/RP85/yj/Hv8Y/xb/Fv8Q/w7/EP8P/wP/BP8I/wv/EP8F//v+9P7r/uX+3P7S/tL+z/7U/tL+zP7Q/s/+0/7O/sv+yf7U/tz+5/4B/wj/Fv8e/y//RP9Z/2n/hf+c/7n/2v/2/wcAHwA9AFIAbAB+AJgAsgDWAPAACgEiAT0BTgFkAYIBlwG0AdAB7wERAikCNwIsAicCHAIdAg0C+wHyAeYB0wHBAaYBigFoAUIBGwHzANAAqgCNAHMAXQA7ABgA8//d/7r/mP+C/3v/bf9a/zz/Jv8O//7+7f7e/sf+rv6g/pb+lP6M/of+hP6B/n7+eP53/n3+i/6a/qL+rP7A/tX+4P7l/uL+6P7q/vr+DP8W/yP/Lv84/z7/Q/8//zb/O/8+/0P/Vf9i/2D/XP9e/1v/W/9S/07/P/85/0L/Vv9l/2n/Xf9X/1z/aP9s/3b/fP+B/5D/mv+l/7b/yv/d/9r/1f/Y/+f/5//d/9f/0P/d//r/HwBBAEUAOgBKAGwAigChALcA0gDzABgBSQGDAbYB2gHpAf0BKAJYAo4CuQLbAt4CzwLTAu0CDQMQA/UC1QLJAsMCvgK8AqQCdAIwAvMB1gHHAa4BfAFLASsBAgHiAMwAsgCFAE0AGQD7/9//tv+K/17/Pv8X//P+3P7A/pT+YP5D/jf+M/4y/iv+J/4s/if+Lv41/jb+Hv4P/hT+M/5S/nP+i/6l/rv+z/7k/vT+Cf8c/zf/Vv97/6X/xv/k//b/AAAUACgAQQBbAHcAjQCnALcAyADYAN4A5QACASMBOQFMAVwBYAFeAVcBUgFeAV8BYQFcAWMBZwFnAWABWwFRAToBHQEQAQcBAQHyAPEA9ADfAMwAwQC9ALAAoACUAI8AgQB4AGQAVABAAC0AFAD6/9b/rP+A/17/Pf8c/wr/9f7Y/rr+mf5y/k7+LP4P/v796f3c/df94v3q/fz99f3d/cf9vf24/bT9s/29/dH98P0L/i3+Sf5k/nj+jv6k/sP+4P4G/yb/Rv9q/4X/oP/C/+f/DQAyAFQAiAC4ANsA9AALAR8BOQFJAV4BZQFtAWsBcAF3AXkBfgF6AXkBcwFnAVgBQwE0ASEBFgEOAQYB9QDlANUAwACoAIsAcgBcAEwAQAA4AC4AIQAfAB4AKwA5ADYAJgAgACEAIQAmACoALQAlACoANgBAAEIAOwAqACcAHQAUABcAGgAYAAoA+P/q//L/AAAIAAMA8v/f/9H/2P/e/9H/s/+b/5r/nv+e/5b/kP+K/3v/a/9j/27/cf9f/0j/Mv8g/x7/G/8a/wn/A/8B/xb/Kv8y/yz/Hv8i/xn/HP8m/0D/Vv9h/2X/fv+T/7H/u//C/8j/xf/K/9r/8f/0/+b/3v/i//X/AwARABUAKQAqADcAPABLAFkAWwBUAFcAYQBuAHQAdgCBAHsAdAB3AIkAigCDAHgAcgBuAGsAYgBYAFcAWgBVAFYAXQBjAFEAUABXAGMAZwBwAHEAbgBaAFIAVABbAFwAXABjAHcAggCCAH8AbwBgAFYASAA5AB0AGQAiADEAPQBEADYAFwABAOX/0P/H/8f/0f/h/97/zf+5/7f/sv+x/5f/gf98/4b/kv+l/6L/g/9M/yr/Gv8m/zv/Tv9f/1f/Sf9F/0r/Rf8p//7+8v76/g3/FP8c/yT/Iv8A/9v+x/64/qj+lf6d/qL+lP5+/m/+aP5W/jj+Gv4b/iv+Of4s/hj+Cf7x/fH9/v3+/fz9Bf4e/lD+iv6s/qv+mP6Y/rf+2/4Q/1n/sf8NAEsAgwDMACABZwG/ARwCgALXAigDjgMQBHMEowS5BO8EPQWABbkF6wUNBg8G/AX3BQMG8QW+BZMFeAVHBfcElgRdBDYE9AOtA4EDTwP+ApQCNQLWAWcB9gCVAF0AMQDm/6n/ef88/+L+df4Z/tT9lf1b/TP9Ef3i/J/8T/we/Ab8+/vl+9z77PsL/Bf8Fvwa/C38Q/xX/Gz8ovzq/CH9Xv2X/eX9KP5S/m7+oP7W/v3+If9a/5D/s//M/93//v8rAEsAXwB5AJMAoACxAMwA5wADARoBOAFjAYoBpQHBAdwB6gH4AQsCKgJJAmUCdwKDAoYChAJ9AnUCcwKDApwCrQKtAqkCngKQAnwCcgJ8AnwCegJ9An8CfAJoAk8CLgIPAuQBuQGZAXUBRgEIAcgAhQA7AOL/kP9M/wr/w/5z/i7+8/2l/VT9+vyy/G38MvwJ/PH71fu4+6T7k/uE+3P7afto+3j7j/un+8X78PsJ/BT8N/xj/Jb8yvwF/Ur9ev2o/eH9H/5q/rv+Dv9r/83/MwCUAPIARgGFAcEB/wFKApMC1gIOA0MDaQN/A40DjwOPA48DiAOFA3oDagNBAwsD2AKsAoACSwIXAvIB0gGmAXYBTAEhAeQAqQB2AFIANwAVAP3/5f+4/4L/Uf84/x3/CP/d/r3+l/5j/jP+/f3P/ar9jv2P/ZH9k/2F/XT9Zf1d/VH9Tf1Q/WX9iP2z/dP94P3d/df90P3U/eH9D/5L/n7+of6d/nv+Qv4P/vz9+/0O/jf+d/69/uz+7P7M/pT+bf5t/pX+2v4F/yn/Vf+S/7j/u/+4/8X/+P8wAGIAmADRAOUA6wAEAS4BTgFdAXIBkAGxAa8BpgHKAfkBEQIPAhwCSgJ1AooCmAKgAp4CiQKTAsoC/gITAw8DEAMdAygDFAP9As8ClgJsAnACdwJlAiICzQGJAWABLgH1ANUAsgB5AC0A/f/U/7j/of+B/2L/VP9W/1v/W/8y/wD/6v7y/vr+BP8P/xz/KP8l/xH/9/7j/s3+x/7U/uT+AP8d/zT/Kf8V//3+Av8W/wv/+/4A/yf/XP96/4b/f/+C/5r/v//n//n/9v/x/+3/7v/q/9z/1f/g//7/DwAXABwAFQD6/77/ef9k/3z/m/+Y/3X/S/81/y3/Lv8a//T+zv6u/q3+xf7Z/tf+vv6q/pL+dP5k/nj+kv59/kD+If49/oD+uv7j/uv+yv60/vf+ev/q/xMAEQBDALUAKgGMAfkBYQK+Ag8DdQPvA1cEggSZBL4E9QQkBVQFtAUZBi0G6QWiBX4FaAU7BfEEpQRiBCgEDAT5A7UDNgOyAmACOQIBAp4BPAHmAKMAagBFABQAvP89/9b+rP6N/lP+4f2J/UT9E/35/O/8zPyS/FH8E/zz+9n7x/up+477kPuv++b7KPxV/Gj8evyJ/L/8D/1j/aP95P0j/nj+3P4y/3j/m/+y/8z/+v86AHkAlwCdAKsAwADLAMsAygDCALYAwgDyACIBOgE2ATQBOQFGAVgBbQGDAYsBhgGXAcAB7QEDAgwCEwIbAikCLgIqAjMCMAIiAhMCFAIZAhwCFQL8AdwBrAGLAXgBggGAAXYBWwFOAUoBPgEoAQUB8QDmAMoAqQCKAGcARQAQAM7/gv89//z+vP6J/lj+Gv7M/Zb9aP1L/Rv96PzZ/NL8w/y4/LX8uvzE/Nr8AP0q/UT9Rv1g/Yv9tP3G/eL9CP4x/lr+hP6z/s3+uP6i/qn+xv7W/un+Dv81/0T/T/+G/8L/2f/e/+P/+v8eADsAXQCFAJUAjwCWAK4AtwCpAIYAawBjAFkAOAAbAPv/yf97/0j/K/8R/+r+0/7P/s3+w/6q/qj+of6B/k/+Qv5p/pr+uv6//sf+1v7h/vX+Hv85/zP/C//4/hH/NP9C/zL/MP80/z//Tv9h/3H/cP9l/2n/ef+I/43/lv+n/7j/y//T/+P/AAAqAEcARABJAFsAdACAAJwA0gAXATwBOAEsAR0BEQH9APcAFgE7AUgBTwFTAUwBLQHyAN8A+gAWASsBSwF0AZgBigF1AXMBpgHSAfoBHAI7AlkCVAI5Ah0C+gHMAaUBmAGeAagBmwFvAT8B8gCnAGoAQAAWAOT/uf+l/6H/m/+G/2H/Pv8r/wj/1/6p/o3+lP6x/r3+rP6S/nv+c/57/pL+jP5w/mv+jP7J/ur+8v4C/w7//v7m/uH++/4r/1z/nv/i/+j/vf+o/7r/uP+G/13/ff/T//X/1/+9/63/nP9r/0j/PP83/wz/CP8X/zf/NP///tf+2/7G/oD+Rf5F/lT+I/7K/aT9zv3//dv9h/04/TD9Uf2H/dT9Af7w/fX9UP7v/l7/j//D/00AJAH0AY8CMgPMA0QExQR+BTUGpwb0Bj8HlQfgBxUIXgjKCAcJ2Qh8CD4INQghCNAHbAcDB5wGQQbzBa8FRAWMBMUDWwMvA+ICWwLLAWwBGgGoADAAxv87/43++P2r/Wz9Ev1+/Pn7sfts+yT71fpw+g/6vPmW+bX53Pnw+ez52vnT+ff5S/qj+gH7avva+z/8ovwN/Xj9zf3+/T7+nv4V/4//DgBsAIwAfwB0AJEAuQDSANkA+QAeAU4BeQGUAYYBZQFDAUQBbwGlAdcBFgJhArQC8wIXAzYDYQOJA8ADEQRyBMYE+AQXBTMFTgVcBW8FgAWaBZIFdQVmBV8FRwUQBcwEdAQWBLkDXAP2AosC+AFfAc4AUADl/2//1f4Z/mD9rPwA/Fr7ufog+qD5MvnT+F/4zvcz97P2UfYE9tb1r/WV9ZP1nPWc9YL1ZPVi9X71uPX+9V/2xPYf93v33vdD+Jb40/gn+aT5Nvqi+hT7lvsh/LL8Pf3J/WP+//6c/zcAvQAcAW4B2wFcAuUCdQMFBJMEBQVUBZsF2gXvBfUFCQYpBlgGgganBtcG/Ab0BtAGqwZ+BngGfgaEBnsGTgYXBvMF9AUKBgQGxAV8BUkFOQU+BUEFKAUHBdUEkARpBEUEHwTuA6wDQwPVAnMCFgKmAS4BuABcAO7/aP/s/mL+v/0B/Vb86Pua+zr74Pqf+lL69fmL+TX56fiw+Jj4z/gr+Wv5h/mH+ZP5svnU+Qb6TPqN+s76GPt6+8X7/PsT/Cf8P/x7/NL8L/12/aD91f0q/oj+zv73/g//Mv9o/6r//P9iALgA7QDzAOoA7gAZAWQBvgHzAd8B6gE2Am8CdQJMAiICAQIUAlcC7wKHA6ADSgPsAuUCMgOaAxMEcARrBEkEegT7BGAFVwXoBJwEwgQ7BeIFiQa8BmkG8wWuBZUFqwW4BYEFJQXZBOUEDAX2BI4E1wMEA2cCJAIHAuABdQH3AI0AFACm/1b/+/57/gX+1f3c/bT9V/3+/Nz85vzI/Jv8j/x0/DL82fuh+5j7gPtX+1H7Xftk+3X7jft/+z775frE+hf7qPsN/DX8G/wC/Eb80vwx/S79Kf1J/Zz9/P0//nv+of6m/rX+A/99/9r/9/8AABoASgCRAMoAuABuAE0AkQAwAdIBRgJ5Al0CEALYAe8BOQJgAlsCWQKWAvQCRgNdAxoDuwJnAmYCpgITA4sDeQPUAh0C3wEjAmwCeAJ3AmwCMgLGAZ4B7AEJArkBUQEuASoBDgHOAJEASwDg/37/Y/+K/4f/SP/y/pb+Lf7v/ej9wf2E/U/9NP0s/S79Lv1R/Y/9pv2F/Xv9m/21/ef9Uv7Q/kz/tv8EAEAAdQDPAC4BhwEQAqgCFwMkAw4DOwOyA+4D0wPMAxMEXARqBGAERgQIBJ8DPwNKA4QDfQP/Ai8CgQEcAe0AugBwAAQAif8m/+T+pv5J/q/9Cv2z/I78Tvz2+8b7w/uz+4b7VPss+/n6wfqr+rr6y/rc+uf69frc+p/6lvrx+mP7lfuQ+8j7MPxm/HT8kvzQ/Ar9S/3T/bb+fP+e/17/TP96/83/VgAGAboBVAKxAtEC5AIEAzwDeQPGAycEhATaBEYFzQVHBnUGHwaVBU4FdgXiBTcGKga+BUwFDAXgBK8EkQRdBOUDWQMCAxsDggO/A2gDvAJHAjECWAKXAvYCWgNgA94CWQJcAowCiAJJAigCKQIEApwBCQFqALH/v/7J/RT9rfxR/NP7Ivs8+hb5sPeI9uX1ovWJ9XL1N/Xc9JH0fvSi9ND0CPVg9d71WfbH9mn3APiJ+A75m/ld+kX7EPyU/OH8IP1h/Yf9bP1T/Xz92v0a/jP+TP4t/sz9Vf0k/Vf9o/3f/S3+rf5p/zcAAQG8ATgChgLqAq8DAgWgBhMI9QhaCcEJUgrpCnsL/wt1DMwM5Qz9DDoNXw0eDcUMngyBDEwMDgz/CwQM8guJC8sKJArgCfQJAQrSCXMJywi7B3UGiQUhBZgESQOnAXcAtP+6/j39pvse+nr4tvZH9Vj0v/Mh80XyQ/FJ8KPvaO+B79DvO/CU8Mrw9PA28a/xR/Lk8obzH/TV9K71b/bI9ur2Bvcr9033Wfdp95P3qve399X3/vdB+JP4Kvky+jb71vsE/DP8AP1U/rj/EgGOAkwE9QX7BoQHRghlCZQKlAubDJMNJA77DZcNfA2FDesMyAv5ChYL2AtPDDQMKQtCCVYHTAZcBgIHiwf9B2AIpwgqCeQJbAo/Cp4JYwkwCuILlQ21DiwP8Q4LDiENiwwsDNELZwvlCjMKEQlnB00FIQMwAXX/zf0S/JX6kPmf+Ej3yfW69NnzvPLL8ZbxEvKX8nTy4PFl8SjxOfHl8THzRvSE9A30p/O28/rz3vNH86jyZfKz8mTzPPSl9E/0cvO58tTygvNw9LT1MPdu+BP5aPlA+mP7Ofz4/Gn+iABhAmoDaQTxBSsHUgfeBtYGhQePCH0JQQrDCqsK9wkuCfEIVgkJCpwK6ApDC+wLuQxXDdYNZQ4RDwcQVRHbEi8UGBWlFe0VCxbTFV4VERW5FPsT0BJSEWQP7gwsCqIHXwXSAsn/4fx6+if4ufVw83fxhu917eDrU+uA64LrFuvd6lDrJuzZ7GbtOe5l7zXwYfBz8Pvw9vGa8kDybPH28ATxKfHw8ILw++9f76vu5u1X7THtTe177fntG++I8J/xJvK98kL02/ag+br7ef2T/xICsQTIBmgI+gmvC1INqg7zD3wRExM5FJQUMRSzE0sT2xKEEm8SZBIDEj4RghBnEIgQMBBHD1IO5Q3eDbQNhw2nDcUNQw0PDCALLAupC4YLaQoHCeUHnQYBBaIDuwKhAen/Pf79/Mv7Kvoi+FP2G/VV9Mfza/Ma89Dyc/Ih8qPx+PDV8F/xNvLE8u7yQfMW9AP1U/UT9Tr14vUI9nD1CfUa9XT1ufXe9RD25fX09Mzz9PNm9az2Xfcp+B35kPng+fn6C/3t/vz/KAFQA7cFPAdjCCQKtAsrDGUMeQ0nD50QdxG7EW8RlxDpDyMQLhHVEYMRARGTENwP6w5+DowOcw73DUMNfwy8Cy8L0Qo/CjQJAwhfB34HYQdyBjUFGgTFAhMBzv82/3z+NP31+0f76/oK+pP4avet9qn1e/Tb88fzcvPf8rLyqvIr8m3xcPGi8hT0h/RT9F30ovST9LL0rvW49un2+PYU+Kj5Y/o/+lf6/foB+w/6wPk0+xb9B/5t/sf+nv6G/Zb8hv0YACICkQJIAksC8QL7A10FsAbyBn4GgwZoBwIJtQqxC1wLBQryCFQJugpyC6IKZgnICIUI+AdLB98GBAYwBEkC7gFnAyUFUgXbAyECJwHqAGUBggLnA4oEXgSHBI0F9AaIB5UGFAV2BCYFuAbYB3UHzgXCAwACtADe/zn/F/4s/Dj6GPlb+N/2ofSq8sPxbfEA8YbwefBI8CrvA+7i7dfuEPDd8IvxCvL/8YzxRPGq8ZLya/PO82Hze/IT8rPyEPTs9Gj0M/NZ8gryHPKs8gX0gfVq9tf2sPd2+bH7N/1P/gQAQgLgBOsHWwvRDnMR9xL5ExEVnxZvGOsZiBsVHdodkx2jHJ8byRpFGu0ZmRkeGSkYfRaVFI4TfBOpE0ETRBJJEcgQuhBqEJEPkw7iDa8NYA2qDJoLDgrmB1cFAgOUAYMAjP6e+7T4Qfbt833xEe/N7N7qGOll5zvmX+Vs5KvjgOPp43jkweTt5Evl5eXy5nXo/el/67bsc+3z7XXu4+7x7v/urO8K8a3ysvNY80XyY/Es8ffxY/O69Hj1m/XS9an25vdP+cn6OvzH/Yb/GAK1BX4JYgxKDvAPExLRFOYX/hpwHa4eDB8yH20fwx8uIE0gvh9KHrAbsBhnFusUcxNnERUP6AwgC7IJYwhSB9YGJwalBHcDjQNJBNwECQXnBMkEHQWyBfIF1QVIBW4EEARyBIYE2gPBAvkAk/5q/MH6DvlB96T1A/Rn8hfxEPBN76ru0O2u7Nfrwusa7NPsHe5N78Dvw+8R8M3wnfGL8m7zLPTI9BX1r/TK8yzz6PLs8hHzt/LI8SrxD/Hf8HbwRvCZ8F7xH/JH8l7yHfN09Ln1Z/b99q34efv3/Tn/BQDXAfEEnAdoCCoIjghYCugMzQ7qDxsRHBJ7EloSRxLJEhcUWRWkFTUVtxQhFZAWGhi0GGEY2heYF1QXGReWF4kYERmRGP0WMRXFE4MS+hBBD7YNPAxzCsMIWwewBfUDVgJoAF3+Cv2q/Kn81fvE+aT38PZz97z3NfcM9q/0iPPg8tvyBfPz8lXyF/Gc72buzO327RHur+z16c3nXOf2523oEuj+5tHl6ORM5HTks+Vl57XotOm36vXr0O0j8BHyjfM09er2jvh3+r/8MP/EAdcDyQQPBVoF2QWjBqkHRQgaCNcHFgh/CH4IIQh2B2AGpQXGBbMGVwj8CaMKowoGCzYMOw7mEEATYRSrFEYV6xZTGYgbehzlG6MaXhmmGNcYLRmSGOIWxBTtEnQR6g8hDkkMVQrxB0cFFwMBApgBzABS/5r9BfzI+ir6CvoB+oX5VPgi98H23vaN9o31ZPR482Py5PBj71Puvu0v7RLspeqv6V7pY+lr6TTp9uhh6ejqDO0/70zxG/PO9KP2uvgQ+579EQASAuID2wXfB6AJ+wrHC+ALkAsnC98KwQqMCuAJqwj+BtsEmQLJAH//W/4Z/dL7yfpm+p36vfp4+l76wfpj+0D8Vf1U/mD/aAAEAXsBMAKHAvQBGwFoAOX/lv82/zP+gvx2+mb4LfeM96D4hPjG9rj00/O59Af3dflY+yf9A/+EANMB5AM2B2kLNw+CEakSSxR/FhUYCRkRGtwaoxolGfMWYRWvFIwTYREoD3YNyQvLCXAHqwQ2AuUAbgBRAEMA6v8o/1j+o/1U/RP+OP9q/6f+Pf6q/nL/8v+N/+D9GPsA+Nf1jfVO9iD2GvQM8djtDOtZ6R3pqunb6Svp/ufy5k3mHua35m7o7Oot7TnuHO6q7d/tSe/X8b30e/aF9sj1Q/Vu9Vf2yfen+DL4uvYr9ef0fPay+Mj5Ivrn+vn73fwM/koAkwNOB7kKng29EBoUjhb3F5MZPxxJH48hkiKYIogiASOJI4UjqCLMIGAe9BvpGaEYIRidFxcWlxPEEDUOOgwNC4sKZQo6Cl8JAAggB/EGwAZLBiYGZwZDBlcF6AOoAvEBOQFFAGL/Tf4i/AP5L/Zc9Bbz2fGB8CfvoO3w66Hq8Om66Zrpqenb6ejpy+kH6h/rsezR7fbto+187cntou7u7xrxYfHP8DXwVvAt8RjypPIC80DzAPM68sfxh/L38zH1/vW39sL3J/kG+vX5r/nt+af6wvtn/VH/9QDWAa8BmwCM/8f/yQHzBKoIpAvFDGMMlAvXC4AOCxOUFn4XBherFt4WGxieGnQd5h7cHXkbVRp8Gx4dTx2OHMIbfhqaGCMXJRfyF+UXGxZBE/gQwA8CDykOtAxeCswHzQURBNQB+P4O/N352/gp+E32N/PM7+jsOevK6onqjuny51Lm8eRG5O3keeYl6Czp/ejk5+bmnuZP51TpEOzA7TDtA+sy6enon+lF6tPqleuc63Xq5ujA59LnFemu6rzrPOyJ7Dvt1+5j8efzSfbG+Vz+ZgLxBOAGKwn6Cy4PrxLdFWMYxxmYGU4ZYRrzG4oc+xuGGqUYeheBFxgYqRi6GPcXtBaxFSMVOBV2FjMYARnAGN8X8RalFikXlxdaF+0WOhbfFAET6hD+DtAN5AzQCmoHBwT1AJr9a/rN9571vvOj8eXu1eyg7Cbt3ez868vrzOyQ7jXwPfE38qXzP/WI9oP3LPgi+J/3N/cK9zX3mfeR9432rPQl8pzvGe7i7Vzut+6k7vrtDO1z7Irsku217xzyjfOc9Hn2Cvn6+/7+8AA1AcMA1AA7AtwEXQcUCJ4G8QMaAWr/Z/+l/0H+Nvv096r10vT+9Nf0wPOy8g7y9/FV8w72Xvg7+YP55Prt/n8FNQxwEHESthPiFN8WWxpzHq8hXCNAI8ohtiDNINwg7h+/HWoaTRfHFVsVnxR9E/MRUw9ODHsKaQpwCwQMyQp2CA8HJgfBB4YIvwg+B08EWQER/1r9cPzM+1b6mffX867voOyI6+jqyehj5QjiZd9N3oreCt9W3zDfPN4s3UTdlN793xXhKuJQ4yLlvefl6bXqyerZ6ujqkut/7QHwifLb9N/1PvW+9O/1ZvhN+xn+fwBkAj4ElAYtCUwMGxB0E7AVehcbGcEazhxEH18hsiJaI14jKyMRI9UiayJHImwiPSLLIUMhkCApIGkgxCDJILIgXCCgHyQf+h6DHvgdmR1uHPAZOBedFNcR3w45CzEGYQBs+7T3jfRm8VLtzOfI4cjcNdnB1k7VmNRM1BXUg9Nw0uLRo9IU1MnV+Nek2mfdv99B4dDhs+G84U7ibOO25F/lI+Up5KfiRuGW4NngN+LW43LkA+Tr42jluugA7t/0wfulAEkD8gUgC5kTkx0NJtcrdC/YMQY0JjiQPotG2kxOTqBNXEreR8FJykxoTjNLMEPAOkM0pi9/Kw0mfR5kFeIMkQYiAir+P/mq8mbrJOXP4AXfNd9J38rdNtv22OXXFtio2OrXqNVc0zbSOdLN0jnTsNGIzQHJ98Y5yDzLs83VzfDLnMroy5rPwdRg2s/eU+Fg48zm/etD8hn5qf/BBOUHAApJDYoS0RiaHtMiNCWeJfUk1CTvJngrCjCHMqMyizHcMF4xoTJAM7gyDjKLMgA0ijQFM88wHi8ILQkqRSdzJV8k/yK8H8saQBVKD/UIwALF/C728u9A7F7qsObe3z/YOtLczg7Nc8uzysjLIs39zKXM3c130GXTwtaB2urdHeG/5KjozuvN7R/vMPEU9AL2zfb199b5IPuQ+tP4+Pf1+Ef6pPqi+vj6F/tx+pv6U/wS/oT/SwGQA8IGYQqBDZUQ8xNEF1caHB1KH1Uh5iOUJpUoKyrAK/0rsSq1KScpCCgtJmwjPiBOHr0dVhzOGGQTmwwKBvQBdwBZ/x392fnn9QbyHO/j7Azr4+nh6NnnIeig6XvqderA6vjqKeoI6Sbp1+qI7IPsXus56xLs+Oum6nfpsegZ6I7o/+nF6ijqIOlx6eDrb+7X7lTupu/e8qr1QPfK+Ir6zPvd/Pn+TgJcBb8GIQe0B2UI6QiHCo4Nrw+ID9QO6g8YEjsTNxMiE8ITvhQxFe8VChjFGrUcxh2AHpkeRB53HhkgqCLyJOUluyRbIu4fix4ZH5sfkhw+FmkQUg0MDD8KZwbu/y745vGz7d3qpOh55czgbNwZ2Q3WBNR11KvWONhm2I3Yq9nT257eCeH+4lTl7Odk6ubsbO8C8cfwX+/z7fTsFuwy6/jqcuvZ6pvn9OKb38ne9t8R4ovkvedP7NXxXfdp/N8AvQV2DMMUVh05JRYswjGfNfA3hjnDOlI7cDqsNxk0njF9MDYvDCyFJjUgeRvLGNgWbhT+EfsQPBG3ELAOMw0qDVoNTA23DRcPjRADEYkQXA+LDZUL2gnRBy4EZP7h9+ry4e/C7A3oweEB27TVztKO0ZXQec+eznvOJM/8z7fQf9KV1hbc6OAJ5BrmOOjN6njtl+/t8PHxKfM99Jz02vPs8QPwhu8J8A/wCu/S7ebtAPDS8zP4hPvq/CH9Sf4VAicIhQ6ZEz4XeBpKHl4iaSVfJzwpaCs7LdMtei0dLQ4t4CzkKxUqVijjJuokLCLvH88fxiGRI6Mijx6eGRsXRBgxG7wcaBuOF2US3g1KC+cJVwchAoH7dfVl8AXsIegc5C7fGdmY0mnNjMrIyczKDsyZy0/JT8ftx8/LatEt1kvZzNuF3gjhXOOp5pvqSO0L7iPuG+/d8F7yFvOn8nHwVO0K7BLulvFW89fyzPGC8bzyHfZZ+qP98v9XAnQGhAz1EskYzx2eIZUkaCiTLb4ymDapOEs5MTlTOIs2ADQoMb0uaixvKXwmAyTcIOocwBgFFZ0SyBEVEuYSBxNREYQOJgz2Cm0KWwrgCngKsgdKA+f+8vr99hPzju/76xHn2OBD27zXa9Wj0nXPn8xLyi7Jockcy1DNmM/E0R3Ua9bg2K7bqt5J4qTmUOp/7K7tXu6t7r7uEO/87+XwX/Hg8VryafId8tLyI/YA/IUC7QdVDKYQ9xXzHJIlCy+aN/E9k0E3Q45EC0edSllNY02HSiNFmz0kNWctnCcpIwMeKRYCDCACN/tP+PD3hvcs9QLxdOyr6WbqMO+h9Z/5kvm09njz+fHP8mP0p/Qk8pfsvOWo337bhdja1F7Q+cunx/nD/MENwXbAD8G+w9bHYswM0RbWodtP4Y7nr+7e9noAcAomEokWtBgHGt0bgR9dJPcnbSiNJa4g4xusGO4Xwxh3GE8VNxCzC/oJwAv/DycVYBnqGroZiBjcGrUh/ypiM1E4PjmzN2w1bTTbNvE6rztwN88waCn+ITocrhfqEUYK+wAn9jLsIuU/4HLcE9k/1B/NRcbLwfq/X8EVxobLpM74zrnNkMy5zQrSJ9h/3lnjwuTE4jTgnt5a3VPcDNz22zTbgtnM1knT3c+kzSDOudL+2Q7gH+PX5PfnRe9y+4UJbBU9HvokliqCMJc4MUHiSPxNNE/wTUtKFUdrRMVCn0KsQVs+jzjYMCcpfiSmI4kk8CRPIxAfKBqzF0YY1xlQGiQZEhfwFJwSWxB9D/4PrQ8/DPQF7v4U+ZX0fPCI7Bnp0+VJ4eDau9OazaXJqMjcyfnKfspgyNvF1cRJxmDJ7Mxb0DfTE9VV1p3Xl9nB3MTghuT85o7nquYl5uHnLuyC8QD2zPjt+Tb6LfuR/e8A1QQYCXANexGAFIYVdxUOFs8XVRqYHIUdeh2FHb0dwh18HUcdxB0WH10gbyAkH6cdnB0dH+AgPyJ9IxskvSJiH+8b9hpPHZQgNiGOHRIX6BCNDUkNZw74DWMKAgWr/yH7b/hu+KH5Svmn9dXv3OrA6LXow+iA6EvomudN5WjiweCK4Gjh9OIv5Bvku+LN4D3gLOIf5Rvn5ecv6HPo6Oi/6U3rk+0+8ATzavVl9035I/sf/br/7QKDBtYJkwuwCjwIQwaXBYwGDgmRC8ILegi8Auf8k/nb+c38awBuAm8BSv3i91j1ffi2/2UH2QunCycJuAcKCcMNohSWGU8a/Rd9FKMR9hFqFTAZshpzGMkSOgxgCDAJkQ1mEvkUlBPWDhIKEQhFCVoMXw8CEKUN8glbBscDEgP/Al0BJv6y+V/0VPAE71jug+ws6jDoSOb7483hjeD44DfjZOZ76NXog+ha6LPozOnt6ynv4/K29eD2OfYS9AHy9fEC9H72YPh0+eL5+vna+fX5o/py+6v8zv7dAN4CwwU6CHAJDQv0DeoQfBL2Ej8UcRcaGzAeNCEzI7MicyC3HcUbDBx/HnghfSI2IOEb0BYyEuYPew/YDVkK/AZ3BF8C+f/X/MD5KPea9FzyV/BY7Qbpq+W25QvoQOmb5zPkmOAD3ojcOtw83lvhfeKU4RvhweCz35nfjuEL5VrpeO0U8KfwSPDA8LfznPk5AZ0H7wl6CJkGsAdWDG8S/hdpGx4bXxcWFOQUchh6GxMd6RwsGnkWyxRWFuIZPx2SHqMdyxtoGgUbSB67Iwcp0ysPLG0rfytmLPYt/y9NMY0voCoiJb0gZRzcFi0QBwi3/ffxhOfc3wbakNR/zqHHoMCHuiO2GLRStNy1VriWu+W+F8Iaxc7H5sp2zvPR4dWd2lnfZuLJ4nPhxuBY4mHloOg56yLsHusB6h/rju+k9bz6Pf6tAAwDyQZdDKoSeBi8HJUfUSO4KXkx1DcuOyM8UD15QO1DTkXLRDtEhkM0Qdc9kzqwNncxOizhJxUkWyDwG24X4RPdEEQO6AxVDDsLLgmHBwUIuAnOCWoH4ANJAOn92v0I/6L+LvqW8R3oGuKK4O7gZOAv3d/XQtLYzcfL+MudzM7Musy0zN3N8s930VjStdMf1sTYqNqU2/bb4tyS3/TjYOgL63/rUuqQ6BDo0umR7CzuOO7u7vfxdfWy9mf2efd/+10BXQeFDfETDRnkG/sdeyFGJzAu2zS/OYg60Te+NSk3czpOPA07ZTczM1gvBizVKaEpBit0K+coyyODHsMboRxUH6YhdSKeH6YYPhECDUEL8AlMCHkF/f+w94juAuev4gbhJ9/O2lDU3c3WyfzID8ojyx/L8cmDyGfIVMrMzTTSrdfD3WPiOuS45LbleOef6mrv6PQz+YD6GflR9gjz1fC58Uv1ffj++Nf2evOj8KLvmfLg+kcFegz6DZoLzQklDNwSPBy7JccrJCz7Jwkj4CBnIoUl4yZtJIod8hO0C5YHiwYDBWsBoP0x+yT5mfXi8ZXxv/VI/BoCLwWtBY4FTwZQCeUPzxj6H3EiFyGsHWAZ4xZEGYsfVCQZIpoYsg36BwIHjAZwBeACt/wh84rqsubv5k3oB+lh6M3lQOHz227Z5dyG5GfqTOuw6EHlB+PE48/nte3c8hv02/CX683lK+CB3P/cmuBX4qzerdcQ0gfRy9TF2Zrcq92u39zkgu3/9iz/2QZ5DqQVrBz6I+gqrDB6NRY5MjriOZ47jj4mPl44ry98KQQpIixHLr8sqSftIGMb9RhVGdIanRxHHlgduRitE0ERDhEeEQcQmQ2ECh4H3wJ1/tT6pvf08w3wvOyD6aTlmuI04gHjfuLV4Erg+eGp5OLm1ehw68Du9/Fo9Dv2C/iQ+Rz6IPoA+qn5J/k3+M31kfB96dbjMOGj4G7g4t6a20rYP9fB2HbbnN6D4kjnfuvZ7RrvffFJ9tP8QAMICKQKywpiCSQJ5wsBEN4RzQ+RC0sISwf4B54JLwt1CycKawjDBy4IRgkxDJARJRe3GYwZ6xqQINgn2ixKLzUxkjQvOW49T0DOQRFDuUNgQUI7PjPdKy0m8iEsHQsVTgkA/g732/Iq7ZTkLtwx11XVmNSi01rSxdEo0uHSYtNX0yzTKNTu1jPaOdwN3GzaYdgg1aTPt8hrw/fBnsIswvO+urkNtGuvH6/4tSDCVs1F0vvRntIe2mPpqvwrD+8cDiX8KBErTi/gOD1H80/4TsdPbUwZQmk96D3aP3s+pTlhMtIp0SFJHIIaCx7/JGAoOiRKHNoXkRtYJvsw8zMsL2wnliAfHXsfsyV+KesmNR+JFbkM7wYIBKACEgFW/ff2qvCU7Kvo7+LK3QncyNzh3AvbSNjC1eDTt9JM00HW+NkM20LYKNSF0sjUINnm3IvePd152FrS8M5r0I3VDdty3r/extsv127UgtYv3kLn0euX6nPnNOYN6Bftv/T6/DMCYwIrAKz/agLdBycP9RbwHOIefx01HeYgFCezLT00tjmnPEU9Mj6WQeBF+EfuRudENUQhROlC+EBZPtI49jC+KhgnESS6IH4b/xPgDOEGSgGt/Yr8bvrt9I/tDecf42riu+KD4HXbKtan0VnOxs3szr3OPc3Zy8DJSsc+xnjGP8gzzG/Qp9Ij0xrUwNaw2mvg/ueU7r3yavYu+zkCXgyzFrwd+CGFJGMm5ClzLx80yTUkNMMuxCacH10amhQ/DVcF+vz09N/vvu047G/qVeg05cji2OMM6H/sxu9C8mH16PpIAQgFogWZBGgCj//3/bD+JgHKBH0H9QXDABb7/va69Yj4wv0JAgkEnQT+BGoGegmiDbcS2xfvGqMb6Rz4IBQmXiqlLbkuEi0HKmkmNSJWHxYe8hrFE8kK1ALg/On4XvV58HHqDeWa4erg4eJh5cvm/+jj7WXz3PeF/B0CNAcTC9gNGhDKEmkVgRaJFIwPeQhUAMj4f/Ig7MzkAN4d2e7UzM9lyRDDML/lvozBccVZyRvNRdJm2ork+e119VH74f8bBJ0J3hD3F18cHh2UGiwWIBJYDyYNEwsPCDEDSP2O93TyTO4+6zDpa+gA6o3tsvHa9RP6j/4cBJYLTBTQHDMkPSqJLyc25j7GRalG9EItP9I9Cj42POE1dy5cKoMo6SV+IR8aVBCEBwsDKQRMCesNFw3jBvf/8Psj/H0A0QWoBlkBZPo39rb06fMR8tftl+d04HrZGdT90JrOPcs/xxjElMEQviy5vrTPs6+3IL3Yvs+7N7j6t1y8ZsRnzDTRWtJ70SjTMdyi6pn2FPsb+oH6ygDbDL8avCU5KzUrnCjhJ+srBzTFPKhBWT8iONAywjNjOLU79zumOYQ2EjXnNsM50zpPO/w8lz7jPGI2Bi/ZLDMwZTN9MSoqgx+IFJ0MUgkVCSgIYwNg+unvE+iM5KrjseN446PhQt7+2sTZ89pa3azfDuGp4Uvix+Of5XbnTOl76mXrNO2Q7yHwWO0k6Vznvuhj6lLpxOXV4K7ajNR10MvPAdIf1cjWqtWo0pHPLc7X0I/Y+OLX6qzsn+rp6fXtZPUS/W8DNAiqCmMK2wgTCMQJ6g5YFlsc1xx1F8QQ1w4rFLUdJCabKnsrNyubK3cufDXxPspG0krOS1hLikvbTM5N0E0BTkhNfkVOPHA1HzK6Lxcq1B8MEukEqfuN9M/s0uTh3s3auNbE0LLJ8sPEwQ3EeseMxwDEA8HEwTDFCMhCyanKg8w1zD/JrMVfw3jD1MR9xWLEb8HEvpm/JsQRynHOSc99zzjU9t4r7P33wgBvB3sOKheeIEIpDTJKPAVG5Ez9Tn5OPU7ETXxNOE0YTUJNnk3xTUlOZE6HTsFFgjkVL7EmcCANGbcQmQhBATH6nvRu8Fbsg+gz5tvkluI23wHcKdpy2dDZDNs+3IHbJdjW0xPQGM0byj/Hl8Oqvuu6BLtpvn7B3sJcw6rEaMjBzgvXkODe6ZTxufgNAckKoxN7GvIfHSSWJjsoUCv2L9AzEzShMBQs9igPKPMojirMKt0ohCXhIuAiHCYbK6suiC8CL9MurS/PMN0wOi+DKz0l0hy+FAUPbwrdBA3+VPbn7MzhW9cD0JrLrMfKw8nBh8ESwQrBfsOdx8LKnczzzl/T+dk14abnCuyv7eXtw+4Y8YX0XPdR95307fEy8H/u/Oo35u/i3uI95Gbkk+Pl4hLknOfb7BDzXfmb/wgGKg1wFW0eMCcXL/E1LTtsPuNABkSbRwhKcUkaRplBhzwLN8AxQS03KiEpJyhDJEEdMhU/DkwKmgrWDQ4Q0Q2vCCUFOwRMBB4FiQfhCRgKCwlbCKAIJAk9CQsIrQRP/yr5dPQ58hzwE+s246Dab9Jnys3DE8CivrG9przwuii4OLZ0tw28wMI+yrzQCtW51+jZQ90s4jTngurM61Pr6OjI5ZbjduKp4dzgZeBA4JDgV+HZ4SviueOY6Gjy2ABVEbsf3CgOLZMxsTppSrdPk07pTkxODE5PTUxNO01aTZJNmE3OTc1Ngk4kSf1C9D5sOH4uliH8FQYPDQ4TELYQaw3wBfb8Hveg9i757vu5/FT5rvBD5YXbt9UO00DRxM1Hxoy78q/pqCapNanJqSaqsKreqvCqyqqRqjaq5ql2qVSqm7D8uIHCeMuT0nDXS9vY4IHqp/ZrADgFsAb3B34LQRE+GLYfoCXxJuojFCHUIkgpBzGeNi44DTYPM/wyLTgpQQVLg04sTj9OyE13TUFNV00bTSJNEU1wTTNIHkkPTt9NzEVNOeUsYCLWGpcVWBDmCDT/5PTY6sfgj9ez0VLPEs26yD/ExMJrw7DCR8Abv6vAXMMjxknJ9MwX0ArRzM+MzvTOY9Cf0T3TNtVK1THS4s3ry/zNPtLQ1XXXyNcX2K7Zv9075ErrTPDI8VnxdPJh96D+TgWHCmQO1g9ODqYMFhB/GeMiqib2JCIhaR35Gx0gMyphNLI2zzBYKiQodCmHLT40RjpVO6Y2UjCtLTswpzR5N7s3MTV7MH8s9CvpLQUvgi06Kmom5yGkHPQXNhUHFFgRQApzABL41PFy6xPlD+E83wXc5tRgy5HDkMDmwafEFMZFxL6/wbvEuzLAp8Z4zIzQedMm1g7ZDNxS3w3jfecE7cPy6fb+91v14+9S6jfnvebh5jHmCuSk3yfZFNMG0gfYOeHs53Lr2O4M9PD6twO5D+cesC1HOPs9a0HORGdKo05qTnlOXE4LTlhO6ElhQ1RBzD+/PaQ4UzFqKasjfSAfHpcbSBmHF2MVkxI4ED4PYRC8E34XFRj4EwQNdwd8BmwIdQgtA+j4iuzo4PLXLtJKzlTKCMXHvvG3erGvrYytVbARtPu2zrh4u/jA78fUzdPRwNX324XjsOi66ffoFema6j3sJuyt6enmUueP6jTtD+2R61fsS/E/+R8BPgiwDkEU9RmkICEoATDeN8g+LEMPRW9Gn0gqTGVOk04RTcdH10KiPZI5jTZRM+gtwiZUHgIWZxAKDgIMywj8BBoAG/qX9eLzUvS89qf5pfru+Sj57/iE+aj7m/7z/wT/wPwd+ib40/YV9c3x0+xn52TjVuGX37jc09ge1VrTk9SK1x3aBtt/2wve9+LJ6NbtefGE85T0YPTL8sDxX/OQ9o/3PvVh8SDt/ug15ovkp+Ls31zd+Nvd25zcyN5f40bpz+3U8Lf06Pp6A4MOjRoXJbMsyjGSNSU51j0FRCFK+U0lTjlO/032TZBNAE5HS8dFAUO9QIs+ITkcMMUmfB+MGcsUPhE+DbIHfQEl+tbx6uqu5rbjW+Au3PXWRdI70BHQ8c6Xy6jHm8QxwzLDw8Inwdu/hr/Bvi28y7hFtu+1+rc5u669yL4EwG/C98X6yWnOkNRn3XHnrPBo+TwC8QrHE98deShKMXo4Oj9ERSRKrE3STt9N4kzxTPdLMUnmRNg/ITv5N6I1KTKxLJ8mySHcHlcd1RvWGR0XYRNFEBYQfRGGEOMM8QnXCXEL9AvzCRsGuAGd/EX32/NU8hnw5+tE5/Dj6uHg3+jc09kO2LXXndfc16LZstxi34Xg7eAa4pDkD+gp7FXwaPNJ9FzzZfKz8bjw/+/68HTzsvRR8wHwjOw+6vfoK+fq5OHjGeQU5L3jI+Rm5eznruv/7kXxIPQT+Vz/EQZLDF4QIBIwFAUYvhvgHTUfECHSJMAq9y+QMSwvtSqDJ2Aoey3GNJE7kz+YQNtA30EbQ6FE1UZvSCFH80JuPgM6IzQSLFEiqhckDR4Dpfku8YLpbuG92MLPVsbIvey3UrVYtaa2ALfYtam1p7gPvfXAxsTPyBnM2c0azhfNo8xyzkjRaNP+1HPVINTX0pvTwNbz2sjeleGP48Hl5ehl7ST0Hv1HBsMNHBSlGkshPSjlL9s3K0A6SP5Nv05VTgpO8025TeZN4E2STqdL+0XdQHQ6sjKnKVQhwRo0FlgTVBECEL0PcQ+WDSgLuwoIDSgQyhKwFL4Thg4lB4AAyvpi9KTsveSK3S3WEM0Ow4u6KLRvrzCskaqGqkqrVqysrpKz5Lq4w+XMfdVF3Xjkv+vp8//7WQJ+BsgHRwYPBeIGGgpIC5cJKAb6ATP9GPj+82/yBfPM8zf0ifV3+AX8c//lApoHJg5QFXEcaiQNLVA0IDjIOcE7pz7vQUZEOkS5QBI6BzI0K0EoYSjbJv8gWRlHE7oOfAoaCKkJ+A1vESYSLRGRD4MNegxCDmURNBLfD0cNSQv9B5YC0PsF9ADroOHO2c3UqNGgzurKGMbIvyG5uLTbtFG58b6bw2vHJcvLzQzPttA31F3ZTt/p5I/pAe1W72/xEPQl9835bPqp+BT2vvSl9Zf47/tX/qD/q/87/i79pP82BVAL5hDGFnIclSCsI9cnDi7ENGs6KD8SRJNJ8U1rTi1OX04HTChJzkZJQ8k+tDn+M50triYPH7gXhxGZDFAJFwfEA+H9jfYO8J7s1ev76qHoeeWR4VjcSdjh1+vZatv12oTYytQ90u7Srdbf2k7d2NwZ2pvX2df52pTfAuTq5sDnAOe+5SPlCObo6BztGfFB82XzjPLS8Y/xEPJs81f10vZj9mfzDu8S7Ibs1u8g83/07PSG9T72f/ep+8YDWAxpEf8TcReSGwcf8CKmKC4vHDQONjk1AjO6MGgvvi9HMbkxlS8/LCApgia1JGcknySHI/ogah4hHB4aYRkqGcwX6xQzEf4MwggYBTYC8/8n/WD5pPQy70XpI+T24Nrfh9953rHc0doX2dLXhNiJ2y7fxeH04kbkjeYo6Z7sovGZ9n75FfrU+bj6Cv2C/yUBUgFB/3n7JvdP8rbte+rt6BLo3OZY5OnfF9pJ1HXRwNMv2j3hduXi5aXk8+S658ztZff4AYIJPA1xD1MRaBOxFtQbpyEIJvIn9ydkJ34n1ScEJzsmViZfJYkinSCvIQMlyCiSK6oswyv0KT4pzyoALrwwRzG4L4MsaCcUIbwbEBiFFK4PVwnrATb6xvL667bm/uLV3jnZAdT70OXP5c9h0ZPUgtcN2AbXu9aq10bZGts+3YrfDeAO3b3XadNk0dXQhdE/06PUAdR10ZXP3dCJ1RjcvOIS6b3vAvc6/l0Fdg33Fskgvyk0MbM2VjrVPNk+10CfQ5NGEkciQ+I7cjSxLtYqJSjhJHwffxiDEcALQQiFBq0EfQFY/X/5ufaU9QT2Xvfm+HD5r/jf9wD4HPgc95317/RT9Qv2B/Ys9LDxnfBh8HnvFu968EPyR/LL8N7vwPB/8qrzxPR39j74PPkl+af5Pvy1/x8C6QI7Al4Ahf7h/ff9vv3Z+533tPFx68LmKeWR5ZblmOMH4Drdb9244PLkg+j36kDt1vAx9kb9xwXEDRkTLxYXGSwdGiJvJq8pzSt9LDUsHyzgLM0try3RLGcsmyzeLF0tSi7hLtkuWy6LLYQswCq6J8IjMB86GkwVmhDGC0wG4f/I+M/xRuvS5B7e19cI0z/Qsc4UzTDLZMlCyIjIBMo7zGXPZ9Mb15LZNdpJ2XDYM9kz2/Dcd93e3Ojb7tp42bbXuNZ013zZRNsU3LncRN5z4XvmRO3i9D78aAMXCxYUvB33JocvrjeAPhVD6EXqR1JJ8UkVSrRJE0hwRIE++jaAL/IoBSM7HcEXOBMAD0gKTwVdAWz/Tv8iAGkB8wKiBI4GAwnSC+gNsQ7vDkcPtQ/xD+wP/A55DD8IOgOF/jP66vXn8X7uNesB5+bhKt3Z2e7Xa9dh2E3aOty53ZjffeJf5o/qV+6O8V/0D/en+Wv82v7X/zn/+/14/BT6fvbm8fvsnOhw5Srj1eDb3VXactat0nnQANEx1NrY392v4knnNuuf7oXzPfstBE8MlxPMGvggsiSjJiopySzyL3MxwjGPMk80nTVZNaQ0KjT8MswwBS++LhwvqS7pLHEq/SfIJbEjCiKBIY4hWSDUHNYX2BIADwMM2ghiBYUB6fzC9+nyz+5c62vouOXG4ufeTtoG1gXTfNE40afRNdLy0jvTutLZ0V3R2NFr03PV29ZM16rW09Sy0uLRm9NX1+Ta6Nsx2kLXMtWf1Q7Z/d7G5fnqc+1P7svvOfSF/OEG1A/fFYIaiB9IJS8rLjGxNk06WDu/OtQ6mTwVPts8gzmhNUIxUixGKJslWCNjIcQf6h28G9IZbxi8F/AXnRgdGhgdKCBFIb8g0B+WHuQcRBsYGpYYORV1D64I/QKa/uX5mvPC6/viYtqy0+fPWs5tza7Lm8hfxeHDKsVjydDP9tXl2RHcVt584avk9ufL6y3vBfGE8WjxS/Ha8JHuseoA5+7jieCt3C7ZfdZk1CjSmM9uzY/M0M1Y0ZbXFOGP7Lj2Zv2JAj8Krha9JTQ0fEA1SmJPQ0+mThdO+U3LTRxOEk7ETlJMyUSpPFc0FC2wJoYhfB2lGfwVcxM/EkQROBAvEPkRDxQiFQoWSxf3FyQXIhVZEyMS0Q98CzAGkADM+X3xd+j734XYvdHTy7nGhsHbu762rLODs2u1B7g8us67Vb30v87Emcv80pzZ594i4xXm8ue76d3rKe4k8HzxpfGQ8JbumOxy63LryOwl7yzxmPE78bLyc/c0/4UIThFGGCodqyCAJI0qxDPuPVNF2EjwSThKLEq9SSVJ8EcnRWlAkzpWNSgxIC1gKGYjDB+VGy0ZixcGFoIUzBOqFHgWKBiEGSEahxmOF0kU2BAYDhoLmgaSAJT5Q/L/6hTkgt111iDOVcULvqK5vLfBtq611LSntBa2UrobwbfIm8/r1BrZYt1j4t7neu3i8lX30PkS+vj4cveV9R/zlfDk7bXqkee25PrhFd8u3FXZIdcv11Hapd+P5ZvrSvJA+VMA8AeWEQ8eICtqNX079D7nQn5HB02nToFOXk6dTjNNpUXZQM49ADoiNDctiCegI8IgCx5mG8sYeBZKFXMW5RniHR0gnh9NHXYaZhhLF0EWXBSZEBMLfQTb/IP01uuh47fc39ZO0bnLG8YgwAC6qrS2sSiyL7U6uTu9X8BGwsDDosZEzEjUtdwy44vmKOhv6gfuwvF59Lr1vPXB9OXyqPDw7vjtruyq6vXo+uge61HuPPEN80r0nvZa+7gCegw8F3Ig0CZ9K38wOza6OzlAlkNiRm9Ip0gNR4BEjEDlOdQxfCv7J1AlqiG7HHsWgA/2CHgEEwMkBAwGDAhaCeEIWAemB9sKuA43ET4SpBKdEuYR6g+WDBEIpwL7/K/4E/YG823tiuWd3aTXUNQi09nSJNJQ0P7NX80H0EnVbNsp4anlBukq7NrvcPTB+XP/ewSkB3kI4AaiA9wA+f8RAMP/jv6v++D2XfEz7Wvrpuuz7P/seuxX7Fntju9I80P4rfxD/+cAQwMHB+sLxhA2FNkVZBYNFvAU2hNIE2wSWRAjDU0J2QUbA24Aif0U+4H5cPi894z3Bvhx+HP40fjf+m//ewUOC6UO2w9DD2gOUg8xEjgVpxbyFboTPhGpD/8OLA56CysGlf9K+ln4zPhC+Zn4+/bf9LnysvH78mj2S/rX/LT90f28/hMBrQQjCRoNkg8nEFgP6A2SDMkLDAt4CQIHiARDAqn/T/zM+Lj1DfPA8ETvZe+/8IrxHPEp8XLzj/d/+zv+/P8cAfcBPgNUBX8H6AgfCfkICQnPCOoHdAZzBJkBD/6Y+vX3ifaC9kP3kfca90L2mfWA9U72TPi5+/b/kQNbBacFkwUWBssHdgoMDbgOrw6PDOcILgWGAuMA8/+0/m78VPkB9rzyV/B+79vvivAZ8cLxsPIk9GD2yPj0+mH9OwD/ArUFmghHC7cMqQzQC+MKXgpNCh0KEAkNB8EE0AIlAZ7+9vqF99/1NvYj99z3C/ku+1D9aP6e/3wChAYbCssMhQ+VEnkUNxQYE/0S4xM3FEETvBEEEPANRwtJCL0FfwMGAV3+M/ys+ov58vjd+Nv46/iS+eb6lPyh/hkBRwMLBAgDSQFnAHMAQwCd/wb/ff4L/Tz6nfa78v/up+tX6WXoI+j/583naOe15uvlFeY86Jnrn+4N8bnzCPeP+gH+hAEVBeIHXQknCm4Lfg08D+8Prg+XDtUMPwu+CtsKbwoLCcIG2QPuAKH+0/xT+6/6EfvT+yL83Ps3+476G/pn+cP4bPmG+7X9of6j/rH+eP5l/sD/5gKFBl8IKwiFB0gHbwdfCIQKAQ1aDnsOtQ6hD6AQ6hCgEPUP1g6aDTwN1g4rEUYRJg63CRIGAwSRA84DpgMnAjb/4vsZ+ez2X/XS9C71dPXE9IzzyvK+8i/zzvOB9Fz1yPYM+S77NPy0+676rPrb+5L9S/+vACYB1QCKALIA8QC7ADAAov8u/+H+lf6o/kv/9P+c/xz+wvxX/KT8fP1Y/t/+uP65/Sr86/qx+nz7oPyA/TL+hf4O/qD8Afua+tD7av03/kr+9f23/en9mf5A/7n/rAA6Av4DYAUnBnQGlAanBrcGlQaXBioH1Qf6B6AHvAbdBJYCYAGoAZACzgLaASMAIf4y/L/6gfq++539y/4B//3+1f5L/sX9+f3J/l//P//3/p//0QBnAUQBWQESAuYCdAPaAygEfQOeAZj/Rf+LAZQEFQYpBcUCegD9/nL+7/4zANMAzv+8/Z/8uv3n/7cAxf5u+/f4k/j5+QL88vyz+zn5Gvh9+kL/tAItAmn+lPoM+Xf6Dv9PBXgJwAhzBM4ArwBFAzYGDAjYB34FbAIsAbkCwQR4BKgBfv4X/Xb9l/6r/27/kvx2+Mz2h/mR/mcCZgN7AZL90fnD+IH7VAATBMoEJgP8AJz/l/+8ABsCLAKnABn/u/5b/yMAqQD2AOUAXgCb/1b/KACxAcICwAL2ARcB6gDpAfED5gUcBhIE9ADS/hz/3AAqAvMBLwDp/Xb8r/zq/Z3+sf1C+y344/X+9f34vf2BAV8CNAELAKv/FACqAZIEMwe6B4UGrgUUBssG6ga2BsQGkwaeBYwEfQN3AQr+i/r3+Ej57/lZ+sb6i/qv+PX1UfTh9O32vvkM/Yr/xf/I/UH7C/rH+j790QBaBFMG1gXJA+ABCgHxANcAkACAAMsA8gDCAOr/Wv75/Nz8jP5WAQsE3wUZBrUEywIIApUD9wYDCiALfQpPCXAIPAjjCPAJJArVCMsGGwVMBN4DHAO2AaT/mP2O/FD9Z//TABgAsP2c+zf7Qvzm/T7/m//H/qL9tP09/84AAwHg/0z+2/wj/Lv83P3z/VX8m/kq9831cfWw9VL2EvdR98j2SvaU9ij3j/ca+E/59fpn/Jz9Gf/RAOMBKAJ5AnoD4gQZBuAG6gZTBqkFPAXtBLAEPgSUA/wCjALWAZ0AdP+3/ov+3v45/zz/pf7E/Wn9z/2X/kH/lf+v/3b/7f5u/mz+jv6H/l/+H/6f/YH8/vrE+Qz5ufjG+Dz5E/px+tP5o/iy97r3iPiG+X76d/tu/JL9F/+fAHMBowHTAX8ClgOiBF8FfAXpBGkEEgUkB6kJEQuOCpUIAgYRBJ0DdgStBV0GqgbVBv0GJAcXB/IGkQbBBRQFggUWBx0JzwpkCx4KWgdOBV8FwwbJB2AH9AVkBCQDeAKkAisDCAObAXH/q/1+/Nb7Avyq/Kj8ofuk+v/6g/yL/RH9YvtF+bL3dfcP+cz7pv2b/TX8lvo++Xn4k/gd+Sj5I/ik9vX1cfZa97/3O/cT9vH0ovR+9TX32/it+a35dfnj+XP75P12ACgCvAJbA6YE6gWBBvIGFwiuCRMLtAt0C84KaQqWChELGAtiCjkJawhdCGUIDgh7B6oGowWKBJMDBwPhAsoCXAIQArIC3ANaBLkDUgLJAMv/hf+z/9r/8P/6/7P/Nv/N/nz+Fv40/fD79/qe+qr6ovp6+lP6Nvon+hr69PnK+dv5YvpJ+zT8Fv0X/uD+v/6C/ar7Jfrk+Ub7jf1g//3/L/+V/QH8C/vq+n/7lPy2/aH+/v7B/lT+0P1A/Wr98/5fAZMDvATqBLoEkgR2BJAEWQXDBhwI3wgdCdIIxQe7BgAHlQj7CQEKngieBs8EcAOIAmICEwMVBKMERgQ1Ax8CkgFmARsBkAAsAGMADAGtAQgC9AFVAWYAj/+h/4sAaQGnATYBTQAz/2D+Cv7K/T39fvwP/OT7avuL+qT5HPkh+XX5r/nS+fD5vflI+RH5Ovll+Wf5evmd+Rj6OPu6/M790P0I/VT8dvwx/RX+Vf/EAIwBrwHlAWgCoQKGApYCBwOmAx8EhgTdBPEEjwQLBNED5APxA+MD4gO8AzcDnQKKAgkDrAMWBBYEmwPRAv0BTwHPAKIA5QBoAb4BVwE9AOv+7P2E/Wb9G/1y/H/7kPot+o76BfvF+ur59vhQ+B/4cPjk+AX5B/k1+b/5Yfrf+jj7Wvtt+3X7a/ts+637QPz8/Gj9TP36/K78l/yr/Ov8GP31/Lj8pfzi/Hz9av5W/wUAcgCwAOUANAG7AYYCkgO/BM0FTAZEBkQGlQbxBvQGqAZDBsAFGwVtBAUE7wPCA1cD1gKCAnoCbQJHAv8BKwEeAOv/IgEKA1cElgREBAoEKgSgBIoFnAYvB7sGZAXyAwkDvAKxAjsCHwHL/77+T/4//ir+2v0n/Wb8TvxA/bz+x/+8/+f+Pf5t/p3/hQFwA4kEZQSBA70CGwJGAWkAHgBUADgAY/8v/jX9nfwt/MT7ePuD+/b7Xvx8/H78bfxK/Dj81Px3/o8ARwJMA80DLARgBE8EbgQYBQEGXQahBRAEagJnAQcB7gDVAHgAvv/r/oH+mv6s/kn+zv2b/cb9O/7T/rf/1QBuAUcBEwGKAa8CyAMzBMUD6QINAmsBQQFPARQBbQCV/8D+F/7M/aT9SP2V/ND7b/t7+8j7MPyk/OP8xPyu/Bv94/22/n3/QADfAFEBwgFMAo0CTQLvAckBCQJ0AqACUwK5ASABqAB+ALEA/AAlAQkB5wAAAUgBpgEAAjsCVAJ1AqkCEQOsAykELwTLA04D5QKUAhwChQHZAAIAKP+N/ij+zf1N/bX8KPza+wL8fPzn/BP9N/1c/Xz9z/14/nD/YgDsABABOQGYAfcBIAIWAgAC/gEAAtkBhgEcAbYAZgBHACQA5v/Q/wAAQQBxAGYAIgAIAEsAvAAjAXQBogGzAcEB8AFJApYCxQLkAswCVAJ4AYMAuP8s/9n+jf4l/qL9Mf3s/Oz86/yg/Dv8Jvx//Cz97P1n/pf+1v5Z/zEAGgGSAWcB3ABjABwAGQAtAC4ADwC7/yr/c/7z/d79Kv6B/oP+Wv5C/kn+cf62/iv/nP/s/yAAOABSAGgAhgCfAI4AZQBPADsABgCr/0T/7v6f/iz+xf25/RH+Zv5o/k/+h/4k/+//pQAWAU8BZAGeASwC6QKVA+oDFQQ0BEIETARGBC4E2wMkAzUCcgHsAIYAQgAYAOb/q/+D/3T/XP8h/+n+2v74/lj/4v9GAEMA8P/H//f/MAA7AAYAsv9C/8/+VP7j/Xf95/xS/OL7jvtZ+zX7//rM+sP6FvvH+5L8Fv1M/Wn9cf1//af9Cf6c/iT/fv+Z/5//u////xwA4P92/wn/vv6i/qr+1P70/vP+5v4D/2j/2/9BAIoA2ABLAdoBVwLIAjADfwOoA8IDvwN0AxYD5ALWAqcCVgIcAg8CDQLcAXYB5wAeACH/WP4n/ov+Ev9N/zD/4f6H/kX+Iv4K/v399f3r/dL9xv3A/af9f/1s/Xz9nf2n/ZT9dP1b/VP9XP2e/Qf+ef7e/kf/rf/y/y0AgADyAGgB4AFpAtECBAMJA/UC2QKaAlUCIgIeAjYCQAJBAiQC/AHKAZwBXgErAR0BFAEIAfQAzQCgAIoAjQCSAJgAkQBlABYAwf+L/27/Wf8z/wD/7v4I/y3/Mv/+/q3+hf6a/s/+Hf93/8D//f9EAJAAyADhAAQBSQGOAc4BKQKSAuMCCQPyApYCMALmAaYBfQF5AYIBUQHqAHMAFgD1//H/8f/i//X/MQBiAGgAXwBpAIsAxAAEAUkBgQGGAVIBGgH7AOYAuABuABAAoP8A/0j+0/26/aj9d/1m/Yv90v0d/n7+3P42/4L/4/+kAKABhgLzAvYC4ALzAikDUwNVAykD2wKDAjYC6QGoAXIBOQHpAHkADADC/6n/sf/a/xEAJAAQAOT/xP/Q/+z/5f/S/8//z/+7/43/OP/H/k/+1P1U/d38mPyS/JP8W/z4+6f7fftc+1b7efur+9H7+fs1/Kr8bf1a/jj/1f8lAEkAhgDaADkBqQEvAp0C7AIBAwEDGwNaA4oDUAPkApsCngLHAtgCtgKCAkUCBALFAaEBigFOAfYAowB2AHwAsgDpAPYAvwA0AG3/z/6L/o7+qP6e/lH+yP1B/Qf9Jf1b/Xf9U/0A/Zz8Mvzu++b77Pvd+8f7x/vO+8n73vsX/FT8nvzw/Fj97v2M/v7+Mv9Q/3P/mf/T/xwAeADSADkBsAH8ARoCIAIrAi8CKAIUAv8BBQIfAhYCzQFpAR8BAgEqAX0BuQGSARQBvADhAGkBzwHFAXEBHQHUAH4ASAA1ADAALwATAOf/wf+B/w7/gf4e/vH9z/2i/V39Gv0Q/UD9mv0g/sz+of9rAOsABAHbALkA3QBoAfQBOwJIAi8C8wGcAUwBzgAKACP/a/7y/bD9lf15/T/9CP0I/UD9l/3u/VX+/v4TAEsBNwLSAm8D5QPBAyoDfAIKAuUB1gHPAd0B7wHNAUIBUABQ/7X+cv5K/hj+Dv5a/uP+gf/4/2UA2wCuAbkCpgNNBIoEXQT9AwcEWwSFBG8EdgSBBA0EzAIUAb7/i/9RANcASQAe/zb+2P3//V/+nv6p/rz+C/9g/7r/bQBoAfMBjgGrABsAHABOAEEA1v8U/yD+Tf2//LL8C/1C/db8//uB+6X7Wfwu/Yb9V/1B/br9pf6O/yUAMgD0//3/VgCJAFMA3/+w/xQAvgDsAEQAbf8E/0D/ov+p/4T/mf8NAIEAuwDOAPcAPwF8AZ4B5QFHAqMC/gJdA6wDowMpA4sCggIRA5MDeAOrArkBGAHsAP0AFwERAd4AeADe/2n/Sf9Z/2T/Zf9s/6f/IAByAFQA4v9w/zH/Gf/y/uX+JP9n/z3/nf7a/WL9Uf10/WP9//yQ/E/8FPzM+6r75vtb/Jb8jPy2/Dn94v1x/qT+e/44/kf+3v61/1IAeABOACIAJAAkAP7/3//e/wwAOQAKAHn/+f7x/kT/rv/v/yUAhAASAZcB5wERAh0COQJgArUCPgOlA8ADlgNNA9ACRwL/ARACQgIjAqIBFAG0AHkAYwBkAIkAmwBXAAYAKACKAIkAewDyALMB/wHMAcoBLAJVAgYCcAH9ANwA5gC5ADkAxf9K/4T+wf12/WX9K/28/Hz8dvxo/C383fuV+1D7VPu/+0j8jPyU/Kn81fzw/M38o/yd/Kf8zfwu/Yf9kP1W/Sb9M/2G/fX9Vf68/gr/Of+W/yIArgAtAcIBcgIcA4UDvQP0AzIEkQQOBYUF2gUNBgYG3AW5BawFkAVGBccETAQBBMMDaAPqAmICBgLgAbsBggEjAaoAOwDj/7n/2/8PAAoA3f/E/6z/Zv8C/6D+bf5U/ln+P/7U/Tf9yfy//Oz8/Pzl/NL8vvzJ/Oz8Cv0u/Vb9h/3O/TD+c/6L/rz+Iv+E/9D/IQB3AJcApQDCAOYA7gC9AJYAdABWAFMAVwBCACMAOACLALsAeQAGALz/qv/t/1sAkABzAFUAZACLAM4ANAGlAcYBkgFJATcBTgFoAWEBZgGPAacBpgGaAZUBowGhAWgBGAHqAPgAJQFTAWUBSQEkAR8BOwFiAYMBowG1AZsBbQF0AZABpAGXAWAB/gCRAEgAIwDv/7H/cP/o/ir+w/3n/SL+3/0v/ZP8Qvwb/A/8Ivww/CP8//vd++n7E/wp/Ef8bPyS/KH8r/zZ/BP9Pf13/ej9bf6+/vz+U/+c/+b/VwDHACkBkwHuAS4CbwKkAs4CCANlA78DAgRRBJUEqgSdBK0EywTUBJoEKQTiA8UDiQM8AyYDRwMyA8ECMAK7AVUB2wBbAPP/m/9E/xD/Hv8t/x3/EP8U/wT/A/8l/zf//v6s/qD+0P4T/yT/+/63/oH+jf7C/sb+hP4x/uz9sv2N/YP9W/02/Vf9q/0I/if+Df7+/S/+a/6G/pr+4P5E/5//yf+e/07/Mf99//f/YgCZAHkAIgDX/9D/QADSABMB/wDrAAEBBAH6AP0A+gANAUEBWQFTAVABZAFcAUQBPgErASEBGQEUAQkBBAEsAWwBZgE4ATgBZAF4AYsBpgHFAeQB9wHzAeYB2gGrAWUBRwFmAZsBngFYAecAgwA9AAMAwP93/zP/6v6K/iP+1f2l/Zr9qP3F/b79YP3f/G38G/wQ/DD8OvxD/Iz85fz6/Mf8ePxf/I780/wY/Wb9mf25/e/9L/5s/r/+KP+b/wIAJwBGAI8A5wA2AZ4BCwJUApkC6wJVA6gDtgOXA1EDKgNSA5QDyAPcA+cD4gPFA5wDiAOHA20DKgPbApsClQKtAsICuQKCAkQCKAInAjYCUQJhAiUCkQHtAHAANQATAN//sP+O/1H/AP+S/iH+yv2I/Tz9Av0S/UD9S/0u/Qv9BP0N/f789Pwc/Wf9hv1x/UH9Dv0X/VT9gP2U/aX9o/2Q/Yn9jP2G/Z798f1p/r7+zP7Z/iH/l/8FAGcAtwDmAAcBHAEZAfAA5QAgAWgBeAFRAR8BFQE3AV4BWgEuAQgBDwFZAaQB1QHkAfIBEgI/AmYCiAKxAsMCtgKtAqoCjgJmAjkCCALOAWwB+wCZAFIABAC2/4n/e/95/3f/Uv8T/+v+8v4V/zv/Rv8a/9X+qP6n/rD+0f4J/x3/zv5s/lb+fv58/jD+4v3B/dH95/3o/df94P0m/oX+sv7N/u3+G/86/1n/pf8AAD0AUwBZAFIATwBSAGcAcAB4AJYA6QBBAVQBIQGuAFIATABoADYAz/+F/5j///9yALUAvgC3AM4A+wAfATsBggHpATYCYwJmAnYCjALlAl4DmwN6AwgDnAJ1AqICzgJ7AsQBSAEmAQwB0gCYAHgAfgCFAHcAWQAnAPL/0f/B/5X/Uv8R/+X+y/7E/p7+Qv7i/ar9hv1K/fb8lfxH/Db8YvyJ/Jn8k/yF/JX82fxL/dP9Mf5+/uD+Y//m/08AoACmAJwAzgAqAYcBzQEOAikCFQLfAZ8BcwGKAeYBHgIgAhMCKQI9Ah0C0QGwAecBRQKTAqMCZgIMAt4B9AFCAmYCQwIcAhsC7AFlAckAYQAwABQA+v/Y/5D/BP9n/t/9pv2F/Wb9S/0d/cX8ZPxd/Jn8yfzl/AX9Lv01/Rz9M/2S/e79Ff4m/l7+rP73/ib/Lf9R/4b/nP+X/5H/jP+s/+b/GgA0AC8AUQCSAMMAxAClAI0AggCTAMEA5gD/APoAzgB0AAMAxv8AAG4AiwBdADgAIwARAPn/+P8UACUAFADl/9X/+v87AIEAyADoAN4A9AAnAUgBUgFyAawBxAGzAbgB6AEaAk0ChgKlApICbAI7AgQC4QHAAZwBjQGIAXUBJAG5AHUARADu/5H/UP85/yb/8P6X/jL+/f3y/f/9Bv4C/vb94v3D/bj9wP3M/eT9CP4l/jD+LP4H/tL9y/0D/lj+mf6z/r7+2f4B/wX/A/8p/0T/NP8s/1z/mf+v/6b/s//Y//H//f8SAC4ASQBNACoA7/+//8//HABqAJUAsQDCAMMArQCmAMoABAERAd4AqQCTAIUAbwBoAFwAUQByAJ8AjwAcAJT/d/+w/+D/1v+p/6D/q/+t/5T/ff+v/xMAWwA4ANL/lP+v/9f/1f+V/yn/8P4M/3j/PwBfAXcCGwNJA0wDPgMWA7oCagJSAmwCmAKqApQCOgKgAdcABQBI/8/+mP54/kz+5f1b/fX8Af1b/bn9G/5s/qr+6P47/4T/ov+//wUANADs/2L/3v6Y/nv+hv6v/t/+6P7I/pf+QP7M/Xf9gf0D/vL++//LAEUBmwHuAUYCqwIaA5AD8wMnBCQE1wNVA98CjgJcAhoCzQF+ARgBbgCy/1H/Tf9D//z+lv5F/iL+2/1g/ej83fxs/Sj+nP6v/qr+of57/kL+Af74/TX+pv4T/3T/xP8CAEwAsADsAOAAzgD5AGEBqAGqAYoBfAF4AVkBHgHwAPkABwHnAJkASAAgACYAOwA8ACUAHgA6AGAAVQAgAOv/7v9OAMoAAQHFACoAnv9l/2L/V/86/yX/JP8j/xL/A/8A/+r+vv53/lH+Wf5Z/lD+bf6n/uf+CP8Q/wb/3P7A/sD+yP7E/p/+nv7k/lz/w//V/9T/9v8UABkAMQCJAOoANAFKAT4BCQHSAMoA1QDMAMAAqQCXAIUAXgAgAPD/3v/i/+n/9f8HAC4AWwCQAMIA1wDlAPIA+QAJASgBZgGYAZcBfgFhATsB5AB5AA8AmP9M/zn/Pf8l/w3/Ef9B/3b/p//F/9j/AABCAIMAqgDJABgBjQHtAQsC/QHcAbcBigE4Ab4AQgD8/+H/pf8w/73+XP4i/u/9tP2C/YX9oP2W/Wj9T/2C/dj9FP4P/uj92/37/ST+Hf4D/jL+l/75/gz/6v7R/tL+1f7K/rD+qf7a/jT/o//1/yYALwA6AHMA4ABSAb8BDAIZAhsCJQJAAlkCaAJ8ApMCnwKRAncCSAL8AbEBdgE7Af8AtwB3AFEAMwAbACAAOwBLAE4AQgA9ADcAMwAnACUANgA2ACcAFwAEANf/kP9E/wD/yv6b/ov+fP5W/hv+y/14/TX9Gv0i/Ub9XP1u/Xj9f/2P/Z39wf0K/l/+q/7k/gr/K/88/0n/WP9s/5n/6P9DAIcAqACZAHwAdQCJAKsA0ADuAA4BJQEkARIBCQEIARwBTgF2AX8BbgFVAV0BcwF6AWMBWAFxAYcBjAF0ATMB6wC9ANEA+gD8AMwAXADw/8b/2f/g/7D/Tf8M/yD/Sv9V/yz/FP8v/4L/zf/v/+D/vv/D/9j/4P/j/+P/1P+z/5r/h/9w/1//S/9D/z3/MP8z/2v/o/+//73/nP9y/0T/R/+O/wAAZACSAIIARAAWAPz/7v/b/8D/uP/m/ycATgAzAOT/mf+R/7v/5P/x/+j/5//4/zIAegCmAJ4AeABiAIsAFgGlAbUBQwHeANcA/AAwAWcBmgGrAZkBbgEiAa4AOwAGABEAJQADAKv/Qf8K/wP/8f6s/mL+N/4y/k3+V/5S/jX+If4n/j3+PP5C/kv+WP5v/rD+Mf+k/7X/cv8u/xL/LP9q/8v/MgB0AKkAzADiAPMA8gDZAMQA8wBaAZYBiwFVASoBMgFgAZ8B3wEeAmICtgLqAu0C0wKxArcCCQNwA5EDUgP3AtoC/AINA+ACegIiAhwCNALmAUABmgANANX//P9GACoAwv95/0j/Dv/D/lz+Kf5k/uP+R/92/23/Uv8O/6z+Zv5w/nf+Lv65/U79Dv3+/N38rvym/Nz8Hv3y/Jb8Ufxd/K78QP3j/Wr+tP7Q/t7++v4M/yz/nv8sAK8AIgF7AXEB9QCaAKIA0ADIAKUAmwCzANkA4wDMAK0AkAB7AFoAUABvALoA/gAZARcBLwF7AdEB8QHjAeAB3gGtAVMBCQH0APUA6gCzAEAAuP9S/yb/Nf8x/xL/4/6t/oX+ff5z/lX+Mf4d/jf+Y/50/lf+Rf55/un+KP/i/lL+7v3o/Qb+Dv7x/bv9l/2d/bb90/32/Sn+ZP6W/sD+0f7O/tb+G/+S/+j/GwA/AHgAqwCuAJAAjwC7AOAA7wDTAIAARgAvAD0ARABbAJIA0QACARUBNAGEAeQBGwIoAi4CSQJnApUC2wICA/ACygKiAogCawJAAvMBkwE3AeAAkgA0AMn/kf96/2n/T/80/yz/QP9+/9X/FQALAO//EwBsAOAAHgEwASUB9gC5AIwAaQAxAM//c/8t//X+ov45/u/94P3s/fr9C/4d/iz+QP5l/rP+Cv8q/xv/9/7u/v/+KP8z/xP///78/uX+pv5f/kH+SP5c/lz+S/4+/j7+Qv4+/jH+L/5X/pz+/v5S/5T/zf///yYASAB9AN4AWAGWAYkBdwF/AYYBmQG5AbEBfgFiAV8BbgFtAVQBQgFAASYB6QCcAIIAkwDSACABXwGAAXMBPAERAeIAsgB/AF0AUgBOAC0ABQDV/6f/l/+b/5z/hf87/+D+mP5t/ln+Rv5N/nv+yP4H/0L/dv+p/+D/CAAwAGwAowCyAKMAkQCHAIgAngC0AMYAuwCYAGIAOQBAAHgApACrAKwAvADwABgBCQHXAL8AywDbAOAAxwChAH4AVQBWAI8AugClAF8AJgApAEAAQwAgAPH/xP+V/4n/wf8SAEsAawBjAAUAk/9o/4D/wf/r/9//qf91/0f/Mf9B/2v/bP9W/1T/XP9b/1b/UP9Q/1b/Y/+A/6b/zv8FADkATwBPAFgASgAxAAAAzf+8/87/sf+H/5H/wv/Q/57/d/9z/4L/gv+A/2b/Rv9C/1D/Vf9l/4//yf/z/yAAbAC6APQADgELAQgBJwFpAZUBegE4AfsA0ACmAIQAWwAxACYAUwCeALUAiwBYAFQAegDIAAgBKgEyARoB2gCeAH0AbQBXAD4AIAAUABgAHgAIALz/WP/0/sb+6v4l/0L/MP8h/xf/GP8U/xn/Mv94/7L/1P/o/9//zP/j/yYAVABUAEYARgBOAFAANAD3/8v/y//l/wQADwD+/+b/1//6/1QAvQD1AAoBKwFBATEBAAHTAL8AwgDLAMoA3wDkAMIAmABzAGUAYABnAJMAqQB3ADYAEQAjAFEAkwCtAI4AQQALACcAeQDKAO4A0AC3AKcAhQBKAAwA4P+s/2j/Gv/l/tP+3P7d/rz+fv5W/nT+m/6s/qv+y/7u/vL+2f7a/gj/Lv9R/3H/hv9n/0L/WP+I/7H/mf9o/1f/g/+9/9n/0P/A/6X/mv+w/9//BwALAO7/yf/Q/wkAXwC/ABYBTAFPAUcBMQEIAcsApQCeALYAwACuAJQArwDsAA0B8AC6AJcAlwC4APIAGwELAckAkwCBAIsAnACZAJMAfABiAFwAWQBSAFMAXAA1AM//Xv8R/9v+sf6O/nD+Wf5w/p/+3P75/t7+qf6C/pj+1f44/6f/+f8FAOj/z//D/8v/z//t/xgAKgAOAN7/2P8hAHIAgwBlAEoALgAVAA8AKABOAHEAcgBrAGcAdgCSAKAArwDUAAYBMwE6AVIBdAF0AUsBGAEGAQoB6ACtAGMAHQD7//b/+/8pAEgANADW/13/Gv8A/wL/9/7k/s/+3v7w/vH+3v7Z/uD+CP8x/1P/W/9E/xT/0f60/r/+xv61/oz+af5c/mD+YP5o/ob+of65/sv+2v7Y/sb+sv7I/hv/mf8LAEsAdgCwAPEAGgEfATQBWgGUAasBeAEjAeAAsACRAHgAbwB0AJEAmQB3AEUAJQAxAFwAdQB7AHgAbQBrAIQAxQAKATYBQQFCAVwBcwF4AWIBQgEdAQgB9ADcALQAhABMAA8AzP+X/5b/tf/O/+z/EQA+AFsAYQBkAFgAMAAAANv/4f8BAAwAAwDw/9//tf+N/3b/Zv9U/x//yv6C/nb+k/6r/p3+Y/4v/jb+c/62/tv+9/4s/3n/0P8ZAGgAoQCeAIoAmgC7AL8AkABtAJ4A8wAxATUBFAEFASsBQQEUAcIAegBqAKgA3QDgALMAjACfAM4A9AAZATABRAFNAVsBRAECAawAfABkAFAAHwDU/6//zf8QADIARQBsAHYAWAAYAPD/3P/a/9T/vv+8/8H/pf9w/1z/Y/+D/57/oP+B/1L/H//3/tz+v/6W/nH+Yf5m/mL+Xv50/r/+KP99/57/gf83//f+2/7k/gL/HP9N/3T/h/+V/6r/s/+8/7j/sf+h/5n/rv/g/xgANABHAEsANAAIAAMARgCzAAMBEwH6ANoAzwDHALcAogCDAG4AbgB4AJoA1QAeAU8BdgGXAaUBqgGeAZQBmwGdAZgBkAGQAXkBYAFDAS8BLAEYAdcAjAA9APX/xv+h/4T/av9F/xj/zP6Z/pr+0P4Z/0//ZP9U/zf/FP8H/w7/AP/W/q/+pf6o/rb+sf6i/qX+sP6t/qr+ov6u/rb+w/7a/hf/cf/Q/zQAlAC+ANAA6QAYAUMBRgE6AS8BMgFAATUBBQHMAJwAgABxAF0ATwA1AB8ABQDr/+n/+P8AAAMADwA3AFAAXgCHAN0AEwEJAd4AtQCLAIAAkACSAGAAKgAJABkAKwARAOf/z/+1/3n/PP8g/y7/SP9u/5T/4v8gAFIAcQBiADYABwACAP//2/+m/6D/y//q/9v/zf/B/6v/fv82//f+t/6H/nD+bf58/qL+w/7W/u/+Ev87/07/S/9M/2X/hf+N/4z/p//f/wkANABlAIYAjgCUAK0A0ADQALQAugAAAUEBXQFaAXEBiwGMAXQBYgFjAXsBkwGXAZoBfQFfAU0BRAFNAVkBSQETAakARwAtAEAAXABkAGwAZQA2AP7/yv+z/5b/bf9V/zv/H/8I/wn/GP8l/wz/4P7J/rD+qf6V/nr+bf5y/nf+df6D/oj+cf5X/j/+MP4k/jz+bv6f/qr+w/78/kT/Zf9f/1T/UP9z/5X/kv99/3T/mf/u/ycASgBmAI0AuwDNAMIAnQB7AH0AoQDfABcBPgFwAbEByAGuAX0BYgFsAYkBnQGbAYgBeAFxAWMBXAFiAVABEQHRAI8AQgACANn/zP/p/yYAPQAQAL7/Xf8K/+/+5f7S/qb+ff6C/qL+t/6z/pr+c/5U/kP+Bf6z/YX9l/3a/R7+Uv53/pv+u/62/pD+ef6n/vX+Of9Y/3P/oP/i/xkAPABnAJYAuADLANsA3QDzAAkBFAEmAUwBbAF0AXABfQGeAacBkAFXAU8BfAHTAQkCHQIgAhUC5wGsAWwBNQEiASwBTQFHAS8BJQErARUB4gCnAFMA9/+n/4D/Zf9n/6H/+v9OAIcAqACVAGcAGgDW/8//+/9AAH4AsADJAKwAXgD3/6f/if+G/37/Rf/x/q/+lv6m/rb+rP6X/pf+qP60/pX+cv51/qz+0v74/hn/M/9W/2P/Y/9m/2//e/+X/8r/9v/v/7b/iv+A/5T/wv/7/yoAOAApAB4AOwBkAKEA3AD9ABEBKQFYAXIBdAGOAbIB4AH+AeoBuQGpAbcB1AHdAdIB4QECAhYCAgLIAXsBPwE3AU4BYwFxAVUBEgG/AH4AWABMAC0A8v+j/13/K//8/tT+kv5K/gv+5/3c/eb9DP4l/gz+1P2i/Zr9n/2h/Z79if2H/aX97/09/mX+cv6G/qz+xf7d/vz+D/8k/zD/T/+E/87/CwA9AGAAagBiAI4AxADaAMcArwC2AMMAzADpABYBMQEeAf4A7gDbAL4AuQDOAO4A+QDzAAsBIAERAeAAqACBAGIAUwA8AB0A8v+//5T/eP9s/1X/J//w/rn+hf5i/nT+tf76/hr/LP8z/z//S/9D/0z/hv/N//H/+f8OADMASAAyABMACAASACAAJgARAPL/yv+w/7T/v//B/8b/1v/e/9H/1v/n//3/IgBSAKcA8gAGAQMB+ADbAMUAiwBgAFQAZQCEAJ8AiwBaAB0A2/+h/2//Xv9w/3z/av9i/3b/q//n/y8AcgCXAHYAOAAQABsALQAyAFEAcQCMAJ8AnABYAOf/if9T/0T/SP9I/yn/F/9J/5v/2//l/8X/of+n/9//CQAqAEsAYABiAFEASwBBAB0A2P+Z/3L/Vf9E/z7/SP8k//n+zP6W/nD+ZP6I/q/+y/4D/2L/vf///zAATgBcAG0AiAC+APoAIgEyAToBOgEsAScBIQESAdUAgQA2ABcALABdAHUAcwBPACEABAAXAEUAagCHALoA6gANASABGwH0AKcAQgDg/5j/hf+f/6j/jP9p/07/GP/E/nD+R/5B/kH+Uf5p/nv+lf7f/jX/af9n/zX/+v71/jH/bv+f/87/6//4/wQAAADe/4v/R/8t/0X/gv/d/ysAaAB0AF8AKwD//wYAQgB/AJoAsADoADABawGVAaIBeQEvAecAyADNANQA7gAfAUUBUwE+AQMBqgBYAEEARgBFAFUAVABZAE0ANwAIAMv/uP/d/xIAOQA6AC0AJgAyAD0AJQDz/8b/tf/O//P/KABaAIcAqQDGAMsAoABdABwA/v8FAB0ANABIAFkAZQBHAAsA0f+l/3b/V/9H/1z/hv/C//3/EgD3/7j/iP+T/6T/if9d/3f/xf8QAD0APgAbAN//h/88/yf/N/9O/13/ef+d/7r/1P/N/8H/u/+x/6//0f8dAHQAqgCxAJQAdwBaADkADQDX/6X/iP+h/9T/DQA2AEcAQAAZAOL/uv+g/5T/r////10ArADDAKEAVgAMAMz/j/9x/4b/vP/0/xEAFgAaABoAIAAXABoAHwAYABIAJwBgAJYAtQDDAMgApQBfACsAHAA/AG8AkACRAIQAdQBQABgA2v+x/6n/mf+O/5j/u//x/xQAAwC//4L/a/96/4f/hf+U/63/yP/Z/9T/y//A/7D/oP+e/6n/tv+s/8L///9BAF0ATABCAFAAVgBCACoAJAAqADoAcgCsALIAfgA9AA0A/P8HABIAGAAaAPz/3P+5/4b/Vf9M/2n/l//F/+D/4P/J/6n/hf9v/2v/d/+N/6H/s//G/wYARABaAEgAHADu/8X/vP/O////IwAtACkALQAyADAAGwDz/8n/pv+i/7P/vf/a//r/9//K/5f/fP9q/1r/Rv85/zz/WP+I/7D/zf/X/9T/qf+L/5//wv/b//P/FQA4AEwAWABeAFsARAAKANb/t/+i/53/pf+n/6D/qv+n/5X/kv+m/6v/kP9u/3X/pP/r/x4AGwAFAOL/2v/n/wEADQANAAMA8//i/9L/zP/F/7f/mf+E/5n/0P/7////CAAAAOf/7f8FABoAKQBLAHEAkwCiAKsAqQCNAFIAEgDd/7r/q/+6/9//7f/l/+//+//y/7n/bP82/yz/Wv+o//X/MgBSAEkAJQARABEAFAAPAAcA9//t/+z/BwAwADQAFwD0/9//xP+e/5r/w/8FAC0AEgDq/9b/8P8OACoALwAlABYAAAD//w8AGAD5/7v/if9t/3L/fP+P/5P/nf+s/8D/tv+R/0j/Df8C/1X/5/9LAGcATgAfAO//wv+s/67/yv/x/xYAMQBMAFAAGgDN/5z/pf+q/6X/tP/2/1kApAC1AKMAiABuAF4ATwBJAFQAfACwAPgAOwFNARUBuQBrAEQASgB2ALYA2QDOALMArgCdAHwATQAoACIALwA/AEQAVABNACsA8v+0/3f/Tf9K/13/Zv9b/1X/Qv88/zr/Hv/5/sf+qf62/tf+Fv9Z/4v/gf9K/xf/+v7v/gX/Mf94/8H/8/8JAOX/iv8i/9v+xv7b/vb+K/90/8L/+v/k/4//I//C/nT+XP6D/s/+K/+P/+H/9f/D/4n/Wv9O/4T/2P9CALUAFAFmAasB2AHIAXUBAwHCAL0A4gALAT0BXAFJARsB5QChAE4AFQAWAFMApwD1AD8BewGNAXABPwEMAR0BWgGOAX4BPgH4AMMAkwBhABgAwP+K/3D/V/9F/07/Sf8d/97+r/6d/pv+tv7i/in/dv++/+v/7f/B/4r/Rf8D/+b+5f7m/uj+4f7X/tD+uv6m/of+cP5X/lD+XP6J/tP+J/9z/7L/5f8XAEkATwBKAFIAiwDbABsBOAE9ATkBCwG8AHgAZwCKAL0A3gDVALgApADHAAQBMAFIAV8BZQFkAV8BUgFTAXUBkgGgAaoBqAGSAVEB/QCcADsA7P/F/83/1v+6/5T/lv+m/5//cf9R/zf/Lv8+/1H/Vv9K/1H/cf+W/77/0P+z/2X/G//y/ub+8P7//gL/+f7o/uL+7v76/vP+6v4B/zb/df97/2L/bP95/3P/lv/L//n/GQAyAD4ARgA7ABkAAQABABcAJQAUABYAPgBsAGsAagBoAGwAfAB5AHYAggCUAKUAqgCmAIgATQD9/8r/vP+y/6//rv/a/wEA6v+r/1n/H/8W/y//WP99/57/xf/0/yEAMwAiAAAA2v+p/57/tv/T/+7/+v/o/8H/qP+f/5L/hf99/4//rP/K/9r/7f/6/+7/z//T/+v/BgAzAF4AiwCLAHYAUwASAMT/c/8n//7+8/4A/yj/Vf94/4T/Zv8z//r+0f7g/iL/e//p/0AAWwBFACkAHAAsAEQAbgCXAL8A7gAqAVUBVQEjAcYAYwAZAAYAJwBjALIA5gDTAIsAQwAIANv/s/+N/37/fP+m//L/MAA7ACAA3f+B/zT/Ev8U/yn/Pv9F/0v/Vf9l/0z/H//p/rj+mP6m/sb+7v4H/wf/BP/8/v/+/f7v/tD+w/7J/u7+Mv+N/93/7P/N/6X/k/+X/6z/zf8RAFwAjgC2ANMA3gDNALkAtADFANIA2QDbAOgAAgENAQUB5wDTANkA8wAKAR4BKgEuASUBEgEJARMBFAH/AN8A0ADYAPsAHgEuASYB/AC/AJMAeQBWAC4APABmAIYAhgBfAEQAQAA7ACQAAQDh/+v/JQBjAI0AgwBAAAQA6v/c/87/xP+0/8b/7P8dACoA+v+7/33/Xf88/wv/3/7Z/gP/O/9I/zX/G/8D/+j+xv6f/nn+ev6V/rz+2f72/hT/NP9J/0n/M/8d/xD/Ef8X/xH/K/9V/3T/fv9y/13/Sf9E/0H/Q/9D/1X/hP+y/7//yP/Q//D/JwB7AM4A/QANARkBMwFcAXABZAFGATIBLQEVAfAAzQDGAOQA+AD5AN8AygDDANMA5ADpAOoA4wDmAOYA2gDJAKsAkACBAHkAZwBSADoAFQDU/5j/Xf8g//D++v4q/0T/K/8D/+X+4/7Y/sr+wf60/rj+vP68/sj+3P7z/hH/IP8t/yL/DP8P/z//mf/n/xQAIwApACgAJAAWAP3/7//7/ywAbQCtANkA5gDJAJYAhACAAHoAYABCAEkAawCcAMsA2wDaALkAdgA4AB0AKQA+AGEAegCUAJMAggB4AGgAQAAWAAUACAARADoAdgCTAHYAPQACAN7/yf+i/5n/wP/9/zAAPgAjAO//rv+G/2v/Zv+C/6P/q/+q/6v/nf+F/1r/Kf/5/tb+yf7T/vT+9/7m/uX+Af8K/wD/7v7c/t7+5/4C/zX/d/+a/5L/dP91/3v/cf9i/2f/fP+b/7v/6P8OACQAJgAGAOf/3f/u/xYAVgCuAPcAJgE3ASoBDgHdAK4AoQDAAPQAIgFAATkBAAGwAH0AZABqAGsAaQBgAFAAVgBTADIABgDm/9P/0f/V/9r/6P8AADAAeQCHAEgA6v+m/5X/rP+7/7v/x//l/wMACQDl/6P/a/9M/zL/Jv85/3P/uP/f/+X/0f+k/3r/X/9G/0//ZP96/53/xf/e/+D/7v/n/8H/kP9z/4b/rf/m/xgAQABoAJIAlwCLAIMAkQCjAKgAqQC7AOUA+wALAQMB5wCsAHEAVABTAFkAUAAxAPf/xP+n/6v/tf+k/4f/fv+N/5j/mf+d/5b/lv+h/8v/8//q/83/qP+Y/5X/rP/O/97/2v/e//H/+f8AAPz/BgAFAPH/5P/0/xgARAB5AJgAoQCWAJ0AqwCtAI0AXwBBAEMAYQCHAJ8AhgBCAAkA7v/v/+L/yf+l/3P/VP9d/2z/cf9z/4L/h/9y/07/Sf9b/3P/jP+T/4b/fP+F/4v/nv+c/4H/av9t/5j/wP/Q/8n/qf+S/5T/uv/u/w8AFAAJAPT/6//9/wUA9v/q/+z/7//f/9X/5P/u/+f/3P/a/+H/3P/n//7/EQA0AEYAMQAOAP7/DQAyAFAAaAB8AJoAtwC/ALoArQCRAGwAZABsAGsAegCbALcAwgCxAI0AXQAjAP//+/8WAC0AQwBiAG0AWgBVAFoAQAAdAO//4f/+/ykANQAvACoAFwD8/+//6//t/wgAQAB1AJEAowCXAHUAWQBKAEcANwAtADcASwBSADIAFQANAPb/y/+d/3v/f/+C/4T/cv9Y/z//RP9g/3X/jf+u/97/BwAlACQABADZ/8H/tP+Z/4H/i/+j/8j/4v/s/+f/wP+c/5r/uv/n/wkAGQBBAG4AdQBhAGAAeACOAJoAkwCLAGoATABVAGcAcgBHAPr/xP+z/6v/mP+F/33/fP+Q/6r/qP+C/0//Jv8R/xT/Jf9K/4j/0/8NABcABAD6/wMA/P/R/57/lv+m/77/4P/9/wQA9P/b/8b/zv/b/9r/wf+S/2D/S/9i/5r/w//W/+r/3P+0/4//lP+i/7H/v//f/xsAYgCaAKoAkQBqAEkAMgAkACYAQAByAJ8AngCCAGMANQD//8b/oP+i/7z/2P/n////CAAQABEA/v/n/9n/5f8AABwAQQBrAIQAswDbAM0AiwBKADAAQwBiAHYAdgB6AJMArQC7AK0AjgBkAEwAUABUAFEATABPAFIATgBBAD0ARwBWAGEAZgBfAFkAZgBbADgAKwAjAAsAEQA1AFoAcQBeADEACQDq/9z/5P/p/+T/zf+m/3//Zv9c/1L/O/8u/zn/VP9//6//z//W/8z/s/+e/43/g/+V/8L/+/8XACYAJgAnACoAGADs/8T/of+A/27/gP+s/9X/8f/x/9H/sf+W/4z/qf/N//r/HQAkABoAAQDh/63/dP9R/1T/V/9d/2f/Yf9L/zL/Gv///uX+3v73/hD/Kv9C/2H/jP+9//X/FgAeABoANABdAIwAsQDAALwAxADQAMMAngB6AIIAjQCXAJoAnwCxANEA5QDnAN4A4gD4AAUBHgFEAWABaQFkAUsBMwEeAQIB6ADKAKAAWAAAAKn/eP9y/3L/YP8k/97+r/6W/pP+pf7G/uv+C/8h/yr/Nv9D/0r/R/8//zD/Kf9A/1n/bv94/37/k/+2/8r/uv+q/6X/rf/S//n/HAAsACQAFQD1/9z/zf/j/x4AZgCuAOIABwEJAe4A1ADZAOsA4ACsAIYAjgClAK0AnQCIAHEAXQBYAGAAcgB0AFIAIAD1/9v/u/+T/23/T/9B/07/gf+0/+D/BAAYAA8A1/+l/6H/xf/h/97/0P/P/93/4P/d/7n/gv9T/0b/Vv9L/zz/L/8+/1z/Yv9J/yb/Fv8W/yX/Ov8+/zX/PP9N/2b/Zf9X/3b/vP8PAD4AQQAoAAUA3f+7/6r/pP+t/7b/yv/c/+n/4P/S/93/+v8XACQAIwAkAE4AmgDKAMwAywDUAPoAKgFOAV0BYAFuAXkBjwGqAaEBbwEoAewA2gDYANsA6gD6APkA5ADeAOYA9gDuAN4AzADFANoA+wAbARoBEAHyAMgApACOAHsARgD6/7f/lf9y/0r/LP8i/w7/4f7A/qz+qP6//tn+2f67/pz+l/6s/u/+Nf9Y/1//Sv8V/9b+pf6h/q7+t/7A/rj+s/68/sr+7P4D/wD/9f7s/g//av/b/zQAYgBsAGgAeACvAOYACwEnATUBKwETASQBTgFdAUIBEgHsAMwAwgDXAPAA+QD1AOwA6wDqAOYA3QCyAHwAaQB4AJIAtwDDAJQASgD+/9H/rf+l/7P/sP+F/0//Of9I/1j/TP8g//X+7v7z/vn++v4T/y7/LP8R//D+8/4C/xD/FP8U/wX/4/7d/v/+Mv9F/zD/Hf80/2T/j/+n/6z/rP+j/5X/l/+r/9f/EgA/AEkARQBSAHAAlQCqAJYAcgBqAIIAtQDsACYBSQE0AfwAzwDSAAIBOgFXAW0BeAFpAUMBGgHsAMQAxgDaAOoA+gD+AOgArAB8AGgAWQBLADMADwDl/87/zP/p/xkAIwALAPD/7P/x/+r/3v/d/9f/zP/F/8f/vf+a/4f/j/+P/3L/WP9F/0T/W/93/3T/R/8L/9/+2f76/ir/Vv95/3//df9z/4D/h/+Q/63/xv/J/8v/5v///+z/rv96/2n/bP9r/3T/iv+l/7z/wv/F/7H/qf/D//f/PgBtAJAAsADEANAA0gC4AJQAhgCfAL0A1AD2AAkB9gDPAL0AwwDJAKkAiwB3AGkAaABUAFcAZQB7AIEAXAArABQABQD8/wIADgAWABgACQDj/6n/Y/87/zf/V/9q/27/X/81/xX/Af/5/v7+Hv87/zr/Ov9Q/3H/ev9f/0H/Qf9Y/3r/hP+O/6L/q/+m/5H/fP9g/1r/hP+z/8v/4f/t/wAAGQAxACkAAwDb/+P/EwBEAG4AjwCrAJkAbABCADUAJwAaAD0AdQCgALYAsQCZAHIAPwAWABQANwBpAKUA3QD+APkA2AC8AIsASgAkACsAUwCLAL0A4QAGAQ4B8QC1AG8APgAnADUAVgB/AKMAxwDLAIUAFgCx/2z/QP8r/zL/Sf9s/4v/jP+G/2v/Yf9p/1X/Nf8a/yf/W/+J/5b/lf+Y/47/cP9U/0T/N/8s/zD/Mv8t/yr/Jv8u/07/a/9q/1P/O/9a/5P/sv+X/2T/XP+S/9j/AQAAAO7/5/8GAD0AXwBNAA0A1//K/+b/FgA6AEEASwBmAHwAfgBvAGEAagCIAKgAvgDEAMAAtACvALAApACBAFoAPwAxADYARQBbAGMAZQBGAAwAvf+J/5f/w/8AACUAJQAQAAYA+P/T/7b/pv+Y/4v/lP+v/9f/5f/i/97/0v+s/3z/W/9b/4j/s//Y/+f/+P8RABQA8f/F/5n/gP+I/53/yv/z/w8ACAD2/+T/5P/k/8z/oP+T/67/zP/W/9r/5f/r/9//y//D/7z/t/+7/73/wP+//7r/pv+H/2j/WP9i/3z/l/+m/83//f8eACwAPwBaAHEAegCBAJ8AsAC2AMYA3ADjANwAxwCtAJMAcQBNADEAHQAKAPb/2//M/9L/+P81AF8AcQB/AH4AeABpAFsAbQB6AGwARQAhAAkA/v8MABoADwDm/5f/Tf8Y/wj/F/8r/z//S/9V/3L/pf/c//P/9P/j/9f/7P8dADoAOgArACgAOAA+ADIAFgD5/9z/yf/E/+D/IQBiAHQAcABoAGMAagB7AJwAxwDrAPoA/wAEAf8A9ADfAKoAVAAJAN3/2P/v/xMALQA8AC4AAgDO/6L/iv97/3f/gP+g/9X/GABVAGsALwDO/37/Y/9q/1//Wv9R/0b/Qf9L/03/PP8e/wn/IP9b/5P/tv/F/7z/rv+p/7z/xP+8/8X/2P/o//z/CQAUACIAKwAIAMH/iv+T/7v/5v8FACAAKwArAC8AIQATABgAPABaAGMAXQB3AJoApAB+ADoA/f/n//L/HwBVAIQAoQCUAH4AZgA/AA4A8f8CADAAYwCUALYAwQCsAH4AZABTACoA7v/V/+P/9P/i/7L/gf9y/27/T/8n/wX/C/8v/2X/iP+N/4P/dv9o/0n/Mv8t/zr/Uv9u/3z/k/+o/6j/jf9i/03/Mv8b/xj/IP82/0n/Zv+D/5f/q/+v/6D/o//F//n/CgD1//b/GwBeAIUAlQCUAJYApwDGANYA3QDmANwAwgC2ANEA/QAaASgBPAFNATwBKAEfASIBKwFDAUgBJgEFAQoBLQE+ATMBGAHsALUAfwBmAHQAZwBAABkA+f/r/9z/wf+d/4v/nf+g/5L/ev9g/0z/O/8y/yf/CP/e/sP+wP7Z/vX+AP8N/zP/XP9u/2D/SP9S/2r/f/+P/57/pf+y/8v/7v8OABkADADw/9r/2f/k/+3/6//x/wcAJwA6ADwANwAzADMALgA8AFcAdgCXAKEAnQCBAHIAYwBNADIACwDs/9L/u//A/9z/5//T/6n/e/9i/2P/ev+K/5j/qP+y/7z/0f/o/+v/3//W/9j/4f/4/w8AJwAkABIACgAEAAEA8v/Z/73/rP+p/7f/zf/d/+P/1P/I/87/yv+9/73/1//t/+z/3f/T/9z/6P/z/wgALQBIACwA9//T/7//pP+N/5v/yv/i/+D/y/+9/7j/r/+r/7P/w//L/87/6P8tAHUAogCrAJoAjwCRAKUAuADGAM0A3wD2AP4ADQEvATQBFgHdALMApwCwANcA7AD7AAYBBAHtAL8AkgBzAFwAUABMAEEALwAbABYAIAATAPj/0f+f/3n/XP9R/0//Sf88/zH/Lv8L/9f+qf6d/qH+of6I/mj+Zf6H/qr+v/7I/sH+sv6y/tj+Cv8i/yn/Lv83/0f/a/+M/5//sP+6/73/u//D/9H/3f/0/xsATABYAEsASgBGAFIAZACNAMEA6wD/APEAzACdAI0AowDEAMEAjgBJAA0A5v/p//T/8f/o/93/6P/5/+r/t/91/0r/Sv91/6//0//X/7//v//L/83/y//Y/+v/5P/O/77/u//B/9L/9f8MAAgA5P/F/73/yv/b/9r/1P/p/wQAKQA2ACoAHAATAAcA8//b/8j/tv+b/6D/uf/1/ykATgBSAEkAUAByAJcArwCnAJcAmgCpALsAuACgAHcASQAsACIAPABbAGcASAAXAPP/8/8AAAoALABpAKgA3wAUAT4BbAFsAUUBCAHgANMA3wDxABIBKgEbAesArgBwADYAAwDd/+L/AwAzAFAASQAoAPz/3f/R/93/+f/3/+H/3f/3/woA7P+c/zr/7f7L/sP+0f7m/v7+Dv8L//X+4f7T/rr+o/6d/rr+7f4l/1z/kf+p/6L/k/+R/5H/kf+m/8n/5//b/8j/xv/J/8D/vv/U/+T//P8uAGwAoACnAJEAbABTAE8ATwBSAGQAdQB4AH0AfAByAFMAHQDp/8X/uv+9/8r/1P/a/9z/2f/V/83/yv/U/+P//P8QADMAQgA6ABsA9v/i/9X/0//d/9T/y/+3/6r/sf/A/73/rP+L/2v/aP+I/8P/5f/h/8z/zv/g//L/+f/s/8z/q/+a/5v/nf+k/6j/qv+V/4v/kf+v/9f/6//r/9b/zf/S//L/FwApABkABgD+/wYADAAUAAgA6P/H/6z/lf+U/7n/yv/C/6X/iP95/3b/jv+t/9H/6f/1/wMAEwAVAAgABAAVADkAWwBvAHcAcABfAEoANAAgAAgA+P/1/+3/4f/a/+T/7f/z//f/9P/z//b/8//5/wIA9//n/97/yv+x/6P/rv+3/7//xv/O/93/zv+p/2r/Kv/+/gn/OP9m/4X/i/+N/4b/f/90/3D/Z/9j/2z/ff+c/77/4f///xYAGgAMAAQADgAuAE8AdgCOAKAAqgDFAMYAswCSAIAAiQCrAMgA3QDkANsAxQCyAJ8AegBYAEsASgBGAD4AQgBWAGwAeABvAEoAGgAEAA0AIwAuACgAGQANAPr/3v/J/7v/qP+Y/4z/lP+Z/53/fv9N/y//IP8p/0j/cP+R/6n/xf/Z/9b/xP+r/5r/fP93/37/l//F//H/DgAVAAgA8v/e/+D/7/8DABoANwBXAG8AggCDAIIAfAB5AIEAlwCyALgArgCvAKgAlwB8AFoANwACAM//wf/Z//r/FQAUAPn/w/+f/47/k/+g/5//nf+U/57/tP/Z//L/8P/F/5f/if+S/7b/2f/5/wYAAwD5/+b/x/+o/5f/pP+//9v/9f/0/+D/zP+z/5P/jf+W/6//w//G/7//tf/D/9T/4f/w//b////+/xAAPwBmAHQAbgBtAHMAbgBoAG0AbABzAHgAdgB4AH4AfgByAGMAWABIAEgASQBZAGYAZQBWAEYAQgBGAFsAawBtAGcAcACAAIoAiQB5AGUAQQAeAAkABgASABgALQA2ADUAHQAEAP//9v/d/87/zf/f////HgAtACwAFQD1/+j/4v/Z/8n/vf+z/6r/rP+w/7j/uP+f/4X/ZP9Z/1L/T/9Z/2//if+R/4T/dP9p/2//ev+A/4z/nP+z/8f/0f/c/9j/yv+z/7P/zP/Y/+P/9f8VADEAQQBPAFEAUwBSAFwAZQBpAG0AawBaAEcAQwA3AB4ACgAbACUAFgACAPT/8P8DABgALgA0ACsAGwAoAEYAZAB/AJIAnQCPAHsAdwB5AHcAcwBhAEkANgAuADEAKwAlABIA7f/b/9r/4f/c/9f/yv+t/4r/d/94/43/k/+S/5D/h/93/2H/Sv8y/xX/Av8B/xX/Pf9s/4f/jP+H/4D/ev+O/6X/vP++/8z/4f8LADMATgBHACwAFAAcAEUAYgB1AHcAegB7AHcAcABlAF4AZABwAHsAmQC8ANYA5QDdAMMAmQBzAGEAZAB2AJYAqACnAJAAfABuAGYAVwA1ABwACAD5//X/+f/0/+P/2//S/9b/9P8TABYA+P/X/8D/uf+6/7j/q/+d/5D/k/+t/8T/0P/H/7b/nf9+/2D/Sv9S/2X/Zf9r/3L/aP9X/07/Xf9Z/2D/df+R/5f/of+3/8r/0P/H/8D/wf/R/+H/+f8IABIAJwBGAEcALwAMAP//8//5/wcAFAAhACcAKwAmABEA8//a/+7/EgA3AEEAPAA5AEQAYAB7AHoAWwA4ACYAOABoAJgArwClAIIAZwBZAFAATQBNAEEAIQAUABwAIQAoAEAATwBKADsARABNAFsAVgBBACAAAgDo/+n/BwAsAEYAUQBEADMAIgAYABMAHAAgAA8A//8CABIAGgAUAAgA9v/h/9L/1v/u/wYAHgAxACwAHQAXAAUA+P8DABoAKwA6AEgAUAA9ABIA0/+q/4j/eP9+/47/nP+b/5D/gv92/2j/Yv9l/1v/T/9P/2L/h/+4/+H/8f/n/8z/uv+4/77/2/8IADUAVwBlAGUAUAApAPz/6f/n/w8AQQBoAHcAfwB2AGcASABBAD0ARQBWAHIAlQClAKUAqACsAJoAggBQACgAEwAnADsAPwA4AB8A+P/P/6X/dP9H/zT/Qf9g/4H/iv+L/3T/V/9A/z7/Qv9b/3T/g/+U/6H/pv+x/8D/yv/E/6//qP+r/87/8f8QACIAGAD8/+f/1P/I/9L/4P8CAB8ANAA/AEYATgBeAGcAYwBKADkAPQBsAJkAnQCIAGoAVABTAHQAqgDYAOcA0gCdAGoASAAzADYARABJAEMANwAmABQACAABAPD/1//G/8j/z//e//P/DgAaABoABwD+/wAADwAYABsADQAAAAkADgAUAP//8P/h/9//3//g/+j/4v/U/73/qf+v/8f/8P8WACYACwDb/7X/pv+k/7L/w//C/7b/pv+u/7//vf+k/4f/bv9p/3b/j/+o/7b/rP+O/3T/bf98/4r/k/+N/37/gv+I/4//pf+x/6T/lv+L/5b/p/+9/9X/3v/t//b/CAATABAACwAGAAUAAwACAP3/AAAVACkAPwBHAEwAQAA0ACUAGQD9/93/v/+5/8n/4v/1//D/4P/Z/87/uP+s/6n/tv+9/8H/v//E/8f/z//e/+H/2f+6/6f/nP+h/7f/2//+/yQAQABbAFsAOAAUAAMACQAQACwAQABJAEwATQBDAC4ADgDk/9H/xP/D/7//zv/g/+j/5v/Q/7P/nP+V/6j/3v8bAEAARwA6ACcAGgATABQAGAAdADcAVwB1AH8AgQB3AHMAdQB2AHsAfAByAGkAbAB6AI0ArADCALsAlgBzAGkAcwCDAKEAyADgANUAtQCTAHsAbQB3AJUAtgC/AMQAtgCeAHcAQgAVAPr/+v/7//3/+v/x/9b/rf95/0H/F/8G/w7/IP85/0D/Pv9I/0v/OP82/0D/Vf9t/4//uv/Q/9X/tf+c/5L/l/+i/7H/yf/d/+r/5f/Y/8z/y//N/8r/y//U//f/IAA9AEIANQAXAPr/3v/Y/+T/8/8GACYASgBYAGIAVwBEAB0A8//O/8L/zv/f//v/DgAIAPD/3v/A/67/p/+x/7j/zv/q/w4AIQAdAAYA/f/y/+7/9f8WAEEAXABnAG4AZgBWAEYAOAAkABYAGQAtAD4AXgBmAFkANgD//8z/pf+T/6D/xv/k//v/CAALAPb/2v+2/5b/h/+H/5j/qv/A/93/6P/o/9X/uf+l/5L/i/+W/7b/2P/l/+D/3//l//H/+/8AAAsAGQAkACsAMwA/ADsAIQALAAAADAAhADYAQgBRAFoAZQBlAGgAYwBVAEYAQQBJAEgARgA6ACQAHAAeABQAGQAmACkAIAAJAPj/8v8BAAoADwD///f/6P/Z/9H/0f/X/9z/3v/a/9H/vf+a/4T/gf+D/3r/df+C/4b/iv+L/43/j/+f/6b/ov+a/4v/i/+W/6P/sv/H/9H/1f/d/+n/8//3//3/BQAJABAAEwAdAC4AQQBIAE0ATQA/ADgAKQArADMANQA5AEkASABEADcALwApAB0ACQD2/+z/8f8DABYAJQAhABcA/v/k/87/sv+s/6f/sP/G/+b/9//s/87/q/+T/5z/pv+y/7b/w//R/9P/x//E/8T/wf+6/7r/vv/G/8b/uv++/8b/0v/I/7P/p/+s/7X/tf+1/7n/vP+2/7v/yf/O/8z/wf/B/9D/4v/6/wIA+v/l/9T/zv/f//b/DwATABsAGAAWAB0ALwBCAD4AQgBIAFYAYwBvAHEAYwBNADoANQA5ADwANwA/AEEASABFAD8AMgAdAA0AAgD//+3/6f/g/+f/8v8GAAsAAQDj/87/yf/H/8j/yP/d//f/BQAFAAkAEAAJAPT/6v/r/+L/0//G/7r/r/+4/8r/4v/z/+D/x/+u/7j/yv/V/8b/tP+z/8H/1//j//D/8P/o/+3///8UACgANAAyAC0AJAAvADAALwAqACcAGAAOAA4AGgAXABAAAgAEAA8AGwAaABkAIwA1AE8AYQBbAEYAMQAlADEAOQA8AEAARgBBADMAIgAPAPr/6f/d/83/vf+7/8L/yP/U/9f/zf+9/7b/t/+6/7r/qv+k/6v/tf/Q/9v/2f/O/8L/wv/I/8P/uf+h/5L/iP+I/5P/tv/Q/+T/7v/y/+v/5v/6/xYAKgAwADIANAA8AE0AYABtAH0AkwClALYAwQDAALgAqACUAJAAowC8AMIAvQC2AK0AqQCsAKUAmgCHAHgAagBhAFEASgBDADUAGQAGAO3/3v/A/6//pP+c/5n/pf+y/7b/sv+p/6b/kf96/3T/e/+N/57/pv+w/7r/xv/B/7z/vP/C/8//0f/S/9P/0P/U/9P/0//H/8L/vf+4/8n/5v8BAAEAAgABAPr/5P/O/8n/1v/h/+b/7f/r/+P/1//Q/9L/zv/L/9D/5f///wYADgAJAPP/zv+y/7f/1/8MACIALAAtAC0AHQARAAkA/v/4/w4ANwBfAIQAmQCwALkAtgC0ALoAwQDQANYAzwDQAMwAuwCmAJMAgQBzAGEATAA4AB8A+v/Y/7X/of+R/4n/gf90/2L/Q/83/zv/Mf8k/w///v70/u7+6f7t/uz+6f7X/sr+wf6x/pj+j/6O/qH+u/7R/uz+9v7x/vD+Bf8l/zj/Vf+E/7//9v8cADUASQBVAFkAYwBxAHYAeQCRAKgAtQCxAK0AqgCjAJsAnwCgAKEApQClALMAswCiAIUAeQB4AHIAXABWAFsAbAB2AHYAYgA2APn/yv+0/5//j/+Y/5b/gv+C/3v/Y/9I/zP/Mv9C/03/U/9n/3v/hP+F/4H/if+M/5f/m/+l/63/pv+x/8j/3f/m/+v/4f/F/7X/v/+//7X/sv+1/77/w//A/7j/q/+e/5b/rP/P//j/EAAoACwAIwAPAP3/9//9/xMAKwA0AEMAVwBzAIEAfABwAE4APQBFAFgAXgBmAIIArACvAJgAfwByAG8AewCVAKkAuADGANEAzgCyAJcAkQCPAI0AiwCJAHwAfwCEAG0ATgAoAAQA8P/w/+3/8//+/w8AGAAJAOv/wP+g/4D/ff+Q/5z/qf+0/7X/p/+O/33/af9U/0v/QP9F/07/X/9r/3j/cP9X/0L/SP9f/3n/jP+g/6b/rf/B/9f/6P/m//H/AgAXACoAQwBlAGoAbQByAHAAWgBkAHwAngCrALIAtgC5ALIArACWAHoAWQBEAFEAcACMAJ0AoACTAIYAdQBeAFoAYQByAIcAlACPAHUAVQA/ACIABQDt/9f/wP+s/6T/pP+v/7L/v//M/8H/pv+W/5f/of+u/7H/tv+p/6H/lf+U/5H/gv+C/4H/h/9y/1T/N/8l/xn/FP8b/zf/V/9s/4L/kP+c/5j/lf+l/7v/zv/X//P/EwAxAEoATgBKADgAKQApACcAKgA7AFYAgQCkALAAoACEAHAAZQBdAFkAXQBnAHsAggCGAIEAZQBHACUACwD9/wEADQAiADMAOwAzABcA/v/t/+3/7f/r/+n/8f/5//7/8v/W/7f/lv+J/4f/mP+e/5n/l/+V/5H/fv9y/2X/X/9W/2P/bv99/4z/pf+x/57/jv+B/4X/lP+m/8D/1v/o//b/AgD2/9//z//A/7r/xv/W/+v/9f/+//r/+P/m/93/1f/W//H/CgAjACkAKAAgACgALwAsACIAHwAgAEUAXABlAGUAVgBXAFQAVgBQAFUAZgBwAHMAfwCSAKEApQCVAHQAaQBnAGYAbwCBAIcAgQB2AFIAMwAUAOv/1f/E/7//wP/J/8P/rf+V/4T/dP9f/0f/O/9E/1n/Z/9r/2r/Wf9F/zj/KP8g/yX/K/8v/y7/N/9F/03/VP9R/1T/Uf9J/0z/X/+F/6P/rf+1/9D/8f8GABoAIwA1AEAAUQBaAGoAfgCUAKsAvwDQANkA4QDnAOAA2QDMAK0AkAB+AGcAVABSAFUAWgBbAFEAPQAhABIADgAIAAMADAAeACYAPgBFAEIAMgAfAAMA+P8CABYAOQBGAEAALgARAPL/zv+0/6T/nP+k/7H/tP+2/6z/lP+G/2//X/9i/2b/g/+T/6f/vP/A/8n/zP/R/9H/0P/G/7v/rf+j/7L/wv/O/9H/1v/V/83/u/+3/7f/u//B/8z/1v/c/+X/4//i/+b/7f/4//7/BwADAAEAAgAMAA4ACQAOAAoAEQAbACUAKAApABMA+//s//X/BAAzAEwAWQBWAEgAPQAtADAAOgBFAE8AUwBbAFcAUwA7ACoACADj/9b/1f/j/+v/7f/d/83/vv+l/4X/bf9h/2P/Z/94/4f/kP+J/3v/av9o/27/d/+O/7P/2f/s//L/9v/v/+f/4v/k/+D/4f/s/w0AJAA+ADkAKwAbAA4AEAAeADkAWwB9AJsAtgC5AKoAkwCCAHQAeACFAJwApwCyAL0AxwDJALUAmQByAGIAVQBcAGoAgACIAIAAZABOADIAJAAfACcAQABEAE8AVQBVAFIAQwA4ADIAMQAyAEAARgBDAEMALAAhABkAFgAGAPj/7P/g/97/3P/L/8b/vf+1/6//qP+v/7j/v//F/8//1//c/+D/6P/o/+T/4v/v/wUAEgAZACAALgAvAB8ABAD3//H/+P8FAA8AIAArAD4AQQA9ACIADwAOABQAIgA8AEkAQwA7ADQANwA0ADMAPQA9ADoAQgBGAEoAQAA3ACcAEgARABEAHwAoACgAKQAiABkAEQACAP3//P8RABEAFgAXABUAGAAeABcA/v/i/9D/1f/b/+L/4v/Z/8L/q/+c/4H/bv9k/1//Xv9i/2z/e/+I/5X/of+4/8n/yP/M/9L/4P/k/+v/8f/5//3/AQATAB8AIAAWAAIA8//r/+P/3v/J/7L/qf+1/7//w//G/7z/x//T/+f/+P8MABYAJAAwADwASwBQAFcAVQBXAFEARgA7ADIALwAxADAAIAANAPX/4P/N/8n/zf/g/+3/+/8MABoACwD6/9z/zP/J/8n/z//a/+//AQASABwAHQALAO//1P/J/8r/zP/H/7j/rf+d/5j/kv+E/3//ff97/3z/e/+I/5T/of+v/7n/wv/O/9j/4v/m//P/+//+//X/8P/p//P///8HAA0ACgAAAAAADQAVABsAHgAnADgARABYAGMAYgBmAGoAbwBzAHoAggCOAJoApQCmAKMAnACQAI0AjgCEAHsAaQBpAHMAcQBsAF0ASQA1ACYAKAAiAB0AEgANAA4ADQAVABIA/P/n/9f/4P/t//r/+f/4//r/AQAQABwAEwD//+3/6f/r//D/9v/z//L/AAAdADIANgAqABgABgD6/wkAIgA8AEYATABQAEYAMQAiACQAIAAYAA8ACgAFAAIACQAGAAIA8//Y/8r/x//V/+L/7P/y//b/+f8IABQAJAA+AEcARwBOAFYAWQBYAEoAOgAwACgAIgApACkAIgAOAP//+//z//X/9P/s/+X/6f/x//f/+v8IAAcABQD4//b/8f/1//z//v/+//j/6P/Q/8b/vP+v/5X/ef94/4T/nv+w/7X/t/+u/7D/tf/D/8j/2P/j/wAAFwAnADYAPwBMAEgAPwA0ADIANAA4ADsANgA7ADoAPgBFAFMAUgBJADMAIgAiAC8AQgBJAEwARQA8ADsARgBLAEEAKgAMAPX/7f/y//n/+f/t/+D/2f/g/+H/5v/e/9P/yP/L/9f/6P/v/+//7f/l/+L/1P/S/87/zf/Q/9j/3v/p/+//6//f/9X/x/+x/6f/pv+m/6f/rP+z/7v/xP/G/8f/vP+v/5v/h/99/4H/k/+a/6H/o/+k/6n/pP+e/4X/b/9n/2z/e/+Q/6b/sv+1/6//qP+g/5v/lv+V/5//sP++/9f/4P/w//b/9//1//L/+f8CAAsAEgAYABoAIQAmADYARQBHADoAJAAYABkAKwBFAFsAagBkAFgAUgBTAEUANQAmABoAJQAzAFQAawBwAGQAYwBkAGEAWQBLAD0ALwAwADsAQwA+ADYAIAAKAPz/9v8AAAIA9v/s/+n/4v/o/+z/8f/0//T/8P/t//L//P8XACIAJQAeABMAEAATACAAMAA9AEgASwBJAEQAPAA3ACwAKQAqADEAOgBBADsALgAWAAoA/P8AAAsAEgARAAkAAwAEAP3/8f/Z/8T/uv/C/8j/0v/Z/+j/8v/1//D/5P/k/+b/9P8KACIAMwA+AEsASwBMAD4AKAAUAAoADAAnADwATABJADgAKAAWABQADwAIAPj/6v/v//v/EAAVABMACQD///L/7v/y//X/9P/3//n/9v/r/97/1v/G/7b/rf+s/6z/rf+u/67/pf+Y/5H/kf+d/6r/vf+9/7z/vP/B/8b/1f/n/+v/8v/0/wcAIAA2AEcARwA/ADcANwA/AEsARQA3ACYAHwAhACwALgAkABMA+f/u//D/+v8DAAgACAAQAA4AFgASAAcAAAD2//r/9f/x/+3/5P/W/8b/uP+3/7T/tv+6/7v/tf+8/8H/w//H/77/uP+v/6//qP+n/7T/vP/A/8T/x//N/9v/5v/x//X/9P/6/wMADAANAA4AAgD///3/AgANAB4AKwAqADEANQAuACYAJAAhACQAJwAnACwAMQAyADMAMQA5ADoAOwA5ACYAFAALAAwAEQAcACAAIAAUAAwACQD5/+3/4f/d/9r/3f/g/+f/6f/k/9j/2f/V/9j/3v/l//b/CQALAP//9//j/9P/1f/T/9b/3P/a/9D/yv/F/8L/sP+i/53/ov+q/77/0//e/+r/7f/o/+T/3f/N/8n/0f/d/+3/8v/y/97/xv+r/5v/lP+R/5T/pf/D/8f/z//Q/9T/zf/D/7//wP/R/+f/FABEAF4AXwBgAFEASgBUAGUAfwCgAL0AyQDTAMQAsQCdAJAAhQCLAJMAmQCdAJQAiQB3AGUAPgAiAAoA+v/5/wsAIQAzADcAJQATAPj/4//S/8P/v//L/93/6v/m/9f/xf+q/5f/hP+D/4L/gP+A/4b/jf+S/5P/k/+L/37/f/9//5H/nv+w/7j/uf+6/7T/r/+p/6j/sf++/8j/2v/l/+n/6f/l/9r/zv/S/9L/4f/t////AwAQABQAFwAZABMAFwAYAB0AHwAkACcAKgAzADQANwBBAEQARQBMAEkARAAzACAACQDz/9z/2v/j//H//v8LABAABwDz/9r/y//H/8D/zP/Y/+7/AgAWABkAEwADAO7/3P/Q/87/0f/Q/9b/5P/h/9D/vP+h/4X/cv9s/3b/jv+k/7H/s/+v/6X/ov+n/7P/xf/Q/9b/5v/3/wAAAwD2/+j/2//Q/9b/7v8GABAADgAGAPr/7//n/9v/0//W/+T/AQAYACcALQAqABsADQAFABIAHwAuADoARQBQAF4AYgBdAFAARQA/AEEASQBKAEMAOgAkAA8A+f/k/+L/3v/k/+3//v8QAB8ALAAtACYAHQAUABgAFQAfACkAIwAOAPv/8v/l/9L/vP+3/7X/vf+9/7v/r/+X/4n/c/9n/2T/ZP9Z/1z/YP9x/4n/n/+w/7b/uf/I/9z/+P8QACMANAA2ADsAQABJAEoATQBPAE0AVABXAGIAZABmAGIAVQBOAE4AUwBOAFMAXABaAFQAVABZAFIATABNAEgASwBJAEoARAAwABwADgAAAPf/8f/o/9j/0f/Y/9z/3P/f/+f/8P/2//7/DAAAAPb/7f/n/+X/4P/l/+T/2//N/77/t/+2/7D/qf+d/5f/kv+X/6P/tf+4/7X/tf+0/67/qP+l/6P/r/++/9D/2P/g/9z/2P/M/8n/y//P/9P/1//u//r//v/2/+z/4P/R/8n/w/++/8D/0f/j//f/DQAVABIAEwAMAAwAEwAgACwAOQBLAFsAXwBcAE4ARgA7ADAAIwAfACMAKwAvAC8AIAATAPr/5//a/9j/3//Y/9X/4//q//b//P8AAPT/6v/m/+n/5P/f/9n/0P++/7T/sf+t/6b/ov+l/6H/mf+I/3b/W/9G/0f/T/9h/2f/cf91/3D/ev97/3n/hP+O/6H/tP/F/9v/7v/8/wAADAAWACMALwA9AEgAUwBZAF0AZQBbAFMASwBHAD4APwBIAFcAYwBpAGwAVwBCAD4APwA9AD0ARABOAFcAYgBnAFoASQA5ACAAGgAXACUALgAwACYAJAAaABkAEgAAAPj/+v/8//v/AQAJABAAEwAOAAYADAAKABMAFgAVABsAJAAtAC4AMgA1ADgAOABAAEQARQBAADkAMAAkAB0AFwANAAMA/f/1/+//6v/j/9z/0P/H/77/w//F/8b/wf+z/6f/ov+k/6L/pv+g/6T/nP+c/6P/p/+q/6j/qP+e/5n/n/+j/7L/x//U/+X/7//6//n/+f/3//b/8v/u//j/+P/+/wEAAQAHABAAFAAUABEAEAAEAPX/6//e/9X/z//O/8//zf/T/+H/7f/z//b/6v/k/+r/9//8//r/8P/r/+3/5f/e/9j/0//Q/9L/2f/j/+r/6//k/+H/3//b/9P/y//I/8z/2//q//T/8//q/+7/7f/x//j//P8FAAkAEAAWABUADAAKABAAEwAdACkAKwA2ADoAOwBBADkAMwA4ADoAQwBPAE8ATQBCAD8AOQAvACkAJwAmACsAQABgAGoAcQBsAF8AVwBYAFcAVABMAEYATwBUAFgAVgBDACMABADs/8//wv+2/6z/pf+e/57/o/+p/6b/o/+n/6//uf/N/97/4v/e/93/4P/r//v/BwAKAAwACwAJAAgACwAGAP7/+v/2//j/9v/1//f/+P/x/+3/6f/q//j/CQAZABkAHwAgACYAKQAnACYAIAAlADAASABbAGAAWwBRAEkAQQAyACoAIgAaABwALgBFAE8AXgBhAFcARwBCADgALwAmACAAHAAYABkAEgAFAO//3P/R/87/1P/k//f/AgAWABQADAD7/+X/2f/O/83/0v/c/+7/+v/8//f/9v/9//7///8HABIAHQAgABQAAQD0//D/6//o/+f/7f/0//P/8v/4//n/8f/l/+b/5P/n/+b/7v/z//z/BAAHAAEA9f/w//H///8JABIAHgAeABYAEQAEAPr/6P/d/9j/5P/7/w8AKQAwACwAJQAcABEACgAOABAAJgA5AE4AWQBaAFQAOgAlABYAGAAhACkAMQA4AEEAPAAtABQA/f/u/+X/2v/Z/9z/5v/8/wQAAAD6/+z/5f/o/+T/5f/r//b/DAAeACMAIQAkABoAEgANAAYA/v/4//f/8v/w/+7/6//o/+L/2//U/8//0P/O/8z/w//B/8P/xP/E/8r/yv/K/8b/wv/C/8X/xP+8/7j/s/+y/6z/rv+n/5//nf+e/6X/o/+j/6v/tP/A/8n/zf/M/8T/tf+l/5j/jv+M/5H/nP+c/6D/qf+x/7X/v/+9/7P/sv+y/7//xf/V/+P/3//p/+7/9f8CAAkAFgAiACoAKwAwADoAQQBJAEgARgBDAEkARgA7ADcANAA0ADgAPgA/ADsAMgAkAB4AKAArADIANwAyAC8AJQAgABEABgADAAoAFQAgACUAIAAcABcAFAAOAAEA+//u/+D/4f/f/+X/7P/z/+//5f/V/8//zv/W/+H/6v///wgAEwAQAAgABgD7//n/9v/7/wQABAADAAQA/f/u/+P/3f/g/9z/3//w//v/BQASABgADgD8/+r/2P/T/9L/0f/Y/9z/4v/k/+T/6P/e/9T/0//a//L/CwAoADsANAAwACgAKwApAC0AKAAhACUAKgA0AC4AIgANAAAAAwAGAAAA/f///wgAFQAgACcAKwAiABAA+//w//X/AwAJAA8AGAAdAB0AEQAQAAYA+f/w/+n/6v/m/+H/1v/M/73/sf+e/4v/hP+I/4X/hP+S/5L/if95/3P/df+E/5D/n/+0/73/yv/S/9P/zv/V/+D/4//u//r/CAARAA4ACwABAPH/7P/q//b/+v8GABkAIAA0AD8AQQBAADkANwA1ADUAPABKAFYAXQBfAFkASQAsABYACQAEAAwAEgAZABQACgAFAAYAAwABAPr/8f/t/+L/5P/p/+T/6f/z//7/BQAKABQAGAAUABYAEgANAP//9f/h/93/4//k/+//9v8FAAkADgADAP7/+//9////AAAEAAQABwABAP//+//2//r/+P/y//b/8v/x//f/8v/y/+b/2P/F/7v/u/+7/7j/sf+v/7D/rP+t/7H/sf+9/8D/0f/i//D/+P/y//n/+f/7//D/4//g/9f/0v/N/8j/zf/Z/+b/5v/l/+X/4v/x//r/AAAHABgAJAAnACgANwBGAEkAUwBZAGEAaABrAHIAbgBrAGIAYQBdAEoAQAA5ACsAJQAbABsAGQAUAA0ACQALAAoAFQAaABsAGAAWABUAEgAPAAsABwD4/+n/5f/k/+b/7P/w//f/9//0/+7/4f/Q/8f/y//T/+T/8//+/wcADQAMABAADgAGAAsAFwAfACcANAA3ADMAKwAXAAMA+P/0//j/AQAKAA8AEQARABcAHAAVAAYA8//m/9v/2P/e/+f/6v/g/9P/w/+2/73/yP/X/+b/8v/0//3/BAAKABIABwAHAAMAEQAkADMAPQBAAEoATgBVAF0AYABaAFkAXABdAFoAXwBeAFoAWwBeAF4AWgBXAE8ARQA6ACsAJAAaAB8AIAAYABQACAD0/+L/1v/L/73/uP++/8z/2P/Y/+D/5//x//L/8P/s/+v/8P/1//n//f/9//b/6f/b/9H/xP++/7T/p/+p/6P/n/+j/6b/r/+z/73/zf/Z/+D/4//h/+b/7P/3////BQATABcAEwAaACIAIQAbABIACQD3/+//9P/2//b/9v/s/+b/3v/c/9v/3P/j/+j/9P/9////+P/w/+z/5P/S/8P/vP+1/7j/v//E/8D/vv+8/7j/uP+4/8D/x//O/9H/2f/c/+D/6//w//L/5//d/9j/1v/Z/9n/3//m/+T/4v/i/9//4f/l/+z/8P/t/+n/8P/4//z/BAAMAAgABgAKAA4AEwASABUAGAAkADYAPwBDAEcAUgBaAF8AZwBnAGEAWgBeAFwAWQBeAF8AUwBDADQANgA1ACcAIQAdACQAKQA8AEgASgBLAEIAOQA1ADgAOAA/AEAAPQA7ADkAOAAxACIAFgAQAAoABwAHAAMA+//0/+j/4P/d/9r/zv/H/8P/xP/S/9P/0f/M/8D/uf+w/7X/tf+3/7j/tP+2/7L/r/+j/57/nP+S/5H/j/+G/4n/hv+Q/5f/lf+Y/5X/mP+c/6//wf/Y/+///P8EAAkABQAFAAgACQASAB0AKwAvADsAOgA8AD8AOgA6AC0AJQAhACEAJgApACcAKAAgABEABAACAAgAEAAUABMAEwANAAMA7P/d/9D/zf/K/83/0f/K/7//u/+0/6H/mP+N/4//jf+X/6T/q/+7/73/uP+s/57/lv+V/57/o/+j/6X/r//B/87/0f/V/9T/1f/R/9b/5f/4/w4AIAAxAD8ARABEAEsATQBQAFcAXgBnAGgAZwBtAGsAbABqAGQAaQBtAG0AagBpAGUAUQBIAD8AMgA2ADgAMwA2AC0AIAARAAQA+//r/+b/3v/d/+D/1f/L/77/vf+6/7b/u/+6/7z/t/+1/7v/x//H/77/sf+h/6D/nP+f/6P/o/+m/6H/of+R/4f/fv93/3z/ff9//4f/jP+P/5r/pv+v/73/wv/F/87/1v/i/+b/6P/p/+X/6v/t//D/8P/v/+7/6P/h/9//6f/t//b/+//+/wYADgAlADIANwA6ADYAMwAyAD8AUwBdAGcAagBrAGEAUgA5ACIAHwAaABsAJQApACwAMAA1ADwAOQAkAA0ABAAFABIAHgAkACoAHwAYAA0ABAD+//r//P8HABEAHAAnAC0AOAA7ADcANAAvACwAMgA5ADkAPwA5ADoAKwAZAAgA9v/x/+z/9v///wwAFwAXABYAGAAXAA4ADgASABcAGwAnADYAOAA0AC8AJAAcABUADgAMAAsADwAUABcAEQAOAP7/7P/f/9j/2//h/+r/7//2//D/7f/o/+f/3//R/8X/xv/Q/+D/7//v/+f/3f/Y/9L/1P/X/9n/2P/R/9X/z//P/8r/xP/B/7v/v//I/8j/y//K/8n/z//P/9T/yP+z/67/sP+7/8f/y//I/8L/vv+//8T/y//P/9D/xv+7/73/u/+5/7L/oP+Y/5T/mf+m/67/sP+p/5j/iv+H/47/mP+f/7L/yf/e//P/BQANAAwABgABAAsAGgAvAEUAWgBjAGsAagBhAGEATwBGAE4AUwBgAG0AegB2AHoAewBvAG8AbgBxAGsAaABrAGYAZgBZAE8AOQAaAAwACQAQABAAFQAOAAgABQD+//z/8f/o/+X/6f/x//z/CQAUABEACQABAAAA//8DAAIAAwALAA4AFgAXABkAGAAYABAAEgAaACEAIwAaABAABgAAAPr/+f/1//D/8v/3//z/+f/6//L/4v/Q/8b/xP/O/8v/1v/c/+b/8//8//3/+P/9////CAAMAA0ABwAAAPf/8P/n/9//3//g/93/4f/u//b/+v/6//n/8P/i/9v/1v/a/93/4P/j/+j/8P/v/+v/4v/V/8v/zv/W/+v/AgAQABIAEgAVABwALAA9AEYATwBQAFIAWQBaAGYAXABZAFoAVABdAFwAXwBfAFQATABLAEYAQQAvACEAFwATABkAFQAYAAsABAD2/+//9f/v/+z/7P/r/+r/6v/r/+z/8////w0AEgAUACQAKwA3ADsAOAA2ADMANQA1ADQAMgAxAC4AJgAmABwAGAAIAAEA/f/+/wAABAD+//f/8P/f/+D/2f/X/9T/0f/S/87/zf/G/8P/wP++/8f/0v/a/+r/9f/9/wUABQAHAAkACwAKABAAHAAoADUAPwBAAD4ANQAqABsAEgAJAAQABAABAP7//P/z/+n/2v/G/8L/wP/E/8f/z//b/+j/8v/4//z/AQAEAA4AGAAnACkAKQAfABsAGQAcACEAHAAkABwAHgAiACAAJQAjABsADQAAAPj/8f/w/+//6v/i/9j/1P/X/9H/zv/I/8r/zf/R/9H/x/+6/7b/v//H/87/1v/S/9f/1P/I/7f/qv+n/6T/pv+t/7X/u//G/9H/1v/V/8z/yf/H/87/1v/k//3/EgAfACoAKAAhACMAIQAhAC0AOQBCAE4AWQBWAE8ARABAADsAOgA4ADIALwAvAC4ALwA6AC0AHAAKAP////8JABoALQAzADgAMwApAB0ADQACAPr/+f///woAAwAFAAgA+f/s/+L/1v/Q/8//yv/L/8T/wf++/7r/uP+0/7b/v//J/8v/y//H/7z/sP+n/6j/ov+i/5z/oP+l/6r/ov+W/5j/mP+g/67/vP/I/83/2v/o//P/BAAPAB8AKgA8AEgASwBOAFAAVQBZAFMARQA3AC0AGAANAA4AEwAdACEAIwAnACYAKAAnACoAIgAoACsAIwAaABIABgD6//L/7//v/+r/6f/s//H/8v/s/+T/2f/Y/97/7P/z//r/AwAIAAQA+f/u/+j/5v/j/+D/4f/Z/9T/yP/H/8j/x//E/8L/uf+0/7f/uP/C/8n/0v/P/9H/1P/Z/+X/8f8CABUAIwAuADkARgBMAFUAYQBsAHQAhwCYAKEAoQCZAI0AgAB7AHAAcwByAHQAcwBwAF8ASwA6ACgAGgAYABEACgADAP//+v/v/+3/4v/Y/9H/w/+7/8H/yP/A/7r/sf+p/57/j/+F/4L/gv+D/4n/j/+Z/5v/mv+X/5T/j/+V/5n/qv+y/7v/yv/S/+D/5v/u/+3/5f/c/9b/2//a/93/4//q//f/+f/6//L/5//m/+L/5v/r/+j/5f/j/+r/6v/r/+//9v8HABsALwA+AEgAUABWAFEAVgBRAEgAOAArAB4ADgAMAAsAEwATABQAEgAWABkAHwAjACsAMAA1AC8AKQAiABcADQAKABEAFAAXABUAEgAPAA8ABAADAP3/6//d/8n/x//C/7z/sv+p/5z/kP+M/4n/j/+L/4v/jf+J/4f/g/+K/4z/kf+c/6f/sf+3/8H/wv/C/8X/y//Z/+D/4v/i/+b/5f/b/9P/z//V/9P/1f/U/9P/2f/e/+r/9v8CAAYADwAbADEAQQBUAGkAfQCRAJ8AoQCjAKAApQCrALIAtwCuAJ0AjQB8AHcAbgBpAGUAXwBZAFUATwBQAE8ASgBFADEAHAAEAPP/7f/g/93/2P/R/8r/yf/M/8b/yP/M/87/zv/H/7j/rf+m/57/nP+d/6T/qf+y/7v/xP/H/8f/wP/F/9D/3//y/wgAJAA1AD4ANwAvADEAKgApACcALAAwAD0ARgBEAD4AOAA1ADkAPQA3ADIAMQAyADkATABhAHAAcABzAH4AiwCOAI4AhwB4AHAAWwBOAEYAPgA/AEcAVgBbAF8AXwBVAFEARwBBADUAKQAbABkAJQAtADcAPgA4ACwAIAATAPn/3f/L/8H/xP/O/97/4//p/+D/1f/M/73/t/+0/7D/tf/C/9L/4f/r//P//P8AAPz//v8CAAMADQAdADIANgA4ADAANAA2AC0ALgAmADEAMAA7AEIARwBGAEgAQgA4ADAAKwAtACQAIAAkACAAHgARAAsAAgDz/+//5v/f/9n/2//p/+3/9f/0//D/9P/2/wAA/v8AAPj/8f/o/+T/4f/j/9//5//t/+H/0v/B/6j/m/+S/4j/hP+H/5P/pP+x/8D/w//L/8v/yf/I/8f/yv/K/9L/2//k//L/9f/z/+j/4P/X/9L/3f/q//z/BgATABcACwD0/9//2P/T/93/7f/1//P//P/7//X/7//r/+b/7P/w/wAAEAAhAC0AMwA8ADYAMwAqACIAIgAXAB4AJQAvADoAOgA1ACkAGAANAAcA+v/v/+z/7v/0//r/CgASAAoA+f/m/9D/vf+2/6//rv+x/7X/tv+5/7z/uP+x/6n/p/+g/6T/rP+x/63/pP+m/6X/sv+2/8P/0//e//H//P8KAA4ABwD7//D/5f/l/+X/4v/h/9//3f/e/+f/7f/l/9//2P/V/+X/7//0//L/7P/p//D//f8UACcAMgAwACwALwApAC0AKgAlACAAGgAVABoAGQAVABoAGwAYABIACgACAPH/5//Z/9P/1//m/+r/+f/5//f/+P/6//7/9v/1//L/8P/1//b/5f/a/8j/tv+j/5H/lf+f/6b/qP+h/5//mP+d/5//rP+//9L/7v/6/wIAAQAJABkAKgA4ADAAKgAhACUAIwAtADkAQwBLAFIAWABOAEoATABMAEIAPgA8AD8ARAA7ADoAKwAcAA4AAQAEAAMACQAHAA4AGAAlACsAHgALAPH/5f/a/+H/9P8JABIAFAAMAPn/5P/f/97/4P/n//D//P8EAAcAEAAWABMAGwAhACMAKAAyAC8ALgAtAC8ALgAmAB8ACwD6/+v/5//r/+P/5P/s/+j/1//M/8P/wP/A/8n/1v/0/w4AFAAaACQANQBFAEYAXgBtAG4AZQBeAFsATgBLAEgASgBOAFUAVABUAFcAVgBOAEIAPgAvACQAKwAoACMAIgAeABsADgAGAAEA/f/1//P/6f/q/+f/4f/X/8z/wf+w/6X/mv+P/4r/jP+J/47/m/+t/6//rv+2/73/v//M/9//7v/2//X/7//u/+f/5v/e/9j/0P/K/8L/wP/H/83/yP/Q/9//7//0//P/7P/j/+L/6f/0//b/+f8DAAMABgAHAAwAFAAgACcALQA0ADsARABCAEYARAA/ADcAMwArAB8AIwArAD0ASABRAFQAVgBIADgALwAqAC4APQBHAFgAZwBtAGsAZgBnAFsAVgBPAE4AUQBPAEUAPwA1ACsAGAD9/+z/1//H/77/wf/E/8z/2P/a/9T/0P/P/8j/zP/N/93/4f/p//f/+P//////AAD7//r/+v/+/wAAAQAAAPL/7f/0//j/AQAEAAIABQAGAA0ADwARABEAEwAaABYAHQAjAC0AMgAwACUAEQAIAAIABAAIAA4AEgAYABQACgD6//H/5v/d/8//zv/M/9j/4P/t/+f/3v/V/8n/xv/N/9j/3f/n/+//+P/6/+z/4//f/83/u/+0/7b/tP+6/7r/sv+o/6j/q/+x/6r/q/+o/6T/qP+u/6j/mf+C/3D/Zv9p/2P/Yv9g/2L/aP9u/3n/hv+G/4X/jv+Y/6n/vv/S/+L/7v/t//n/+f/8/wIADAAYACkAMQA4ADwAPgA8AD8ASABZAGIAaABnAGAAWQBbAF8AXwBXAEsASQBFAEoATgBWAFIAVQBSAE4ATABMAFEAVQBUAFEATwBLAFEAQgBBADoAQwBDADwAOgA0ACsAHAAMAAEA///6/wIACgAHAAgACAAOAAIA9P/o/+j/5f/q/+z/6v/x//z/BwAKAAsA/v/r/9j/1f/b/+L/6f/y//X/7v/t//L/+P/8//j/+v8CAAkAGwAxAEQARwBDADoANwAyADAAMAAsACMAIQAgAB4AHQASAAMA+P/t/+n/6//2//v/+f8DAAMAAgAAAP3/+v/5//j/+/8HAAoADgAHAP3/9f/3/+7/6v/l/+L/4f/b/+P/8P/2//H/6//o/+r/7f/r/+f/4f/Z/9T/0//O/8z/zP/S/8//2P/Z/9P/w/+6/7v/wP/J/9b/5//y/wUAEQAaABgAEAABAAQA//8CABIAIgA9AFMAXwBrAGgAXABOAD8AMAAnACoAKwAnADEANgA3ADcAMAAyAC0AJQAWAA4ACgAIAAYACwAOABUAFAAVABAACwAQAAkABgAHAAkACQAOAA8AEAADAAAA8f/q/+X/4f/a/9r/3f/n//z/CwALAA0AFQAiAC8AMwBAAEkATQBMADkAKwAdAA8A///w/+z/6f/s//L///8IAAcABAAAAPr//v/7//3/CgANAB8ALAA6AEcATABPAEgASgBHAEUARABBAD0AQQA5ADEAMQAxACwAOgBEAFcAZgBwAHgAgACDAHwAcwBsAGAAVQBJAEIARABCADkALQAiABQA9P/V/8X/sv+p/6H/qf+o/6z/s/+9/8D/uf+0/6//rv+r/6v/tv+z/7b/uP++/8H/u/+u/6P/l/+R/4//kP+J/5H/lv+b/5n/m/+m/7b/u//A/8b/1f/p//7/DwAWABUAFwAZAB8AGAARAAYA+//x//H/8P/v//L/+f8CAA4AGwAeABoAGgAdACAAKQAxADQANAAuACsAIAAZABMAEwAZACAAHAAeABgADQAAAOj/zf+w/6D/nv+h/6L/qv+3/8f/0P/X/9f/2P/h/+3/+f8IAA0AFAATAA8ADAAEAPH/3f/M/8X/v/+8/7n/vP+8/7z/wv/H/9H/1//k//L//f8DAAQA//8AAAcAAgD+//7/CgAUABsAHgAXABMADwAIAPv/9P/t/+P/6f/z//3/EQAgACYAKwAvADUANgA8ADkAPAA4ADIAKAApAC4AMwA+AD4ARQBIAE4ASgBEADkAKgAcABQABQD2/+f/2f/L/7v/sv+u/67/pv+U/4z/ff9z/2z/df96/3v/dv90/3f/ef98/33/hP+H/4H/fv98/4L/iP+C/4b/jP+F/4f/hf+V/6D/q/+9/8z/0P/L/8n/z//W/9j/3P/j/+////8IABQAGAAYABoAFAAXAB0AJQAoADkARQBRAFkAVwBHAD0AMQAmABgAFgAZABgAHQAhACEAIgAaABAA+//k/8b/tP+v/6//s//B/9n/6f/3/wUAEAAhACYAHQAaABMAEgALAAEA///5//f/AQAPABUAIwA7AEsAWgBsAH4AhwCDAIAAegB/AG0AQwAZAPv/7P/q/+//7f/i/9v/1P/K/8H/w//L/87/1f/f/+v/9P/z/+//7P/m/9z/0//d/+L/6v/x//j/9f/8//j/6v/W/9X/z//K/8b/yv/M/8f/x//N/9f/3v/Z/9T/0f/N/8P/uf+y/7b/u/++/7n/rP+W/4v/fP91/2v/Zf9h/2r/dv+F/5b/nP+d/6H/qP+x/7b/uf/B/8b/1P/d/9r/2f/L/9n/5//1/wMAFAAbABYA/f/m/9T/yf/L/9D/3P/k//f/AQAEAAkA/f/z/+f/2v/X/8z/yv/I/9D/4v8AABoAKwAzADgARABMAFcAXABjAGIAVAA9ACkAGQAUAAMA/P/z//b//P8CAA0AEQAUAAoA+//z/+//6v/s/+//AQAPABwAGgAXABgAEwARAA8AGQApADUAMwAnABUAAgD1/+b/2P/A/7n/sP+x/6z/vv/Q/9v/5v/1//z/BwAIAAkADwAUAAkADAAKAAcA+v/2/+7/5P/U/8H/uP+6/8P/yP/P/+D/8/8MACMAMAA9AEAASwBMAEkAOQAuACYAGgAbABoAGgAfAB8AIgAlACoALgAwADEAIwARAPz/7//s//L/9P8CAAkAFQAjADQAQQBNAF0AZQBuAHcAewBvAGgAXgBTAEoAPQA0ACcAGgAYABgAGQAfACAAIAAjACUANAAxACgAIQAaABwAHAAjACwANgA5ADkANgAwACEAFgACAPH/2//G/7v/t/+2/63/pv+q/6z/qP+p/7X/vv/K/9f/4f/b/9T/y//L/9b/4P/k//T/AwAHABIADAAPAAgAAQD4//7/BQAMAA0ADwAGAPr/8P/o/+D/0v/Q/8X/tf+p/7X/uv+u/6L/nf+X/5P/kf+Y/6D/rf+4/83/4f/w/wYAFwAWABUAGgAVABMAFgAWABgAFwAoADIAMQAfABYAEQAFAOv/2f/S/9b/5P/p//H/9//3//P/7v/h/9D/uv+p/6P/mf+d/6T/tv/E/9X/7P8AABoANQBKAFMAVABXAFoAUQBJAE8ARwBBADwAMQAkAAoA8P/r/+j/5//o/+X/5f/t//r/9v/q/+v/5//i/8//uv+x/7L/tv/D/9L/2//c/+T/8f8AAAIAAwAGAAMA/P/4//3/BgAMABUADwAAAOX/2//P/77/t/+7/7b/wP/J/9r/7v8AAAEABAACAPv/7f/d/9n/z//R/9P/2v/Z/+D/3//Z/9v/2P/a/9X/4f/g/+b/7P8DAAkABwAMAAcABgAFAP//+v/3//3/CAAOABYAHwAjAC8AMgAuABkACwAFAAIA9v/k/9f/3//k/+r/7//0//z/AwAHAAUABgAIAAsACAD8////CwAWAB0AJQAyADoAQwBGADgAJgAWAAoA+f/v/9//y//H/8b/zP/O/9//9v8FAAkAGAAtAD8ATABTAFMAVQBQADwAKQATAAwAAwAAAP7///8FAAEACAATAB0AIAAfAB4AIgAuADMAQAA+ADwAOgA3ACoAFQD6/+v/3P/P/8v/yv/X/93/3//s//z/EgAdACcAKgAuAC4AJgAXAA0A+//t/+v/2P/J/7T/pP+b/6H/pP+q/7v/1//p//z/CAAbAB8AHAArADkAPwBBAD8AMgAkAB0AGwANAPv/9P/y/+n/3f/Y/9f/2f/c/+H/3v/g/+b/7//+/wQAEgAbACkAJQAUAAUA+//x/+f/2//I/7b/sf++/8z/y/++/7b/sf+y/8L/zv/Y/+3/AQAHAAEA9//v/+H/1f/C/6//p/+1/8T/0P/b/+T/5P/h/9//4v/l/+z/+/8MAB8ANwBDAFMAWABbAFYATQA+ACYAEAD3/+D/yv+q/5r/jP+G/4b/if+X/6n/v//J/87/3/8FACAAKQAwADgALAAaAAsA///y/+f/5v/h/9P/z//N/8H/sv+h/4z/g/95/3j/eP9+/4r/kv+a/6j/uf/T/+b/BwAYACQAHgAKAPj/5v/o/+D/0//U/9v/5//g/9T/v/+0/6v/q/+r/6v/uf/F/9f/6P/4/wMABQADAAEA//8IAA0AFgAjACwALgAzAEAARgBHAEMAPwBEAEUAOgAtACAAIQAdABoAEgANAAcACgAQABgADwACAPb/8v/x//T/6P/k/+n/7//v/+n/6f/n/+z/4v/j/9v/1v/N/8f/wf/L/9X/2f/X/97/6//1//T/9v/2//H/9P/2//T/AQAOABQADQARABkAFQAbABYAHAAiACIAFQAHAP3/7P/j/+D/4P/e/97/5P/m//D/+P8AAAEABQALACAAMwBEAEwAUwBVAFUAUABRAFsAYABgAGgAbgBvAGwAWwBXAFEATwBDADIAJQAVAAoA+//z/+3/6v/r//b/CAAaACsAOQBJAEsASABLAEMAOwAqABoADQADAAAAAgADAAoAEwAbABoAGgASAAQA/v/q/9L/s/+a/4P/bP9c/1r/YP9l/27/dv9//5X/ov+n/63/rP+y/7f/vP/M/9j/6f/+/wwACAADAPj/6f/e/93/4//d/9f/2v/m/+7/5v/n/+r/8f/0/wAABwAOABQAFgAZAB0AHgAjACAAJAAiACMAKgAoACcAJgArACMAEQD3/+T/2v/X/9H/zv/O/9b/4//w////DQAmAC0ALgAoACIAJQAiABMA+P/p/+L/1P/F/8H/wv/G/8j/zf/c/+X/4P/k/+j/7P/t/+f/8P/+/wcACAAAAP//CAAAAPT/1//B/73/v//I/9j/6v///xAAIAAnACcAHwAnACcAKQAkABwAEAAGAAkAEQAYABkAFAASAA4ACwAUABcAEwAUAB8AKAA9AFMAYwBpAGUAXQBaAFQATwBPAEMAOwAvACQAHgATAAkA/v/z/+z/7P/f/9b/1P/X/+T/8/8FABMAIgAvADEANgA6ADgAPAA8AEEASgBbAGoAdAB5AIQAgwB3AGMATwA9ACYADADz/9//zf+//7T/nf+N/3v/a/9k/2n/aP9n/2f/bf96/4r/mP+g/7D/wf/Y//P/CgAhADUARABQAFUAWABTAEAAJwASAPv/5v/V/8n/w//F/8v/zf/Y/87/xf/A/77/uP+x/7b/uf/H/8r/0f/P/9v/3//k/+3/7v/y//T/8//1//3/BwALAA0ADwAhADEARABMAFMAXgBpAGYAXwBZAE4ASABAAD0AQwBGAE8AWwBWAFcASgA/ADMALwAdAAIA7//e/9X/0v/T/9H/0f/X/+7/9////wQACwATACAAMgA/AEQAUQBjAG4AdABuAGEAVgBLADgALgAfABIADQALAAwADwASAAoACAAMABUAGQAWAB8AIQAgACQAFgD6/+T/zv+4/6b/nv+e/5z/nf+p/7T/w//X/+r/BAAYADAAPwBNAFUASwBBACwAJAAQAPb/2//S/8j/u/+u/6T/qP+u/7b/vv/N/9H/z//H/8b/yf/X/+L/9f8JABgAIAAfABwAGgAVABYAIAAlACEAJwA5AE8AXABaAE8ARAA6ADMAOwBHAFMAUwBTADkAGgACAOT/y/+0/6z/rP+v/7v/wP/B/77/wP/I/8L/vv+9/8j/zf/T/9H/2P/T/8r/vf+5/8b/3P/u//j////5//n/+f/0/+//7f/j/9//2//U/8//1P/h/+z/8P/3/wMAAwASABQAHQAgACAAKQAzADkAPwBKAFkAYABmAG4AawBrAGsAZQBeAFcAQQApABsACAD9//3/BQAIAAkAEQAJAAsABwAMAAgA/v/t//D/7v/q/9b/wv+3/7X/w//N/9T/0v/Q/8n/yf+8/67/p/+h/6T/qf+n/57/jv+A/3L/ev+C/5L/pv+5/8f/1f/L/7X/jv9t/17/U/9S/1r/a/98/4T/cf9Z/z//H/8I//z++/7e/rz+j/5n/jr+Gv4H/v39+f38/Q/+LP5L/lT+Wf5T/lL+ZP6N/rf+8f44/5D/8f9UAM4APAGhAfcBLgI/AkECQQI+AlkCkALrAk0DlAPRA/gD+wPpA9cD0gPcA+sD+QMcBDQEPAQrBA0E5gO4A4MDWQM5AywDFQPgAosCHwKjASMBrwA4AM7/ev8k/9T+iv5I/gn+2/20/ZP9gv1o/Uv9J/3y/LD8efxN/Db8Ofxd/Jv82vwW/Uv9Zf1w/ZD9vv3v/Sj+Z/61/gX/R/+A/7j/5/8ZAEoAcQCNALEA4QAEAQ0BBgH/AAcBDAEQAQ4BBwH7APgABgEKAQUB/wABARMBDQHuAMUArACaAHkATgAQANn/u//N/+X/7v/w/9//vv+e/5D/k/+U/5n/of+t/8b/3//w/wcAMwBmAJoAywD2ABsBMwFIAWIBdQGLAZQBigF6AVYBIgHgAJsAawBWAEAAKQAXAAcA4P+T/zv/7v69/ov+Xv5K/kT+Q/4s/hT+CP76/en9z/25/aX9jf1t/VD9Qf06/UD9T/1w/Y79sf3c/f79E/4q/kT+bf6Y/sT+/P5L/57/8v86AG8AoAC7ANEA5QAHASsBVAGEAaoB0gHuAfwBBQICAgUCFgImAjcCPAJCAkUCPQIxAiwCJgIZAgkC+wHlAcYBrAGeAZMBhwF6AWcBUwEyAQ4B3wCiAGMAMgANAO7/1f/A/6//r/+7/8X/xv/I/8//zv/L/9D/0f/X/9H/0//V/87/zf+1/6L/hf9l/0b/O/9A/zz/Qf84/y7/HP8O/wL/7/7Z/sD+yP7M/tr+6P7y/v7+AP/x/uD+wv6i/of+df5t/nb+eP5t/mv+bv5x/nv+kv6s/sP+2/7u/vv+D/8k/zn/Sf9R/07/Pf8p/yH/Nf9V/27/hP+P/5b/mP+K/4X/kP+g/6X/qP+g/6L/oP+T/33/W/8s//r+2v7K/sf+uv6f/oX+bP5H/iH+9P3P/bv9vP3J/dX94/3w/fP9Av4f/kv+df56/mz+Wf5R/mL+pf4T/4b/5/8vAGkAqgDdAP0AHwFRAZYB3AEmAngC3wJTA6cDCARhBJQEuQTPBOUEEgU4BVAFXgVsBVIFIwUDBfAE6QTcBK4EfARPBBkE2gOiA3QDTwMjA9sCiAIfArIBPwHcAIoAPgD//77/e/8//wv/1P6Q/jj+1P1w/Sn9Av36/Ab9F/0Y/Qf99Pzn/OX86vz8/BX9Nf1f/Yz9tv3k/Rr+Wf6l/u3+IP85/z3/Sf9g/23/kP/I//v/HwA8AGEAkwDKAAEBNQFWAWEBVgFOAVUBcAGYAbkB6gEKAgkC8gHZAcABrgGcAYEBZwFUAVMBWgFrAX8BgwF0AUcBIQEKAf8ACgEmAUgBZwF8AXIBVQEzARYB+QDZAKoAgwBgAD0AEQDr/8v/nP9o/zf/AP/E/pP+dP5u/mD+O/79/bn9gf1b/TP9EP3k/Lb8dfwZ/NP7r/uk+7T71Pvk++X72fvL+9P78/sR/Dv8bvyi/OD8If1m/cP9Mv6o/hf/h//c/y4AhQDSACEBZQGnAeUBNwJwAqUC6AIpA1EDXANcA2ADZANVA1sDcwOMA5gDkgNpAzQD/wLFAowCUgIRAtABiwFFAQUBxgCNAEkA8P+V/zv/8f62/pv+mv6X/oH+Sf4b/gb+DP4g/hr+Cv7y/d/9yf2v/Y39bP1f/WP9eP2L/Yz9hP2T/aX9uP3A/b39vf2z/ZT9Z/1a/Yz96P1D/nH+f/5//nn+W/5C/jr+UP51/p/+zf4a/47/6f8sADIA/P+7/5j/w/9BAMQAAAEBAfgA9gDfAKcAfQB4AIsAngCjALgA8AASAfwAzQClAKkAxgDkAAEBTwHEAS0CegKzAsgC1wLpAvsCOgOMA7QDpAOPA3kDZgN1A64DDQRuBLEE2QQDBQ0F5wS2BKAEoQSlBJAESwTeA20D9wJnAsMBAwE3AJD/OP8d//b+s/5b/uP9N/1w/NL7iPth+zP7AvsE+z37bPts+0P7/fq8+p36fvpY+l76n/ra+gj7Y/vF+wz8M/xD/IH8//yC/fP9fv4f/5T/8P9jAPgAoQERAk8CpwIpA4oDjANRAzEDXwO1A9QDlgMyA/4C9QL9AiADVgNqA2IDXANHAx4DAwPwAuQC9wIQAyMDMAM9AzgDKgMAA7ACggKtAgcDTgNaAyUDzQJ8AgYCeAEXAR8BlQFMAgsDjQPNA9QDhgMDA4QCOQL4Aa0BVQEEAagAGgBp/9T+YP7r/Wn96vyC/Dj8Dfzo+7T7afsm+/D6s/p3+mP6ivrF+vL6EvsS+xX7I/sd+yL7NPsQ+8z6o/qL+pP6vPrP+tT6EvuD+9f7Cvwz/Iv8Dv11/Zb9qP3o/RX+Lf4//l/+r/4n/3X/pP/U/wgAGwAAAJD/2/4n/nb92/yd/Mz8Q/3V/Sv++/1J/Uj8O/t9+kn6e/r/+tX7vfyM/ST+qf6S/ycBBAPZBMsGoghNCvELfw3sDhsQvhDGEGAQkA9iDi8NaAz5C5cLVwtXC6ILtgscCwwKyAhWB8YFQwTMAqUB7wBzAAoAeP+O/on9pfzU++n6uvlY+BH3A/b19MLzpfLi8WzxBPF28NLvie+8733wt/Eb82L0cfVi9jn34/c3+HX4Cfnf+Yz60vrn+j373fuv/I79dP5N/7D/tP+z/8P/9P84AKIAbwFoAisDoQNBBDMFDwa6BmkHOwjkCP8IjwgGCJ8HMQewBjMG1QWTBWgFVwV3BckFDgZMBrYGRQcPCAsJ8gmVCuEK0gp9ChoKsglHCRQJMAmNCQMKWwpbChEKqgn7CPQHkwbwBG4DMwIxAWsAvf/0/hb+R/2W/Pf7jft7+9n7gPzj/KP84vsR+0D6P/n998T2IPbJ9TD1YfS783nzjPPT8xf0N/QB9Hbz2PJv8j3yWvLW8rPz1/T39fT20vfF+NP5tvp/+0X8Cf3r/ZH+wf65/sj+6/4A/wr//v7q/vT+/f4j/2v/zf9TAN4ATwGhAcoB9gFgAiADTgQXBocI/QrbDNwNJw4sDioOBA60DYYNaw0TDUcM7gpWCfAH9Qa4BlgHewh4CTAKygo1CzoL0QpGCtMJUAlTCNYGQwXrA98CDgI5AUoAQv8r/hL9Jvxs+7T68vku+Xz4rfe/9rn1DPUT9bv1wvbW9+H45vnS+nT7yPvU+5v7DvtO+or5u/ii90b2/vTs8x7zi/Je8q7yU/Mm9NX0PfWp9Tj24fax97f4tflP+nD6RfoX+g36Z/qh+6H9d/9GANX/VP57/Lr6Wvnf+HH5oPqv+3z8S/1t/j4AwALCBd8IeQtoDQsPxRC5Eq8UYBZnF4YX0RZiFWgTdhE3EMAPeg82DwEPxw5sDh0O9Q2xDR4NJwzyCoYJBgjCBiwGEwbVBSYF/gNzAnUAaf65/F37Cfp8+JP2l/Ss8rjwCu8Q7p3tdO147bDtU+6L73nxvfPc9Y73w/ix+Y76cftq/Ev93v3y/XH9h/yO+zn7tPun/ML9p/75/oj+x/1D/Qn99/wj/av9YP4F/5r/KwD1ABYCbwPTBOoFiwagBiYGfAUPBdIEYARbA/QBbgDg/lv9//vi+hH6xfnA+bH5gfkr+a34FPi699X38fed9yD3wvaS9o/2JffB+Dn7I/5LAWgErQZyBxMHvQYWB9AHlAhXCRkKnwpMCkMJbQhRCPgISgoxDFcOXxAaErMTSxVuFqsW7hVJFPgRZQ/VDJQKtwguB5UFeAPRAP79nfti+oD6S/u2+yb7nvmZ95j1+fMk8y3z/fMo9f31M/Yd9iL2kvZV9xn4zfgv+QD5Z/jg96730PcT+Af4mPcN99H2O/eA+NL63f2NACACfQIIAnMBHwFEAasBzAFWATwAjf6Z/A77nPpz+xr90P60/3n/XP4Y/T/8+fsf/EH8Hfy3+xH7UPrl+RP63PoN/Df95f30/e39Z/6X/4AB7AODBnoIFQl/CLoHkQfvBwUJ+woZDT8O/A3pDM4LAAu7CkELYAyKDSoOSg5HDlsOpw4RD1sP8A6eDWYLnwglBoAEfQPUAjoCFQEu/9z8zPqP+WX5D/oW+8T7Q/uD+Qf3hvSV8qTx5vEG80X0HfVh9Ub1TvWw9Vb2Evex9/T3AfgN+ET4n/jo+CX5Tvkj+bz4cvjU+DP6Kvw5/vz/GQEvATEA1v7//dT97f3u/cH9iP13/Y39yP1o/or/JAFqArMCQwKnASEBtQBhAC4A6f9d/5b+0P0o/cT8Jf0i/gz/gP9l/+n+I/5y/Uz9mP1D/jn/SQBxAX8CMwOEA7UDYwSgBU4HSQkPC/cLvQviCvUJSAn1CCgJAwrpChwLpAr9CbkJBQrjCtMLAwyEC5UKOAnSBygHTweTBy8H0gWtAzYB8f5o/ej8Av24/LD77/lo9+H0N/Oh8ifzZPRM9XH1GvV+9KrzFPNs86n0zvUS9pv1CfXx9EH1yfVZ9qH2lfYm9kP1c/SF9ML15fc6+qr7qPuc+o/5OvnU+aT7z/5DAjIEVwSFA4EC7wE6ApkDtQWSB0QIAQiaB50HAQiLCDkJ4AkhCs8JiwkQCnQLWw08D5AQxBCkD9cNbQxVDNsNVBDFEhMUuBP1EWAPIg06DMMM7Q2yDl0OugwvCmAHlQQzAn8AbP+j/pL9Hvxf+pP4M/cq9lj1uvQr9Kbz5vIC8l3x+PCl8BTwEe/l7Qjtp+yy7OHsy+xj7O7rXeuM6uPp6OnW6mLsJu6m777wt/Gj8pTz2fSO9oL4Tfqk+4j8vvxN/PL7tPy9/oABfQQPB50ITQlRCnQMgQ+cEvgUjxYeF40WYBU8FJ4TghOEExMTDRLSEA8QrhDmEu0VqRgnGkAaehlcGOkWQxXQEy4SiA97C0wGxwAP/Pz4oPdA99z25fVA9DryO/DU7g/uX+3M7IrsmuyM7OnrAuvr6jPsMO7/71LxNfLg8pHz3/NY8znyC/Hw77buZu147JTs1e3H7yXyFPVF+Df7zP0XAEgCbAR4BkcIhwkMCgsK2wmlCYoJ+gnkCrMLEAzuC6wLsQv6C1wMpQyhDCQMqguYC3sLMwtTC7IMOg8PEi8UaxVfFmwXdRjuGFEYvxbRFJsS2w+lDE8J/QXNArj/ovzI+Y/32fVs9IDzIfPt8ijyz/Co7yDvzu6v7g/vpO8x8NHwkPEZ8hTymfHR8CXwju/a7kPuWO4P75nvmu+V7xvwzPAl8djxxvOy9pT5Jfz6/jQCPQWkB2gJmgpDC3MLUgsZC9EKRwp0CUYIsgbtBEIDNgL1AVMC3QJgA+IDvQRSBmgIkQpJDH4NLA5WDlAOUA7/DQcNhwuuCdIHOQY6BS4F7QWqBsIG8AWCBO4C5gHiAZsCYANnA8cC2AGxAKr/2/45/sX9Lv0q/Jj6nfjn9tf1UfXc9AD02/L58Z7xmfGu8STyMPMm9JX01PRU9c/15vUJ9oL2CfdQ94r3I/gl+UX6U/tE/Bj9x/2E/sf/tgEJBC4G9wd5CYYK6wq3CnIKlgpdC/EM2w5LEPsQKxEpEf4QshATEMYO4QwgC/YJ7whrB4MFzQNLAmUASf6S/Ib7G/v0+gb7J/sE+6H6M/ru+Zr5CvmZ+J745fiA+OH2YfSk8U7vA+467k7vK/Cs8BHxYPFe8Ubx2fFL8yL1KPd4+eL7Gf4ZACICOAQmBp0HhAgVCckJxwrrCzoNgw46Dw8PLw4ADQMMnQv2CywNbg69DoAOXA5TDmUOvA7wDj4OTwynCTgH3QWXBdgFMQboBdYEswMZA4QCFwGz/u/7//kD+eL3SfZD9JfxxO4I7WPtle9Y8iH1PvgM+2v8Z/wI/Pz7vvvI+kf51/cK98v2F/cM+Fr5Fvow+l36svoc+/v7uf0PANYBQgJ9AQ8ATf6j/NX7/fup/L/9Nf8LAf0CWQTrBDwFwwVvBtwGxQbtBUwERQJqAGP/V/+//04A3wAQATQBLAINBBQGlAcGCIcHEAdFB8gHIwgoCNUHWgfBBrUFpwPYAHP+U/35/Bb83fnP9hv0TPJj8Xzx3vJD9YP3mvjx+Nn5nPv3/dkAtgOvBT8GBgakBc4EiANtAt4BhwH0AD4AAwDKAH4CoAQGB88JPwxdDYAN5A3NDrIPeRBYEeERWBGKDzQNRgsGCiMJXwhsBxMGUAQ3AhAASf4i/Xz8y/uc+qL45PVD80HxDvDj72LwjfAI8A/v6u3J7KLrkurC6SHpduix593mduYU53jo2en66hnsNu1a7p3v5vBc8kH0nvbu+PT6K/32/xMDEQYtCRIN3xH2FkkbAB4QH1ofqB8bIMEgMiGfIOkeshy3GjEZFhiWF6sXSxgEGREZjxgUGJcXpRYdFT0T8RDVDbgJRAUcARf9Xfme9vv0cfNI8QDvTO0w7EfrR+pr6d/oL+hf5wfng+d16FPpIuol62fsLO0Q7THtKO6w717x4PIe9KD0V/To8wP07/Ra9tj3IPml+X757/mq+/D9uv+vAEgBGwICA0EDAwMeA8EDlwQsBXcFkgXvBHMDKQL4AbcCXgOUA4EDbgN1Ay8DlgJEAu4CMAQKBV0F2AXkBmII1gngCpMLRww5DdMN4g0DDsQOwg98ED4RCBItEjURkg9eDrUNPQ3pDOYM+QxkDLoKhQjyBqMGwAZwBp8FDwSGAaT+pfzT+wD7ffmr9/z1LPTG8RXvDe3u6yzra+rS6abpCeoQ67zs0+7M8GnyD/QP9vz3M/m3+Sb6xfpH+3H7/frL+VH4Ivep9p72SPZr9WT0q/NX80LzJ/Sa9hn6S/3A/0UCLAXxBz0KdAzhDgYRDRIGEtUR4hFqEesPkA2RCksHHgTaAUEBfgKbBGgG0Qc5CRULlQ0oECoSehNXFP4UMxVgFHYSwg+EDLUIugSBAST/CP0U+6X58PjO+Pf4BPns+Ln4f/h8+L34SfnU+Q76B/oa+nf6Kfth/PH9PP8hAO4A3AHoArUD3QODA+0CHAIiATYAeP+C/jX94/sP+w37ovtG/MT8Ff1N/ZD93v3G/e78cvua+cD3MPa79Erz4fFQ8KDuMO2J7Hvsd+xs7Jbs8+zx7FHsuOsP7Ijtme+X8TrzCvV59176ff3jADkECwclCdEKlwwyDhEPGQ+EDnUNVwz1C/4MQg8EEp4U2RapGAMaFRsjHCMdix3iHFIbfRmYF4oVaxMMEVEOiAs2CaAHcgaXBV0FoAX6BacFKgS4Afb+Kvyx+fr3+fb99WH0q/KQ8Q3xkfAf8EzwJPH28QHyIvHc79Tub+6H7q7uZu6I7aDsNewk7BfsVuz87Njtv+4z7ynvWO9I8KvxwvLY8vHxu/AF8IvwqfKN9Qf4kfku+mf6cvql+m/7Cf1d/xwCzwSGB4MK7g2sEaoVexmjHCgfJCGjIlsjBCNUIk4inSLgIX0fRRx0Gb8XHBeKF+QYcxpEGycbnBrdGWMYNRZ+E/gPkgs4BjkA0/rK9sLzPPED7/rsPesg6p3pYuk76XrpQuow64Xr0+pz6Tronued5wro7OhG6vfrru1Q70Pxi/N99c/2vfda+L74NfkA+hX7NPwl/Q7+If/t/wAA0v9NAGwBiAJoA8kDjQMbA9wC+QKKA1EE4ATjBH8ELAQ0BG4EbAQFBJ0DhgNvA84CqAGBAGT/6/0u/Ar7IPsC/L/8Pv0Z/oT/HAFgAogDpwRPBUYF8gQBBR4GhwiQC2sOkhCwEdwRqRG5EWUSCRPYErQRBRBYDsEM/grzCC8HVwYNBpsFCAUSBe8FCQekB08HEAYWBIgB+v6B/Fv5kvXj8Q/vbe1b7OLq8eie5zrna+fU50TooOin6KjozegF6VTpzumu6t7rZO0m7xPx4vLO9A/32vhv+bf4TPfD9cT0iPSm9N30f/W89oL49vqF/mwD6QjWDR4S7RWJGU8dtyC6IjwjriJPIS0fmBwdGu4XpxVAEyERfQ9MDqANkQ0RDswObQ81ECIRJBLJElMSoBAeDn8LCwm3Bg0E6ABl/ZT5aPZI9NvyfPEj8EHvEu9i7+3vvPDU8czyR/MN84LyGPIV8pzybfM29PD0yvWL9iH34PcT+Vn6R/u/+yf8F/2L/rr/7f+7/+j/UAB1AB8Arv9y/zD/of5P/qn+DP/N/uH9g/wJ+/v5yfkD+kP6SPoD+pT5H/kS+Wr5tfmm+Vj5Tvlp+bn4sPYC9OHx2PCc8L/wNvHv8aPyXPMm9an4Mv2rAeAFPgqCDvURShRBFtQYdBsLHV8d3hxIHJ4bqBoJGi8ayxpGG1obdRtRHNodKB/FH7cf+B7+HH4ZSBVZEb0NFwoKBs8B1v0A+in2pvLr78jt1+ut6T/np+TR4ezeKtzV2XnYd9gW2XfZatmF2cjaZt294NPje+a76Lrqi+wL7vXuLO8m7xDvTO7O7BPrxumm6XLqfOvO7CbvpfJO91/9jwTGCw0Suxd8HZEjhyl8LnAxNjKcMScwqC0TKgsmuCEgHZQYOBTkD2gMJguADGgPbRIVFaoXOBqVHI8e6R82IOoeHhwHGM0SfAylBRv/qvm59YrydO+X7H3qYOld6Wzq9esc7UztL+2D7eXt9O3t7Sbu/O4t8CDx0PGt8uPzovUz+Bz7LP2+/Xz9ef0L/o/+kf4l/nn9mvzR+5n7l/u0+zf8Av21/eL9WP1L/AT7kPnT97H1s/Ma8j3wvu1x68jpnug06KPokum26sjrjexA7QTu0+7G77jwOvFv8fDx4/J69IH3MPwHAhkIvA3yEv4XFB3fIWElfScsKRsrziyULYYt6SzqK+wqTiosKmsqRCpaKQQoiiasJEUi9x8sHvYb4RfJEfUKWwWXAdr+PvwT+Vv1fPEL7lXrLenA5o3jjd+B2zLYedUu0+DRuNEE0qLS2dNW1R7Xbtn82wbedd+n4F7hb+EQ4ZHgaeCA4CTgOt983lre2t6f4MfkZOto8yz7nwHwBtEL8RCRFgodECT6KYEtqi4+LtEsJSvjKQkpJyibJpEjUx/PG1AadRowG9wbbBwzHSceKR9tICcidiNfI9Ih6B7eGiYWPRFYDF0HNQLu/JH3xPJv7+vtse3s7WjuBO/e7/Dwq/GB8Z7wyu+y7y7wTPCP7z3uCe2Y7LTtLPDW8uf0HfZu9lP20/Y7+Kz5GvpT+Xv3TfUu9Lf0XvYu+JX5efrQ+rL6Ofp++an4uvdn9nz0PfL97/DtOewv6zDrC+yo7dDvZPLJ9JH2n/cA+N/36/dw+Pv4Wvn2+e76xPtX/P/8l/60AVUG3Qt8EcsWkhuNH88ilSXlJ/4oXyhkJlMk2SKHIdgf7h1fHF8b1hp7GsUZqRi1F1MXmxcFGGMXihTlDzULXwfDA9b/svto96nyju0n6XLmSOXB5ObjaOKN4JPe4dwS3AXcAdyL2/zaQdu93O3eIeFk4xLmPulH7GLup+8T8Wvzw/b6+f37j/wc/F/7GvuC+yX89Pwg/ob/FwFjAuUC0wIoA84EoweeCvsMpA4UECES6RQIGMIafBwkHRsdohx1G2gZARcoFY4TvxF2DwQNtQuxCwIMYgwcDTwOnA8REWESSROJEwcT5RFWENIOYQ0bC7sHkQQ+AjoAIf5S/Lv6sPg89pXzmfCP7SDrdOlF6Hzn/eb75qvnG+lr63PuR/HJ81z23/gS+6v80P2t/t3+m/6C/m3+Ef61/Zj9zP3p/bH9Lf1O/F37efpH+XL35vSS8azts+lp5pXkB+Q15NLkFOX25JflZOdU6ofuqfPA+L78dv9bAXwCWwO0BJUGlAhNCpELaQw8DTwOOg+BEMsSKRYGGrwdVSEAJY8opiv7LdMvKjGUMagw6C4ULaYq7SZQIo4d9Rh4FLoPoQplBXEAXfvx9XzwAOvh5QTi1d/c3tDe+d643mLeg97y3mXfI+Bp4fLiaeRo5cvlQuZ+52rpqesc7rHwePOZ9nP6M///A80HYgrrCx0NSQ6iDsYN5QtgCXYGDANC/4/7WvjA9dXzZvIX8fLvk+9a8ATyqPOP9Pv0JPbJ+Mr7Qf03/RH9Ov2x/Sv+5v4fAK0BZgPNBEIF8QTZBKMF1Ac7C8cOxBGvFGEYTR2dIh0nlyqkLZMwCTOENI80ETOQMI8tJypRJsghgBzdFlkRGgw0B5kCGv7N+cH1FvK87rHrFekR57rl3+Ro5O/jIeO14o7jPeU45+josumu6WLpKOks6XzpEOqm6qjq7ulR6Zbpceor63nrC+uB6fvmQeQ64ubh1OMp59fpsupB6vPpY+vG7rLy7fVG+FH6dPzc/p4BJAV+CRcOxBGTE7ATCxPAEnUTCBXsFmQY5hhdGPkWOhWQE7gSVBOyFdIYJxt+HIkdcR9/IjkmzikmLFcsYyr2JmciAR2wF68SfQ1lCKYD7v6i+tX3svax9pf3qPiS+JL31vbN9q33Kfnw+UH5lfcq9b7yI/KP8131lfbE9mz1QvPD8fbw0e/N7brqpeYm4rzdcdkh1q7UdtQ31CrTBtGnzknNms2tzxfTu9be2ZbcgN9G45HoUO9/9sD9MwVhDMESdhjnHboimibQKcwrwCs0KiEotCVoIzEiIiKsIswjhiVjJ/kpOi5qM0s48TupPWM98TuJOUM2KjJ8LNkkyRt2EpkJVQG1+eryLO196KfkLeFL3p/c5dtV2+Xaydra2nTbXd1p4Lnj2Oaj6bbrEO6I8RH1fPc++ar65/s8/Tz+G/5e/U793/1u/vf+lv/h/7L/Yf8N/3T+Qf0n+3n4FfY19KHyPfHM75DuVO4k73HwL/Jj9DT2RvcE+N/3KPaO80Xxye/r7kPuf+3/7EPtPO5E7xjwNfEH8071HPiK+17/ngMOCD0MZRCUFGgYORxrIPskPirCL+gz7TU1Nu00QTLpLjgrGid1ImUdNBh1Ez8QeQ6dDDIKWwjkBzYIjAiZCE0I7gdwB9sFygK9/oD62PZ39LLyF/B37HvoA+Xa4qThjeAQ33vd2NsX2s7YRNje16TXV9j02afbFt3b3dPdi92E3YzdcN1M3S3dfN2H3iLhFOaz7PTyUPcm+n79SgNyC4YUjBwVInslMiezJ1onkSY4JlEmJyZpJc8jdCF+HvgbDRsoHMge0iFvJMolpSV8JUYmEie6JmQk7R9NGmEVvBEGDrQIBAJT+wX2BfIQ723tHu1X7Xzt2O2A7r7uku4T75Xwk/Jw9D311/Rv9FT1SvdX+Uf7u/xF/TD9a/1l/igAFAJdAx4DfQHI/+T+j/5I/hX+Pv5y/iv93/lq9SXxS+467dPs7usk6lfnZuQV4gXhueHQ41TmNejX6B/olOac5XzmF+nE6+PsqezP6wbrRet67SnxCPXp9yn6m/xF/6gCSweLDOURfBeFHC4gWyPvJwwuwDOUNwg6jjvbOz87CTpxOKQ2RjQ3MTotfCj3I1sgHh1AGrsXDRXBEdANWQmvBFsA8vu89rjwcuqX5M7fidxl2orYqdZ+1NHRw8/2zhfPms8v0MLQO9GN0fTRFdPR1TDafN925Ejo4+up8Gj2D/zYACEFaAn6DIgOmg2RC48KdgvfDI4NgA36DCMMmwvKC0gMugykDGcLuwn9COQI8AhmCd0JDwr+CbYIAgbpA6oDugQyBvsGZQZsBKYBw/6V/Lj7Qfwq/Zj9ov3W/Qv/ogGDBYoKVBAsFjEb/x4lIjQlgChiK5gs3CvyKcgnfyUaIzcgBBzcFncR2QvBBjUDVgCz/Bb48fL37Q7qRude5XHk7uMU46bhWuDz3ybg6eCf4tDkfObX5o3lJeOP4L/eBd5Z3YrbXNju0xnPPctEyV3JFMvPzU7RT9VC2Vjd2+KF6iH08P7NCZ0T1hsVI9kpGzFQOQlBXUYBSU1JO0emQ2c/ajqCNOstwiZ1HwkZfRTQES4QoQ4RDQEMMgzYDakQSRTyF2QazRo7GWYWBhOxDlsJyAM0/i74evEB6iTiztr21KTQBc3XyWzHz8UyxbvGPMpEzojSQtc/3Lvhsecn7rr05Pry/yEDUgRVBOwDswO1A/UCtgBz/TT6lfe09Zb0d/T19Fb1Y/Vb9fL1GPj0+78AJAUmCNEJSguZDa4QZRSjGLQcPh+tH9IeYx1+GysZ7BZXFTkUtRL5D2kMewkWCDgIpgndC8cNDQ8jEPUQmxHnErMUrRZHGMwYuhjuGHoZCRqpGskadhmSFsgSuQ4eCqwEhf7t92fxruv55gTjk9903OXZedhi2F7ZNdsm3pzhrOQq53Tpketk7d7ur++g7x7vbu557RzsQ+ou6LXmreWl5A/jdeCE3e3bXNz93d3gGuWA6ovwpvaj/KQClQn+EVsbGiQNK10v/jDPMOEvVS+ML8Qv4C7jLDMqqibQIkofkRz1GuoZiBinFmwUeBIpEdEPGA43DMYKZArDCioLxgpfCVQH9gS5AoYA9v3X+iH3//Jr7iPpbuNU3qDaNdgp15jXk9hB2Y3Z8dmD2oPbSd3f34ziNuTY5MzlCuiH67HvxfNk92T61vzS/skAiwMkB0YKngvjCsUItgbiBQAGHQb0BfoFOgbPBr4H1wj4CQQLLAzcDaIPVxAdED8QPBFQEgQTXBOwE5cUUhabGOEa8Ry6Hs8fcB9aHeIZpRVXEWsN/wm2BjEDJ//m+m/3L/UY9OTzuPNc84vyL/Gv70jusOwD6wvqIOqY6hfr6etp7fzu7e958DzxpfJ79Bj2hvf8+O357Pny+Dr3ofUy9dv1YvaQ9hj33fdO+D74qve49gj2y/Wf9VX1IPVA9en1p/ce+wUAIQVuCRYNAhGYFXkaDR9VImEjECJGH1wcBxojGIMW1hQ7E7YRBBAaDtkL1Qg6BYMBW/7c+4T5z/bh8/PxuvHR8m702/XL9s33wfmt/Dn/JAAk/738NvpS+Mv2BPXP8pXxBPLi8hTz3vIb82/09fbQ+Tb8Of5GAFYCGAQJBtQIKQxiD+4SOxe4G0gfRyEiInoiLiJkIOcceBgKFLwPlgvCB5gEAAJM/yr8mPjz9Nzwsur24cTXH86pxg7CNcBZwOjBlMRSx1XJJ8vAzZzSatrw43Pt3vS6+AX69PpH/ekBJQiBDocTrRZAGZQbuhzQHAodAx/NIxkqai+EMv8zFjVhNgo44TlAPNQ+v0CeQaNB8j9AO5EztCqtIvMbRhbSEFYKygIt+0f0e+7r6TXmMOOO4Ifd8NlV1mfTzdGD0RTSl9Oo1RfXYtjH2i/ex+Fl5a3oKevM7PvtC+/972Pw3+/S7qXtxezF61vq/OjA557mKuZx5ujmpucj6Trrmu2v8OD0N/m5/LD/qwI4BhcLLhFbF3sc2h/pIKwf/Bx4GgMZQhgtFzEVKxJkDt8KoAjPB8MI2gqYDOgNjg9JEbcScxQzFz4bjx94IscjnCRhJW8ldSQ4IwMizB9IHF0YGRQTD/8JeQXjACX8offR8zHxu++f7vHsj+qK6BDo+eh96gDsxOy37Krs8uxa7Y/twO3u7kvx0/N/9Qf2wvWh9db1mvWl9BfzB/Hv7jntQ+sy6Ofj2t7V2dPVp9MZ0xvTCtNM04zUgddW3IvivekU8Yb3tvxqAb8GpQxRElMXlhsaH0chwCHEIPce3hzYGtYY4hYAFe4S3RDpD5IQlxLdFTcavR7nIscmFCqRLMouYTFuM48zHTI/MNYtlirQJn8ibB2YGCYV5RIBEDgLDgW9/kH54fSL8Vzvtu0g62rnrOM14YrgceEx48zkh+V15RzlxuSM5Inkr+S+5AXl7+Wf5u/lIeQW4jPge97P3Pba0Nh01urTDtEYzhbMj8tuzKnOWdKC16ndyeSu7Fb0o/vwAjYKsRGAGcogryY6K/su7THRM280ozPYMecvtS3GKmcn6iN/IJ0dvRv1GgIbexssHCcdWh6DH8ggBSJyIyEliCa/JoAlCyOLHzMbWxZEES0MhQcWAyL+Zvh48hXtq+gC5WzhZt3K2brXP9e31+rYx9qQ3J7dbN4Z4DfjOecj61PuiPCd8dnx1/En8q/yG/PV8oPxUu+N7D/paOWh4Xbefdy628XbgdzU3Yff0OH85AHpuu3m8qr4wf54BMYJ7Q6cE6UXFhv/HT0gAyIAI40iUCFZIL4fJh+SHs0dehzSGqIZFBl7GLEXExeWFlcWGxdYGYAcbR+3IYgjyyTFJcUmxCepKPYoVycfIygdzRZSEIQJlAIT/Av2ofBG7LvoxeVx493h++C64M3g0ODp4GThEOLI4sjjE+Vp5s3nlOm464/tju7x7rDuEe0a6tLmRuSR4grh4d7K293Ystd32Gba9dz139rie+Ve6ILrS+6e8FDzqvZ5+nX+OQLZBZgJYA0EESsVCBrOHtAiZSVwJvMlpCThI9wjsiOkIn4gkh0rG0YaeBpOGhoZVxfVFf8UshSqFOIU5BWvF4oZMBukHCEekR9aIGUgbh9GHR8aCRYEEbsLcAaJAOj5VPPc7SnqNOjW5j3lvePI4griVuFm4eviI+W/5jbn6ubN5oPnv+hN6lLsie5M8Nrw/+9V7onsyOry6MTm8+Mo4MXbtNfB1DrTYdNo1a7YDNzA3tXgEONr5kXr9PDs9kL9hwPuCFMNSRFjFZ8ZxR0kIkAmByniKcMo/CWlIuofNx5mHUAdgx3uHX4eGR/+H34hWiPsJCUmVSfTJwwnNSXUInEgUx5jHI8a+xibFxMWIhTSEecOkAssCNwE0wDo++72ifLT7tnrhumb5wLmROWs5cXm6uet6Pbo+ugv6d3pqupO61HsAu4o8FrygvR+9sf3G/jD99z2l/U/9LfycfBS7crp+uVX4s3fet473c7bU9tJ3Prdqd+R4QvkDOfl6RzsQO6x8Cbzb/Uz+I77DP8EAhUECgWPBWUGpwfwCP4JtArwCkwLoAwSD1QSXBbzGgkgriUqK68v/zKtNQU4wjnIOmE7fDvoOvQ54TiNN+81BjR5MSsuxCqVJ+8jBx/rGAkSdApmArP6EvTL7jXqauVL4Mnbc9g21qTUq9NW0+TSIdKl0YLRRNEE0fHQJNHa0ffSRdSg1fDW8NcI2NHWt9TB0pHR5tCV0JTQSNFd0yPXINyT4Xfn3u3E9Nf7mQLXCJ8OMxSUGXcetyJkJpcpZCzsLuswyDF4Mb0wSDCrL0Au5CvPKFQlHCJwHxQdCxt3GWcYyhenF9sXNxhlGOUXahY2FNwReQ8PDdsKFwlaB3AFwwM/AqMAOP9Z/uD9VP00/EX6hvc39B7xlO6d7AnrrOlt6JDnVOeX51vozOmO6xjtSO4s793v1/CK8oH08vW39i33J/fg9sr2+fYM9+728Pbx9sD2Svby9RH2xPaw97b4Bvq3+2X92v6SAMYCTQWnB5gJ2QolC9sKGwraCJwHpwbiBewE2AO0AvsAt/4R/Bz55PWf8qPvG+1Y61zqGups6jbrouzE7jjxbvNH9WD3b/pd/pECsQZ5CpMNOBC9EjAVfhfbGUwcWB6gHzAg4R8CH0QevB1rHWwdcB0HHdEb1RmNFy0V7RJnEcIQSBA6D6MNnAvoCJoF5wFZ/mP7+/iC9pfzNvBz7MLogeWj4svfxdy62RbX79Rc02rSP9LA0uXTANbn2Hbcr+Cl5SDr0PBg9s/7RQEMB/sMhBImF+ca+R04IKYhMyK3IWgggB5BHPQZuxdOFRYSEA6cCVMF8gHQ/5z+Jf4x/iP+vf2I/b79P/77/nH/JP/m/d77SPmA9oTzl/Dz7U7rrOjP5jPmc+YB5x3nmuY15qTmFOjA6rLupPPo+Kb9hAEHBaAIUgxYENkUgRm9HRAhTiPCJPwlSSeYKPsphSvQLP0sbSt3KMckmyDnG9sW4RE3DcAIUQS6/wn7rPYn88Pwm++e70zwtfCB8NDv/e5e7vbt++1y7uvuwe6r7bbrWukZ507l7OO44szhIeFJ4GDf/t6A36fghuIQ5bXnD+pE7Mbup/Ep9SD51/yu/5wBFwOkBGIGggg2C0YOExEbExQU2xMeE5kShhKeEqAScBK7EfMPHg0NCoAHqAXTBAkFyAWyBoAHyQeGBzgHeQeSCJEKSg30D6IR5hHKEZwSxBSpFx8aQhsBG5YZ8RZFEzoPkQuCCAAGMASAAhwAqPys+AX1g/Kg8eTx+PHo8OXuTOyC6WDn3Obr58DppOsK7ZLtSu297IjsQO3/7uLw7fHN8dzwdu8l7rLtEe6z7n3vqvAF8ibzU/QA9uD3U/lq+p37Ff1K/v3+S//E//MAzwJYBWwIcwukDZ0OfQ6eDWkMgQs5C28LuAszC9QJUAg6B68GwgZJB8oH5Ae8B40HhQfEBy8IkAjeCC0JwAkOCwMNVA++EZETahTxFOEVIhdXGAgZ2BhuF8cUWRHNDdEKxAhJB8IFCwREAqgARv9h/jf+Rv7B/Yv87fpg+VH4zveo94b3Jfdp9k/1OfRz8+DyEPLE8GHvTu5u7ZvsLexd7M7swewQ7Drrt+ps6g7qgunx6I/oP+ju587nIOiz6MDoKuiZ54bnH+iF6WrrYu2873LyOvUN+DH7gv6TAZUEHQhcDPsQZRW4GKAanRtSHA4dDB6ZH30h9CJLI60iwCHPIBAg1B9mIHEhgyIyIwwjvCGfH5odshu2GQwY6xaSFRYTlA9nC/IG3QKS/7r8+/lI9270afE+7jPrZegs5r3kv+P54pXibuIX4o/hH+E34drh1uJB5BbmGOj66azrs+1U8BbzhfWV95b5lPs4/Xj+Zf8LAFkAJwCL/5D+W/1L/ML7avvT+vr5CPki+IX3gfct+A/5Yvkt+Q/5V/ni+bP69ftK/S/+uf70/gn/RP+s//7/+/+f/+P+7f1N/ZL94P4PAc4DNQbEB/YImAoTDWoQdhS7GMYcLiCuImokuSWBJqAmuSaKJ8kooim5KR8p8icoJr8jriBTHWgayxeEFEAQWAv5BUAAiPqn9R3yvu/K7TjrBOim5JXhOt/J3SLdntyj22raTtmO2ETYg9gY2ZXZ29lN2vXaxtta3f3f7uKW5fnnIOoU7E7uRfHZ9Mn4Hf28ATEGMAqtDWAQJhKSE1MVixesGTQbyRtEGwcarhh9F30WZBXgE8QR2Q6eC9QIJgYdA73/Ufw5+aP2y/St8+nyH/I08U/w0e8F8A7x4/JR9db3D/rG+1f9a/84AokF4wjeC4cOIRG0EwQWzxfiGIwZKxr8GhocdB1qHnoe0h3LHGgbrhndFxMWgRQYE2cR3g5ZC0wHKQOE/778Z/rZ98/0YfH07abqi+e/5HziseB139/eX96N3bjcUdy23PjdiN8Y4bHijOST5sHo+eoe7SHvEfEX84L1ivix+5T+CQHzAkkELwX2BcsGaAe8B98H5wf3BzsIgwh1CAAIQQeYBi0GaAbtBuoGQwaHBSoF8wS0BIQEqQQwBf0FyAZUB/UH0QidCRoKiQruCioLbAsLDMsMHg3hDFMM5QvxC6cMmw0zDrAOog9/ELwQrRCjEK4QhBAVEI4PGg+sDtwNLgzRCTQHegSnAd/+Z/zY+QD3MvR/8c7uQOzI6bfnROY+5U/kV+OE4hDi+OEJ4kDiuuLA41HlWOez6Rjsau7Y8GvzAPbX+An8bf+VAlUFowfECeoLsg0rD6gQJxJlE10UKBWsFb4VVhWFFJsT7RJwEuIRcREaEXcQIg9nDdQLbwosCSUI5QZHBZUDuwFa/578DPqj9yj18vLp8LPuVOzp6Zbnv+WK5M3jY+NA44XjHuQX5bTm6ehl60LuqPFm9S758/ygAAkEEgfyCd8M9g8JE4kVRBeRGKMZXBqyGuYaIxsoG6MaTRlyF5oVyhPpEfoP/w32C3gJswZcBJ0CIgGt/0f+KP1D/Gn7cPov+fP3/fbt9Zb0XvON8qTxa/BN74/uEO6u7YbtAu4N7ybw5vBp8WDy2fNq9Q736/jr+vD8wv5YAMYB9wLwA4cE0QQtBYUFrwXEBb0FewXMBLwDXQLAAEb/RP6U/fX8SvzL+8P7uPuR+3v7g/vh+5j8hf2r/u//GgESAgUDMwRsBXEGSAcnCPoIkQmzCWMJFAkMCRMJTQnTCWAKiApLCiUKOgphCocKigq1CoQLiwzBDCgMhws1C/kKxgp5CgMKVAluCGoHOgafBIMC8v9U/Tj7Zvl+94v1z/OA8mbxa/CR7+Tuo+6z7gHvd+888EnxTvIo8+vzoPR19WX2ePeU+HH5Jvrs+rf7bPzl/Nj8ffwx/Dn8rfxA/cH9K/6R/uL+Ff9B/3//7v+YAEIByAEgAgUCdwG5AE4AUwA+AL//DP9o/s39G/06/BP71PkB+dX4Rflo+v77UP39/Yb+VP96APoBrANpBc0GtwdWCO4IyAm6CogLbgymDQ4PWxBzEWkSGxMOEzgSBhHgD9wO6A0WDSwMvQrCCL0GAwWLA0oCJgERAOv+4f0M/V38w/vg+tD5Afmp+H34LfjS93L30vbM9bP06/PW82r0EPVc9WH1IvWY9Gf0FfVv9uH37fh8+dT5QPrH+lD7yfsI/CH8RPyJ/Or8ef0f/or+h/4b/qr9h/2T/cH95/2H/Yn8afuF+gT6wfmz+fD5iPo0+5j7wvsA/KD8oP33/qIAsQLzBAkHtQgKCvYKnQt2DNQNzg/YEUkT+xMvFO8TUxOtEkgSahLSEvMSkhJ1EVoPqwwmCnwIiwe7BrMFVgSZAloAvP1I+6v59vi++Jb4OvhE9631GvTb8uLx5PDv72Pvhu8W8KHw0/Cf8F7wu/AD8unzx/Uy94z4Bfp2+7L85/1//3wBcgMaBYcGygfMCIQJKgq1CvMK2QrbCmQL/gv1CyoL6gmXCKwHPwf0Bm0GigV1BGoDawJ+AYcAVf8X/gT9UPzs+5L7D/uT+nP6a/oT+qz5gflx+UX5wPgh+J73SPce9y73pfcc+D34Qvij+D75tfkA+jb6VPpi+pH65vpo+xr87vyj/T/+4/5S/4L/kf+r/8r/nP8B/yT+S/2u/DP8tfsy+7v6Hfpi+fv4/vj9+L34o/gg+fj5hfrC+kL7L/xt/fT+vgDJAu0E3warCI4KdAwaDmgPtxBREuUTGxX6FZwW+BYTFxkXOBd8F8sXmRezFmAVsROgES4P/QxqC0wKZQlBCMIGIwWAA7wBzP/2/VP82PqG+Vr4N/e79cfzxvFG8EHvVe5A7SvsMuso6lvpAen/6DHpj+kP6t7q7usB7QjuCu8Z8G3xT/OL9db39/ng+4j9w/7E/7sAuwHMAv0DOQV5BoEHAAgOCN8HqAdUB8UGLga6BTwFwARWBOoDowOJA3oDZAMxA/wC9QLgApgCXwKCAtACCgNdA+4DnwTjBGcEjwP+AtwCAwNNA9wDpgRTBbgF2wXhBcwFswXDBVUGaweCCDkJ3wmXCk4L9QtYDHUMZwxiDEUMuQsLC2EKbQk1CP8G+AUwBXkEPQNfAWT/tf39+wv6YfhR97z2Cvbl9E7zePGj7/Ltyuxu7HXsUOwU7A7sQ+xf7Cfs8us+7CPtH+7f7qHvnvDU8TbzyfSk9sX4vPpe/Mf9Nf/AAGsCTQRkBqYItApJDJgN4A5AEGERBhJfEpUSsRKoEm4S6xFFEXEQfw94DmoNXgxRC0QKRQl5CNQHCQcJBkMF4gScBMoDiwKpAToB4QB1ACIADADw/5P/Kv+r/gT+HP0P/Fr7JPv7+oH68fmr+bH5o/ll+QL5mfhd+Fz4bfiS+PD4ZvmW+Wv5M/kM+c/4nviz+Az5c/mj+ar5tPmx+WL5r/j+97336fc9+ID4pPjS+Bv5b/m3+eP5MfqS+g77rftP/MH88Pwq/eL9IP95AHoBEQKHAgcDiwMcBM8ExgURB24IlwmGCl0L9gtkDNwMjQ1JDsoOFg9MD4IPjA9RD8YOJw6WDfQMQgxfC0QKGwkZCEsHkQbqBSgF5AP2Acz/+/2e/KT77Ppu+v75WvlS+CX3Ufbp9aT1Q/X89N/0t/SK9H70cvQ79Cb0U/TF9Fj11vU29kz2N/ZF9oP2Bffr9/n45Pmb+h77U/uc+zf8F/1H/sr/UwGGAmgD/gNsBMMEHAVtBbwFIQZ1BosGgwaWBnwGEAaDBfQEbgQpBCcENAQDBIED2AIjAtUB8wEhAjsCQAImAgECDgJaArkCAgMqAx0D1wJUAtYBmQGIAWMBEgGtAFsAPQBDAFAAPwDi/zP/i/5H/mT+yP4+/3P/Y/9R/3f/6f+UAFYB/wE8AhECuwFtAV0BjAG1AaABKAFyALr/NP8R/x7/9v6T/lT+Tv5F/ib+BP74/fT92P27/ff9rf63/70AbQF7AQ0BrwCnAOUAKwFwAZcBiwFOAe4AhQAfAMr/qP/E//D/3v+V/zr/2f5d/vf9C/6p/pr/hwA9AaEBwgGhAWoBZQHCAWsC8wIlAw0DxgItAi0BHQBY/+r+m/5Y/i7+B/6n/Qj9dvwU/OP78Ps2/Ln8b/0P/o7+Ef+m/1kAAQGqAWECIgPCA+sDkwMGA5oCcwJxAlwCGAKSAcwA3v/f/uz9F/1v/O/7k/tS+yL76fqh+l76DPrH+bz59flp+u/6dvvb+xf8afwG/bn9L/5r/mr+NP4b/kD+kv7k/ib/f/8GAKoAFgE1AUYBYwF/AZEBygFKAv4C1AO2BHUF8gVPBrYGSgfgB14I1wg/CXQJUwnkCHUIEwimBzcHqgbsBQYFOQS0A1wD+QJbAo4B1QBMANn/bf/y/kb+af2O/N37cvs8+xT72/pd+oD5hPjN9433uPcf+G/4bvgt+AL4Cfgo+Gv4sfjX+BP5ivkt+uj6tvtq/Nv8L/2z/ZD+qf/GAJ8BDwIfAhsCTALmAvkDOQVdBhMHQAcMB8oGyAYUB6oHYAj1CCoJCQmxCDgIlAfHBuEFHgXGBNME3wR2BH8DMwL3AP3/bP83/yP/0v4P/gv9JfyX+1n7dfvO+yz8K/y0+wv7jPo++hD6Dfov+nP60/ok+1n7bPtG+/z6s/qh+tv6Uvv9+478wvyu/F78+PvJ++f7M/yU/Pj8b/3z/Xr+C/+O/yIAzQBPAYYBkwGbAYsBawGBAecBcgLUAuYC6gIfA48DBwRLBFUESgRXBHsErQTwBDwFhgXbBR0GMwYzBiMGFQYgBmUG1QYuBygH2wZiBsIF/AQnBG0D2gJ2AiECnQHKANv/Ev+c/nj+bf4+/vP9jv0i/an8LPzQ+6T7o/uj+7X70vu8+0/7ufpl+mv6yfpl+wT8cvyB/D787fue+4b76vuX/Cv9gP3G/Rz+ZP64/kX/BQDBAFcB4QFLAokCjQKZAvQCrgORBE8FxwXpBboFSwXiBJYERwTYA3MDFQN4AosBkADT/0//Dv/3/gH/B//M/mL+5/2P/ZD9zv31/Rf+K/7+/bT9hv1z/XD9of0H/mr+ov6r/oT+Mv61/Sz91fzY/CL9bP17/S79ovxI/FH8pvwg/Yf90f34/TL+m/7+/kb/Y/9e/2//t/8SAEUASwAoANn/fP9B/1T/pf/u//7/x/94/zP/8f7M/rP+i/5m/lv+T/5K/kT+Mf5A/oX+/P6I/ykArQD6AB0BNwFaAX8BhgFtAVMBUQGAAcMB9QH5AdgBuAGfAZkBqQHHAesBAAL0AcgBkQFqAVsBewG8AQgCYALbAnMDAQReBJwEuASfBGcEMgQSBOUDqANFA+QClAJVAgMCmQE4AdIANQBX/27+k/3y/LL8x/zq/OD8t/x4/EX8X/y5/AL9Hf0i/TP9V/2E/bT96f0c/j3+RP5J/mT+lf7R/iz/oP/n/wYAGQBCAHUApgDLAOUA8AAUAYkBNALKAisDVQOCA74D7AP2A9EDdwP8AowCRAIsAjkCVwJdAjECwQELAVEAyv98/3f/sf/r/wkA/v/8/x0APgBHAEEAOgAtADkAUQBKACkAGwAUAPX/zP+M/zH/n/74/VP9u/xE/AD88vvt+9L7cvvm+lz6Dvok+qf6avsr/Ln8Ff1K/Un9Nv05/Vb9dv2Y/a79vv2q/ZH9sP37/VT+jP6o/qf+g/5t/l/+Yv6M/uv+df8iANYAZAGyAecBHgJoAtQCUAPeA34E+wQ8BTgFAQXNBKMEfwRSBDUEMgRPBHEEcgREBN8DXAPcAnYCEgLAAY0BZQE9ATsBXwGAAY0BXgH6AIAA+v+H/zb/C/8L/wv/7f6c/iL+nP0H/Xz8+ft/+xz74frK+qv6l/qd+sn69/oH+x37Vvuo+wn8a/zD/CD9iv3v/U/+pf7x/lj/u/8VAF0AlQDvAFwBuwH4ARoCMQJSAlcCMQL7AdwB+AEzAooCBwN6A8YD8QMTBDsEVwRWBFkEfQSyBOUEDgVKBYgFwgXaBdwFyQWBBfoEUwS7AzgD3QKZAlwCGQLDAVUBzAAyALb/aP9b/4D/p/+1/7D/nf94/zb/0v5U/uH9qv3A/ef97f3T/Z/9S/32/Kv8VPz4+6z7b/s4+x37Mvtt+6L7xvvA+5n7dvts+4D7wvtD/NH8YP3s/Xf+8f5T/6L/3v8PAD4AeQDIABkBWwGJAZ0BoAGOAXcBWgE8ATABLAEiAQgBAQEWAUIBTAEmAfQA2QDqABABNwFeAXYBcwF9AYsBiQFYAQUBowA/APv/xP+I/2f/Xv9P/x//6v7J/rn+pv6U/nL+Rf4+/ln+eP7A/iL/cv+Q/6f/w//g/xEAVACSAMcA8wAPARUBCQEDAfkA1gCjAGAAHQDx/+z/+f/2/9//xv+T/0z//P6//o3+cP5X/kf+SP5V/nP+fP5//oP+hP5j/j/+J/4G/tP9mf1s/VD9Sf1O/UT9M/0f/Q79+fwF/T/9nv0S/pz+LP+4/0YAzQBNAcABNgK0AjMDoAP5A0gElwTnBD0FcwV/BWMFNQX6BKsESwT4A7EDjwN+A08D7wJrAucBcAETAcsAogCEAE4AHQAFAPP/z/+a/0H/4v6O/mH+R/4u/g3+6/3p/fb9/f3f/av9i/13/WH9Rf1E/Vz9lv33/XP+1/4T/zz/VP9d/3X/uv8NAHMA1wAzAVsBawF9AZEBqQG2AacBgwFYATIBGgEeASYBCwHAAFQA8P+R/0P/Df/v/uj+8/4Q/0//ov/Z//P/CQA0AIgAywD7ADsBcwGnAeEBLQJjAnACWQIlAuQBvAGjAZsBeQExAe0AsgCUAIAAcABEAB8AHwA6AFYAXwBUAF0AcgCLAJUAjgCUAJgAlgCIAHkAhgCdAJsAZwAIALX/f/9R/yT/+P7X/rj+iv5W/jP+Hv4M/u79vP2Z/ab94/0q/nT+qv7V/vb+Jv9Y/5T/6v8eABsA/f/a/9z/7v/g/7D/Zv8j/+f+tP6B/lP+Uf6F/u3+aP/h/x0AFgD0//v/IQBUAKgABQFhAb0BEwJcArECCwM/AzED5QJ7AhACuQF/AV8BPgEUAdwAnQBWAP3/pv9h/zP/Cf/w/uL+3P7l/vb+7v7O/qP+dP5e/lL+Xf5o/n/+m/62/sT+w/60/pH+VP4W/sD9ZP0k/Rb9H/0u/Uj9eP22/d398v0I/hv+PP5+/uP+VP/U/0gAqgD+AFMBmwHAAcUBwAG4AZgBewFcAUoBNQESAdoAjAAzANn/g/88/x//If8v/0n/d/+j/7b/vf/S/+7/BAAaABYA9v/m//b/CAAVABYACQDr/87/uv+f/4T/Y/9F/0D/Uv95/6f/vP+3/7T/wf/9/0wApQD+AEgBkwHMAfYBAgIGAhwCRwKAAq4CsgKOAkUC4wGDASEBygCHAFQAOgATANH/hP9K/yj/IP8U/wT///4M/wz/6v7R/sf+1P76/hr/RP9w/5X/rf+3/8T/0f/o/wQAMgByAK8A5gD6ABEBIAFEAYgBzQEDAi8CYAKIAp0CsQLYAvkCEQMiAy4DQQNdA2YDSwMKA7oCYQIKAq4BRgG+ACcAiv8D/3r+A/60/Zf9lP2S/Xr9Rv0a/fX85fzt/Pj8Bv0w/Yb90v0Q/jH+NP4w/jH+If7+/db9yv3N/ej9Fv5E/mf+m/7R/uv+5f7S/tD++v5b/87/QQCfAPAAPgGJAcsB9wEcAksCaAJnAlMCOQIkAv0B0AGvAZwBegE+AeAAcQAKAMH/kf9r/0X/KP///sD+ev47/hv+Jf4+/mz+rf4G/0z/bP9x/3X/fP9+/4L/hP+Q/5//of+h/6b/qP+o/5T/bP85/wf/yf54/iz+GP44/nv+0f4c/1L/dv+E/5r/wP/5/zwAhwDJAPYAAwEJARcBFgHyAMAAmQCNAIUAZAA5AAMAz/+g/4f/e/96/3P/Wv88/zb/UP+A/7b/DgBrAKsA2QDzAAEBDQEbASkBQAFUAVQBQgErAQMB2ACzAJYAggBNAPr/pP9h/0j/SP9N/0b/NP8s/zL/SP9h/3H/Zv9a/13/cP+i/+D/GQA8AEsAZAB1AIEAeQBgAFEAQAA2ACMA/f/K/6z/nP+b/5v/l/91/1L/L/8k/yX/Of9U/2z/i/+s/9H/5f/w/wMAJABWAJAA0gAHATMBUAFfAXEBfAGIAZMBkAFdARgB6QDUANkA4QDdAMYAmwB2AFcAPwAiAAYA/P/8/wMAHQA9AFsAdwCGAIcAegBwAG0AZwBbADgABADV/67/mv+B/1j/F//C/nv+Sf4x/kb+bv6J/qP+vP7i/gD/Hv8t/zf/V/+P/73/4////xcAKgBCAEsASwBLAE4ATgBcAHEAewB7AHEAcABpAGMAWgBHAC0AFQD//+b/1v/h//v/GwA+AEQAOwAtADAARgBhAHoAiQB/AHoAfgCOAJEAhgBmAD8AIgAAANj/o/97/3L/fv+g/8P/yP+t/43/df9l/1r/UP9I/07/bP+Z/8H/2//t/+n/6P/w//7/CQAWACQAKQAmAC4AOgA6ACoALQAvACwALgBBAGEAeACEAJsAwgDaANAAwwCyAKwAqwCeAIsAiwCBAHsAdQB0AHYAcgBtAFoAPgAdAAwAAADw/+v/2f/C/7P/lP9p/z//FP/u/tj+1/7q/hH/O/9i/43/qP+w/6//r/+3/9n/+P8UAC0ASwBwAIAAewB0AGMAUwBIAD8ANAAfAA4AAQD6//v/9v/u/+n/0v+z/4v/a/9W/1X/Z/95/4T/c/9F/w7/yP6b/nX+af5U/kT+Kf4I/t79rP2F/WD9Wf1s/Yv9qf3N/fb9Jf5k/q3+9P4q/0H/TP9b/47/0v8oAIwAAAFqAa0B4AEIAioCRAJcAnsClwKvArICsgLMAuwCDgMhAyIDCAPlAtgC1ALIAqcCegJQAiYC+QHFAXoBJAHLAHcAJADZ/5L/af8//w3/yv51/gz+nP1H/SL9Kf0+/VP9Yf1m/X/9oP3O/f79Jf4y/kD+Z/6V/s7+BP9C/4L/r//N/+b/9P/0/+z/3v/j//n/IABIAGoAggCPAJAAlQCYAKAAoQCfAJwAoACoAKwArgCkAHYASAAaAPj/3f/M/8L/wv/J/9P/0//T/+X/5v/b/97/6f8MAD8AfgDLAAABJgFRAW0BggGKAXwBagFqAXUBcgF0AXgBgQGPAY4BfwFRARYB3gCqAHMARgAuABMA9//c/8L/ov93/0r/FP/g/r/+uf66/qj+if5l/jH+8/2+/Zb9cf1a/UH9Nv06/UP9V/1o/XD9av1g/V39a/2M/br9AP5a/r3+Hv+C/+P/MgB0AJwAqACkAKwAugDJAN0A8gAFARMBBAHtAM8AwQC5ALQAtwC/ANwAAQEiAUYBWQFPAUABNwE+ATYBMgE8AU4BTwE1ASEBGgEPAfgA2wC/AKsAogCfAKEAsAC5ALAAmwCEAHUAbABkAE8ANgAqACYAJwAoACcAGgD3/8b/qf+S/4X/df9y/3f/gP+Q/47/d/9W/zf/C//n/sr+w/7T/u7+Ff81/0r/Wv90/4r/kf+S/5v/pf+3/9b/CQBLAIcAlwCQAIQAcABaAEMAOwBIAF8AcgB5AGgAQAAnACIAJAAjACEAMAAuAC8AMgBBAFAAYwBpAGoAXgBMADIAHgASAAkADAANABMAGgAiACgALAAmAAsA8f/q//v/HQA7AE0AWQBIAC4AGAAWABYALABIAGwAgACMAJEAiwB2AFsAVgBbAHwAmgC4AMUAwgC3ALYAygDUANIAxwDFAMwAzgDIAMwA2ADnAPIA6gDYALEAhABdAE8AUQBZAGQAaQBuAGIATQA4ACQABADc/77/o/+Y/4H/WP8g/+T+s/6H/m3+Zv5s/nH+f/6d/sb+9f4h/1L/hf+7/97/8P/9/wcABAD9//j//P/7/+7/2/+6/6L/iv9p/0b/P/9R/2j/if+z/9n/+P8GABIAHwAuAE8AnADyAD4BcAGHAY8BlAGgAaMBnQGQAXcBZwFVAUEBJwHzALQAawAwAAUA4f+//5//g/99/4H/l/+s/8j/3//k/9X/xP/B/8X/1P/l//T///8GAPH/wf+C/zf///7T/sX+yP7O/sz+xf6o/ob+Xf48/jz+S/5n/oz+tP7j/hb/X/+m/+P/DQAlADUAPwBKAEgAQwBCADcAHwADAOX/y/+x/5X/ev9i/0P/L/8v/0j/bf+L/6T/vf/R/+b//f8TADYAVQB4AKAAxwDaAOgA6ADQAMkA0wDtAAYBEAESAQoBAQH5AO8A2AC9AKEAnAClALkAzQDhANsAzQC1AKoApACdAI8AegBNABYA6f/X/8b/vv+t/5P/af81/wn/5f7D/qn+mP6Q/pD+hf5X/hj+6v3h/Q/+Xv7B/hz/ZP+h/9n/AgAoADUANwAxAE0AfACzAOYACwEZARQBCAECAfMA1gDBAKYAggBCAOX/lv9y/5X/1v8bADIAFwDd/7X/qv+9/9j/AAAwAGYAigCTAIUAXgA5ACkALQAuABEA4/+d/1//G//h/r3+rP6h/qr+vP7G/sr+2/7v/hX/Sf+M/9v/LwBwAJ8AygD5ACcBXwGyAQ4CWQKfAroCwwLEArICnQKPAoQCeAJYAjECAgLHAYoBTAEWAeoAwQCjAIQAXQA1ACEABwDn/8j/sP+O/3P/Xf89/wf/xP55/jH+9P24/Xv9SP0H/cf8lPx1/Hn8ePyA/JD8yPwH/UX9cf2i/dL9+v0+/o/++f5i/8f/FQA9AFEAWgBiAHoAngCxAKIAhwBoAE4ALwASAAYAAgAXADUAUAB6AJQAwQDzADQBfAG0AdoBAQIsAkwCagJ+ApQCsQLMAtcCzAKXAjICuwFNAfkAxgCXAFoAEgC9/3D/Kf/0/uP+4/7o/uT+6P7v/gL/Hv9K/3L/k/+o/8X/zv/Q/8H/qP+M/3v/ef+F/4r/eP9T/x//5P6z/pX+j/6S/qP+sP7H/u3+Ef89/2r/o//q/zkAkwDbABkBQwFVAWYBXAFJASwBEAHsAMsApgCBAGUAQAAWAO7/1v+3/4v/aP9W/1n/bP+P/63/uf/D/9r/FwBcAJYA0QD4ACkBRQFhAXEBagFUAUYBOQE6ATABGAHqAMQAsAC0ALYAoQB/AFEAIQD///T/9/8KACIATwCDAK0AvQC8AKsApACWAIUAdgBpAF4AQQAeAOP/of9s/0L/JP8L//7+8P7d/tn+3P7s/v/+EP8g/zH/TP9z/5v/xP/5/yoAUgBqAHgAdABtAFUANQAgABUAEQAKAAEA4P+//6b/nv+X/5D/cv9c/0f/S/9W/17/bf97/5P/pP+8/9r//f8lAFgAgQCaAJwAkQCTAJAAgwBiAEEAHwAJAPT/6P/a/9//6f/5/w0AGwAiACsAMwBHAG4ApQDrABwBNwFDAUABRgE+ATEBIAETAfQAzwCtAJsAiABlAC8A5/+y/4j/dv9z/3r/ff+N/6f/tv+5/6D/hP90/3v/nP/V/wkAMQBJAEAAJgD9/93/uP+W/3j/WP88/xL/2P6d/mb+J/7g/aD9df1o/YP9tP3v/Sn+a/6+/hb/c/++//P/GwA7AGsApADjABUBOQFOAV4BbQF0AXIBaAFWAVABTQFBATUBGwEAAeQAxgCjAIQAbwBgAGcAhwClAMQA5AD1APoA/ADkALkAiwBVACsAAQDc/7f/gv9H/wv/2/6t/nn+Ov4E/ur98P0P/jP+Uf5z/pr+zP4L/0n/i//Y/yIAcADGABsBYAGSAb4B2AHcAdEBswGTAXcBVgE4AQ8B6AC2AHUAKADg/5j/cv9Y/1P/Vv9a/2H/VP8//yT/C//x/uj++f4X/z3/Wf94/4r/kf+S/4//hf9w/1v/R/9A/zf/NP80/z//Yv+G/6r/wf/W//P/CgA5AGwAnADNAPoAIAE3AUYBVAFkAXsBjwGXAYwBigGIAW0BPwH9ALgAaAAUANn/sf+W/3//ev+F/5z/rv/C/8r/zP/U//L/CAAlAFEAgwC1ANsA6wDpAOEAvwCcAIEAcwBsAGMAVQA+ACQABQDd/7b/kP9y/1r/Vf9P/1//bf99/5D/of+n/7b/yf/Z/+D/5//4/xEALABEAEYAOgAZAO//sv+A/1D/I/8D/+n+0/7L/tX+9P7//gz/EP8R/yf/Vf+Z/+j/PAB9ALUA6wAWAToBSgFMAUQBSwFVAVcBTAEmAekAnQBPAAoAw/+F/13/SP9Q/2T/cP9i/1L/P/9G/0f/U/9N/0f/X/+D/7z/8f8dAD8ARQBDADYAIwAHAOn/yP+v/6T/qf+r/6P/kf9o/zH/+/7Q/rv+q/6l/qz+u/7b/gf/Q/9+/6n/x//a//X/HABGAHQAmQCqAK8ApACeAIwAbgBLACUACwD2/9X/u/+v/63/pP+Q/3f/av9v/3//nf++/9j/6f/y//7/DQARACgARgBoAIYAngCjAJUAgABhAEMAIADx/8P/lv9//3P/af9m/2z/d/+E/5X/nv+Z/5z/rf/c/yAAawCiANEABwE/AV4BawFjAVIBSwFTAWUBcwFxAWcBRgEbAeQArAB8AFcANwAjABoAGAAgACsAPgBYAHUAfQB8AHsAfACIAJEAngCzAMQAygDCALEAlgBqADAAAQDW/6b/cv8+/xX///7g/sP+k/5i/jL+Df70/fP9Bf4n/lr+iv7H/vz+Jv83/0z/aP+P/7P/1f/8/w8AIQAoAB8ACgABAP7/DAAYACEANwBZAHMAhwCUAJkAmwCcAKkAwwDyACQBVAF2AZgBtQHGAc8B0AHMAaYBhAFQASYBBQHvANUApwBtACoA8f+7/4z/b/9S/zf/Hv8I//v+7f7d/sz+wP67/sD+wv7U/u/+Dv8o/0P/Tv9S/1P/Vv9Z/1r/T/9F/0D/Rf9T/2X/cP93/3b/bf9u/23/d/+L/6X/uP++/7z/tP+s/6z/u//K/9//5v/f/9n/2v/i/+f/9f8HABMAEgALAAoABgAJACIAQwBlAIMAlgChAKcAtADLAOgACQEjATEBRQFcAXIBewGEAZ4BvgHeAe4B8gHbAbYBfQE6AfIArQCEAGMARAAaAOH/pP9c/xf/4v6z/pL+dv5g/kv+Pf4t/h7++/3U/bL9pP2s/bv90P3p/Qv+J/5D/lf+Zv5r/mr+Yv5f/nn+o/7l/jv/gf/A/+b/9f8BABgASgCRAOEALAF0Aa4B4AH/AQwC/wHxAeUB0wHBAbMBpwGWAYIBWwEiAd0AmwBiADAAEAD9//L/6//o/9j/xf+n/5L/i/+N/6P/tf/O/+H/8//y/+v/2v/E/6r/mP+N/4v/gv9z/2z/bv97/4P/kv+i/6n/pf+d/57/pf+l/7z/1v8CADQAVwBzAIMAjgCRAIMAcwBWADwAGQDz/8v/pP93/0P/GP/x/sv+pP5v/kj+M/4x/jr+SP5R/l7+eP6j/tn+EP9L/4H/uP/+/0sAlwDaABMBPQFFATIBHAEVARgBKQE6AUABOwEjARUBBAH9AOwA1QC8ALcAwADbAAMBJwFAAU4BVgFgAXEBdwFxAWoBYQFhAV8BYAFBAQwBzACNAFcAIgDw/7v/ef83//3+2/69/rn+uf7I/tz+8f4A/xH/Hf80/1r/jP+//+z/EgAzADkAMAAhABcABgD4//D/5v/e/8v/uv+a/3f/Vf8t/w//+f73/vT+9v4F/xX/KP9M/3b/o//D/97/6f/0/wcAJAA8AFwAeACFAIEAbwBVAEEAKgAoACYAIwAbABUAEQAPAA4AEwAeADIASQBfAHgAkQCvANIA6gD6AAoBGAEnAScBIwEWAQ4B8QDTALAAiABeACYA+v/R/5D/T/8J/8f+nv6I/oT+jP6b/qH+qP6t/rf+zP7Z/u/+Df8u/1H/d/+a/7z/yP+8/6b/hv9x/1b/UP9T/1D/P/8a/+v+wf6n/p3+ov64/sP+zf7d/un+CP8t/1z/iP+1/+L/EABHAHoAqADGANsA1gDKALoAvADAAMUAxQDEAL0AuQCqAI0AdwBaAEAANQBHAHEAmgC6AMkAzQC+ALQAuADTAPwAIAFAAVoBZQFcAUYBGAHmALUAlQByAEgADADG/3H/K//m/p/+XP4V/uH9vv2u/Z/9lv2K/Yv9of3Q/Q7+Pv5d/mn+fv6W/rv+2v79/iX/T/9t/4b/of+8/83/0v/W/+D/9P8MACcASABnAIwApgC7ANAA5QD/ACQBPgFeAXsBnAHEAeUBAgIOAg0C/wHjAcoBrQGWAYMBawFLARsB3ACbAG4AOQAJAOT/y/+6/6z/tv+6/7n/xf/K/9H/2v/l//n/CQAaAC0AOABRAGUAeAB6AHYAbQBfAFcATAA6ACEADAAHAAwAIAA9AEwATAA0ACAAFgAOAA4AEwAcACYALAAoACIAHgAOAPj/6P/h/+L/3f/C/57/fP9q/1P/LP8R//3+7v7o/uL+3P7O/rn+of6U/pn+rP7L/un++f4F/wj/Bv8d/z//bP+v//D/JQBEAFIAVgBSAEsASgBAAEYASwBYAGgAdwB0AGcATgA/ADcAOAA5AD8ATwBVAFsAZQBzAHcAiACWAJ0ApACtAK0ApQCZAJQAkgCKAH8AYwBGADAAHgAMAPv/4v/H/6r/kf+K/3v/a/9d/1n/U/9S/03/Sv9H/0j/Vv94/5f/vv/g//H/8//m/9b/zv/K/8T/yv/d/+v/8//t/+f/3f/Y/9T/yP/J/8//8P8TADsAUQBbAF8AYwCEAK4AzQDVANgA1QDDAL0AvACzAKYAlwCKAH4AbABHABQA4/+t/4X/dP9u/3X/hP+N/5b/oP+Y/4f/d/9+/5b/xv/w/xUAMgBEAEcAOwArABgAEgAWACIAIwAiABEA8v/T/7//s/+5/8r/2P/m/93/0P/E/73/wf/P/+D/8f/+/wIA/P/2//X/6f/f/8b/qf+i/67/wf/F/7T/m/98/2P/VP9W/2D/cf96/3v/iv+Z/67/wP/a//f/GAA5AFgAcACDAJ4AwADSANkA1wDPANIAzQDQAMgAtQCXAHIAUwA3ACQAIAAeABsAGwAZABoADgAJAAkAEgAfADQASwBSAFEARQA2ACoAEADu/7v/jP9h/0//Sf9M/0r/Qf82/yn/JP8Z/xf/IP8p/zX/T/9y/53/vv/U/+//EgAxAEEATQBSAFYAUgBOAEYAOQAqACoAIwAiABQA/P/l/8v/u/+u/7L/vf/W//n/JQBFAFkAWABcAFcATwBRAGUAmAC/ANoA4wDpANoAvwCjAIYAfAB/AIEAgQCCAIEAggB5AGQASwA7AC8AJAAnACEAFgD7/+X/1//Y/9j/zv+9/6H/gf9c/zr/F//w/tD+xP7E/s/+0v7E/rb+oP6L/m7+Y/5q/oz+s/7d/gn/Mf9O/1b/YP9o/3b/hv+b/7D/y//s/wcALQBHAFoAbgCCAJUAoACfAJcAlwCMAIEAewB7AHcAbgBeAEgAJwARAP//8f/r/+7/AgAcAC8ARABeAGUAZgBiAGcAYwBgAGIAbwCLAJkAmwCXAIUAagBBACAADAD2/+j/4v/b/9H/w/++/8X/yf/R/9j/5v/t//3/HAA6AEIARgBRAF4AcwB4AHwAbwBaAEoAOgAsACYAHQARAAMA8//p/9X/yv+//7f/uf+8/8H/yP/W/+H/7//8/wQABAAWACYAPgBFAEAANQAsACsALgA8AFAAYwB4AJAAlwCYAIgAdwBcAD0AMAAiABoADQAIAPz/9f/r/+f/3v/Z/+D/4f/i/+j/8f8GABsAMQA4AC8AKQAzADsATQBfAG0AeQCCAHwAcABlAF4ATQAxABUA+v/u/97/0P+7/5//e/9a/0r/QP9D/0z/Tv9N/1L/V/9Z/1X/VP9U/13/a/98/4r/jf+L/4T/e/9p/1H/PP8u/yf/Hf8Y/wf/+v7u/uX+5v7z/gP/DP8h/z//Wv93/4v/sP/a/wgAOwBcAG4AbABhAFgAVQBcAGQAbgB2AIQAjACPAIoAdwBkAE0APgAyACkAIgApAC8AOwBKAFMAXgByAHwAhACMAJUAlQCEAHQAXgBUAEgARgA0ABsA/v/K/57/bv9X/0f/QP8u/yP/Ev8E//b+7v7l/tv+3/7q/gb/JP9G/3X/sP/h/wgAMQBRAGwAegCLAJsApQClAKkAqACoALAAtQC3AK4AmwCCAGQARgAyACMAFgATABMAEAARAA0AFAAdACIAJQArADcARQBZAGwAcQBwAHkAhQCKAJAAlwCdAJwAlwCMAIUAdQBmAFcASABBAEUARgBBACsADgDx/9n/0v/R/9n/7P/+/xIAHAAwAEYAVABUAEoANwASAOn/0P/E/7f/qf+f/5v/iP9t/0z/Jf8F/+r+zv60/qv+v/7f/gX/Lf9P/2f/a/9w/3T/f/+P/5f/l/+v/87/7v8TACwANwA1ADIAOgBDAEYARQBEAEsAVQBpAHoAlACZAJcAngCjAKcAqACgAJAAiQCIAIIAhQCGAIoAkACPAI8AkACBAHEAXwBVAFoAZQBsAGcAZwBmAGcAWwBNAEMAOQAoAB8AGwAbAB0AJwA2AEMAVABiAGMAZQBYAEoANwAnAA4A+f/l/9X/wf+z/6j/kf92/1//Qv8l/xX/Ev8L/wH/CP8a/y3/Pv9H/1H/V/9c/2P/b/+I/5//rf+x/67/rf+q/6r/nP+h/6X/qv+p/6n/sv+5/8f/1//o//D/CgAmAEUAagCRAK4AuwDBAMoAywDLANsA8wAOAScBMgE1ASUBDwH+AO4A4wDUAMMAsACjAJ0AmwCeAKgAsAC+ALQAqACTAH4AcwBcAEUAOQA2ADoAPgA0ABAA2f+U/1L/If/+/uX+5f7r/ur+5f7e/sn+qv6J/nL+Zf5h/mj+e/6T/q3+wv7T/uP+Bv8g/zT/T/94/7H/4/8TAD4AVQBgAHMAhgCJAIAAfAByAHwAjgCrAMkA5AD1APgA9QD1AAABEwEqAUQBXAF1AYQBigGJAXsBYgFGASgBCgHzANQAsQCDAFMAKAD+/9L/pf93/0//LP8Z/xn/IP8i/yL/Hf8e/yX/Lf88/0r/Vf9f/2X/bv+H/63/zv/k/+7/7P/k/9v/2f/X/9P/vP+p/6H/pv+v/7H/xf/b/+b/9P8GAA0ABgD5//v/AgAHAAwAEAAYACIAJQAQAPL/1f+1/6L/if98/3f/dv93/3L/dv+B/4b/m/+3/9H/5v/5/xQAJQAoACUAJQAoADcAWAB4AJ8AvgDPAN0A5ADiANIAxwDJANAA2wDhAOcA5QDeAOQA5ADcAMYArwCUAIIAdQBtAGgAYABJACEAAQDk/8r/qv+X/4H/a/9V/zr/Jf8b/xX/Ff8S/w7/C/8M/xb/I/87/1f/af92/3f/d/95/4P/iP+K/4r/lf+m/7b/zv/n//f//v8FAAoACgABAPn/9f/5/wgAGAArAEEAVgBgAFcATwBLAD4ALwAaABgAIwAwADsAPQA0ACMAGQATABAAAwD7//X/9v/1//T//P8HABsAOQBPAGsAigCUAJ8AnwCpALMAswCvALQAvADGANwA4ADhANQAxQC4AKgAoQCYAJQAjACLAHwAbgBjAEUAJwAJAPT/6f/l/+n/6P/j/9P/vv+r/4//df9f/1D/R/87/yv/GP8G//H+4f7Z/t3+6v72/gz/IP8+/1X/Y/9s/3D/dv+H/5//xv/w/xYALgA6AEIATABZAGgAcQBqAGAAYABdAGcAdACBAIwAiwCHAIsAmAChAJ4AlQCPAIoAdABrAF4AUgBHAEgATQBVAFoAVwBZAFoAWgBQADwAGAD//+T/y/++/7j/uf+3/7r/yv/q/wUAGAAdACEAGwAMAAAA9v/2//j/AAD2/97/tf+Y/3//av9V/0n/UP9Q/1b/S/84/yX/Ef/+/vj+9v76/g7/IP85/1P/a/98/4j/lf+h/6f/tv/N/+n/+/8LAC4ASwBZAGUAbgByAIUAmQCrAKgAnACRAIoAmQCtAMgA4AD4AAgBEQEXASMBKgEpASkBIAEhASEBIQEgARgBBAHrAM8AtwCkAJkAjQB/AHIAYQBXAEoAPwAwACQAHwAeACcAIAALAPn/7v/i/+H/2f/M/7z/r/+X/3z/Zf9K/yz/Ff8E//n+8v7x/vL+8/71/u7+6v7m/t/+2v7b/tn+3/7z/g//MP9E/1f/a/99/5L/n/+s/7f/vv/D/87/2P/h/+3/7f/y//b/+v8DAAQAAgD9//L/8v/4/woAIABEAGAAdAB7AIgAnQCpALQAuADEAMcAvgC5ALUAsQCzAKoAnQCPAHwAXgA5ABAA7f/U/7r/of+D/3v/hf+Y/7H/xf/S/9b/1P/I/7n/qP+m/6b/tv/K/+L/+/8VACsAMQAxABYA///q/+H/3f/b/83/tP+g/5b/oP+s/7f/vv/I/9T/5v/x//P/9P/w//f/CgAlAE4AegCVALMAxwDQAM0AwgCyAKIAjABvAFwATQBNAFgAZgBvAHcAcABuAGUAWgBPAD0ANwA1ADwASQBYAGIAaABzAG8AZwBUADwAIAD6/9X/tf+W/4f/h/+L/5D/iv90/2b/W/9M/z3/Lv8j/xT/Ef8V/yj/R/9k/4n/pf+3/8H/zf/V/+P/6//0/wkAGgA2AE0AYABxAHgAcABcAE4ASQBJAEMAQgBEAEsAVgBkAHYAhgCRAJcAkwCMAH0AZQBYAEoANwAoACYAJAAhAB0AIAAgACAAFwAOAPr/3f/I/6z/l/+E/4P/iv+Y/7D/0P/1/xEAHQAbAAwA+P/j/8z/wf+7/7f/vv/M/97/6v/l/9r/z//I/7//v//B/8z/5v/1/////P/2//T/7v/p/9n/0P/A/7D/rv+z/8D/wf/G/9T/2//o//n/BwAWAB0AIgAZABQAGwAfACsAPwBPAEoAQQBDAFQAZQBwAHYAfQB4AHgAfQB+AHsAeAB6AIAAiQCSAJYAnwCqAKUAnACJAHkAWAA5AB4A8//S/6//lf9+/27/a/9u/2f/Xv9M/zX/LP8m/xz/Ev8O/xn/M/9B/1b/bv+C/4X/jf+c/53/qP+w/8b/1P/g//T/CAAYACkAMwA3ADkAOQA5ADkANwAxACwALgA5AEYAWQBpAHQAdQBvAGQAUwBCACoAEwD9/+z/4//h/+j/7//6/wQADgALAAIA+P/u/+r/+f8WAC0ATABoAIUAnwC3AM0A4gD7AAkBFAEeAS0BQwFSAVYBXAFhAVoBVAFJAScBBwHaAKsAdABFACIABgDz/+P/6P/j/9n/1v/K/7X/lv94/0v/Jv8O/wH//v7//vv+8v7m/t7+2P7W/tn+1f7i/u/++v4B/xX/K/9E/2T/hf+j/73/0v/e/+b/6//n/+P/5f/y/woAKgBNAG4AjgCYAJAAgAB3AHYAYgBVAEUAPgBGAEcASgBKAEEAMQAoABoACgD2/+D/0f/H/8D/v//Q/+b//f8WACoANwA+ADMAGAD8/+H/1P/R/9n/3f/s//b/BAALAAoA/v/o/9L/wf+6/7D/tP/B/8j/y//V/9b/2f/X/8j/rP+P/4D/ev93/2r/af9v/2n/av9d/0X/J/8M//T+5v7Q/sb+zP7b/vb+Hv9E/2f/kf+s/7L/rv+y/7P/uv/F/9X/5P/w/wkAHQArADAANwBGAE4ATABMAGAAcQB3AIIAkwCwANEA+QAZASsBOQFCAUIBNgEfAQUBAAEAAQoBIgE2AUEBPQEwARoB/QDbALoAnAB+AGkAXgBTAFgAUgBIADYAJQAIAOj/zv+r/5P/hf90/2v/ef+N/5//rv+t/6P/kf9z/1H/IP/6/tP+s/6p/qv+t/67/sX+xv60/qL+kf6F/oH+iv6c/rv+6v4X/zX/T/9k/2j/Wv9T/1L/VP9d/2v/g/+Y/7X/3f/8/xEAEwAUABAA/v/q/9r/1f/c/+v/EAA4AFYAbwCKAKEApACiAJEAhQB6AHwAggCVAKwAwwDTANMAyACvAI4AaQA/AB0ABQDq/93/1f/O/8X/vP+x/5v/fv9l/1H/Ov8v/zP/RP9i/5H/u//Y/+f/6f/z//T/7//s//H/+/8HABQAIQA0AEAAOQAoABkADQD6/+r/5v/m//D//v8HAAkA///1//L/3//I/7r/s/+6/8D/xf/O/9b/1//T/83/xP+3/6b/of+g/6L/q//C/93//P8dAEAAZgB/AIoAiwCNAJYAnwCrALoAzgDnAAMBJAE5AUkBWAFcAVEBOwElARgBEwEUAQ8BCgH9AOIAxgCjAIcAagA7AA8A6//j/97/4P/X/8//xP+0/6z/o/+U/4b/eP9j/1v/U/9N/0r/Tf9G/zz/Of8z/zD/Kf8s/zb/QP9P/2b/g/+n/8P/2f/n//L/9P/5/wAACAAZACIALwAyAD4ASgBKAE0AQwA1AB4AFwASABcAIwAyAEMASABAADAAGgDu/9H/tv+X/33/dv92/3r/iP+f/63/tf/E/8f/yf/C/7n/rP+s/7D/tP/C/9L/4P/u//r/8f/f/87/xf++/7n/xv/P/+L/9v8AAAsAFgAbABQAAADq/9P/wP+9/87/5P/7/xAAEgAPAAAA7P/P/7r/rP+n/67/uf/H/8z/0P/O/8j/r/+b/4j/hf+H/4v/mf+i/6//uv+4/7r/v//O/9z/2f/U/9r/4P/i/+3/AgAPAB8AMgA7ADcAJgAdABMAFAANABAAIQAvAC4AJgAiABwAEQAFAAUAAQD4//H/6//r/+3/6v/i/9b/zP/I/83/z//R/9P/0P/E/7T/r/+r/7L/uf+9/73/u/+8/8T/1P/q/woALABHAGYAgQCUAJ0AoQCqALgAvADBAM4A1wDcAOQA8QDoANEAuACjAJUAjQCRAJsAsQC9AMoAyADAALIAnACEAG4AYABPAFMAUwBfAGsAcABtAGAAWwBUAEgAPAA7ADEAKQAjACgAOABBAEIAOwA2ACYAGwALAP7/8//t//f/BwAgAEEAYAB1AIAAewBsAFcAQwA+AEEATwBkAHUAeQBlAEYAIQD3/9j/v/+o/5//nv+n/6f/pf+m/53/jv+E/4P/gf+C/4T/hf+F/4X/gf99/3P/bf9u/3T/eP94/23/VP88/yf/Gv8R/xL/D/8Q/wn/Cv8G/wH/Af8B//3+A/8O/xr/Jf81/0D/S/9b/2L/df+D/4j/mf+q/8D/zP/Q/8z/yv/F/9H/5v8AABoAJQAsAB8AEAD6/+b/1//Q/8n/1f/p/wIAFQAXABMAAADu/9//3f/a/+X/9v8FABIAHQAeABwAEAD8/+n/1P/G/7r/t/+w/7L/u//L/9r/4P/n/+f/6//0//f//v8DAAEACAASACYAPQBRAGUAZwBgAEwAOwAyADAANQBAAE0AUQBVAFUASwA/ACoAGAAOAA4AFwAwAE4AbQCGAJsAqQCrAKwAqwCuALAAtADKAN4A6gDvAO0A3wDDALQArQCvALAAsgC0ALcAvwC/AL0ArACQAHgAZABXAE8ATQBSAEkAOgAsABcAAADt/9v/wf+r/5b/ff9x/2L/Uv9K/zv/Of8u/yD/Gv8Q/wz/CP8D//v++f78/gD/B/8K/xL/Fv8Z/x//Jv8w/0H/U/9y/5H/qP+t/57/j/+E/3z/ef9//5b/rP+//9v/9f8GAAIA9//q/97/5/8EAC8AaACbAL0AzADDALEAkQBsAFEAQABEAFAAYQByAHcAcQBlAFIAQgApABYAEgAaADIARABTAFcAWwBgAGEAXABhAFYAVQBZAFMAVwBUAFUAUwBXAF4AZgBpAGcAawBdAFcATwBGAEMAPQA0AC4AJAAiACUAFwD8/9//2P/I/7z/vP/H/9r/7/8AAAsAEQAJAPz/8P/0//3/BQAcACcAOQBOAFkAVgBCACIAAwDo/+P/7f///xMAJwA1ADMAJAAbAAYA/P8CABMALQBBAF8AagBqAGcAYgBeAFcAUwBRAF0AYwBnAGcAXgBSAEsARQBHAEwAUABcAFMAVQBSAE4ASABCAD8AOgA4AD8ASgBPAFgAXQBeAFAANgAQAO7/1f++/7X/tf+9/8T/v/+s/5b/ev9q/17/Xf9n/3X/gP9+/33/cv9g/0v/NP8h/xf/Gv8p/z7/P/81/yL/E/8M/w//Gf8d/yj/NP9G/1P/U/9M/z7/Mv80/zf/Nv8//0f/U/9j/27/dv94/3L/bv9n/2P/bv+I/5//v//h//v/CQD7/+L/z//V//H/EgA8AF4AeQCTAJ0AjwB2AFUAOwAnAB0AHwAoACcAKQAiAAwAAADq/93/zP/H/8L/vf+1/6//qP+d/5H/fv9r/1j/R/8+/0P/WP92/57/uv/R/9f/1P/V/9P/2f/z/xYAOwBYAHgAhQB/AH8AdABkAF0AZwCBAKsA5AASAS0BMQEeAfcAygCnAJMAhgCLAJMAowCvAMoA5gD+AA0BCwH4AO4A7AD9ACQBRwFeAWsBaAFWATgBGgH2ANQAswCWAIoAjgCXAJsAlwCGAHkAZQBcAFwAUgBJAEYAPgA8ADwARQBLAD8AJwAVAAcA9f/l/8v/uf+x/7D/wP/R/+H/4v/d/9j/zf/O/9b/2f/X/9X/0f/K/8P/yv/X/+z/8/8DABMAGwAMAAEA+//7//7/EQAdADEARgBIAEYAPQAvAA8A8v/n/+D/4P/o//P/+/8CAAUABgD+//P/5//Y/8f/uP+r/6T/mP+Q/4v/if+A/3r/bP9Z/0v/Qf8+/z3/Pv9D/1n/av94/4j/k/+O/4f/fv90/2T/VP9R/07/S/9B/zb/Nv84/zL/G/8F/+v+1f7D/sT+yf7U/tn+1/7f/ur++f7//vr+8v7x/vL+9/4B/xX/Iv85/07/b/+W/6//wP/D/8L/uP+9/8f/2v/1/xkAOgBSAGgAbwByAHEAbQBeAEoAOAAyADMAQABXAGAAbQBuAHQAbQBeAEUALQAWABgAIwAyADwASABXAFEAUQBDADgALgAlACYAJwAqADUAOQBFAFUAXABnAF4AVABPAEgAQAA5ADYANwA/AD0ASgBLAEsASQA5ACAAAgD6//j//v8EABMAFwAkACgALQApACEAFgARABgAKQA1AD4ARgA8AC4AIwAXAAYA9v/0//T//P8CAAMABgAJAPv/7P/q/+n/7v/3/wMADAAYAB8AJQAdABQAAwDr/+H/4v/o//H/BAAIAAoABQD6/+f/z/+3/6v/sP+t/7X/tv+z/6r/n/+L/3r/av9d/1v/Yv95/5P/sf/J/97/6P/q/+3/9v8KAB4AOwBGAFkAZQBeAFUATQBJAEcAQwA9ADsAPgA3AC0AGAAEAOr/wf+Y/3j/Yf9R/1L/S/9O/0X/SP9O/0v/Qv8u/xr/CP/3/uv+8f4E/x7/Of9Q/1j/WP9N/0n/Qf9B/1D/WP9l/3j/hP+G/4f/hf+M/5f/n/+k/7f/zP/e//X/HQBEAGAAggCbAKwAwwDcAPYADQEcASYBIgEXARAB+gDpAOAA2QDSAMkAvACfAIIAWwA3AB8ACgDt/+T/6f/z////BQAQAA4A+//u/+X/6P/z/wgAIgA2AEYASABCADUAHwADAOT/0P+//7P/tv/C/9H/2//d/9j/0P/L/73/t/+//8n/3P/s/wUAIAAxADQAMAApABYAAADt/+L/3//l//H/+P8DAAwADAACAPX/5P/Q/8z/1f/k//v/FwAnADEALwAyAC4AKwAkACQAHQAcACAALwA7AEwAWQBZAEwALQARAP3/6P/h/97/2v/S/8z/xP/B/77/uP+m/47/fv94/3//gv+L/5P/pf+t/7v/xv/K/9T/1//W/9f/2v/c/93/1//O/7z/s/+m/6D/lf+Q/5L/jf+J/5H/m/+g/57/of+i/6b/of+h/6L/mP+N/4r/k/+X/5r/lP+O/5b/of+6/8n/3P/j/+X/5P/X/8X/u/+8/8X/0v/l//3/JQBNAGYAdQB2AHEAZwBXAFQAUwBdAHkAngDMAPsAFQEuAToBQAEuASEBCwH1AOoA6gD1AAYBCgEOAQwB/gDuAOAA0ACxAJAAawBLAC0AFQD+/+j/0/+5/6j/lf+L/4L/dP9Z/0D/N/8t/yL/H/8V/wv/EP8c/yz/Nv8+/0H/Q/9L/0z/Vf9P/0r/S/9V/2r/gf+a/6j/uv/J/+L/+P8GAAUA/P/2//P/+P/3/wUAJABDAGkAiwCbAKcArgCjAJQAdQBhAFkAVABVAGEAdwCIAJYAnACRAHwAUgA7ACwAIAAaABEAGgAkADYATgBWAFsAWgBPAD8AKQATAAUAAQAGABAAFQAjADgARABLAE0ASQBGAD0ALgAaAAcA+//1//L/8P/w//X/+f/w/+L/2v/R/7r/rf+d/5r/j/+J/5P/pP++/9P/4v/v//r//f8DAPz/7v/l/+X/8v/8/w8AHgAoAD4AXgBtAG8AagBeAFcASQA/ADkAOgBEAFMAYwBvAHkAfQB+AHkAbgBaAFQASgBCAEgASgBXAGsAegB+AHwAcABdAFEARgA5ACsAHwAUABEAFAAZABoAFwASAA8AAQD+//b/+P////7/AwANABoAHQAnADMAOAAwADAAMAAtACgAIwAbAAUA/f/q/9b/vv+o/5b/if9v/2X/ZP9k/1z/Uv9H/zn/Mv8g/xr/Hf8j/yP/LP8s/yz/Jf8h/yv/LP81/0H/Tv9V/1b/VP9S/0//VP9W/1v/ZP94/5L/ov+8/9f/9/8QACIAOgBRAHMAkAC7ANEA5gD2AAgBHwEuAT0BTwFZAVoBTgFEAUQBSQE9ATABIQEJAe8A3QDEALYApgCjAJkAkgCOAIIAewB8AH0AfQB0AHsAggB5AGkAWwBEACoAHgATAPv/8f/u/+3/7P/t/93/0v/I/8D/rv+d/5D/iP+Q/5T/l/+d/6H/q/+3/9P/4v/l/97/1//V/9T/zP/E/7H/t/+u/6z/o/+l/6T/qf+2/8T/z//a/+j/8f8LAA4AEQAWAB4AHQAYABkAHAAlAC8ANAA0ADwARgBIAFEAUABaAGEAYgBmAGsAawBzAHUAggCWAKgAuQDCAMoAygDKALYAowCXAI0AfABqAFoAUABTAFYAWgBOAD4AHQD//+P/z/+x/4r/bf9c/1f/WP9Y/0//P/80/y3/Mf8//0v/Uv9e/2n/bP92/4H/j/+j/6//xP/V/9v/6P/x//f/+P/7//n/7//h/9n/1f/U/9b/5v8EABwAKAAjACEAIgAfABUAEwAcADIARwBeAH8AoACsALcAuQC7AMUAvwC4ALQAuwDBAMwA1ADTAMUAsgCjAI0AewBsAFkAWwBdAGsAfgCNAJAAkwCPAIQAeABfAEoAOwA8ADoAMQA3AD8ASQBJAE4ASwBFADoALwAiABcAAwD9//v/7v/r/+r/6v/1/wgAIAAzAEIARwBSAFIAUgBTAFUAYABeAFEASABHAEsARQA7AEcASwBVAGIAXABWAE0AMQASAO3/1P/I/8H/wP+0/7X/sP+3/7j/sP+j/4r/fP93/3v/dv92/2j/YP9g/13/b/97/43/jP+L/4X/jP+N/4//jv+T/5j/pv+y/77/z//X/+L/9P8BAA8AFAARABYAFgAfACQAJwAoAB8AEgAEAP3/9v/q/9j/wv+s/5X/kP+M/4//jP+K/5H/oP+v/7z/wv/P/9T/0//S/9L/1v/V/9D/zP/K/8H/wf+y/6v/of+Y/5b/lv+j/6X/ov+l/6n/v//J/87/zf/H/8r/2P/e//H/AQATACYAMwA8AEIASABKAEUAQQA9ADkANwA2AEkAUgBbAFwAUQBGAC0AEgAFAPr/7P/d/8n/t/+t/6//tv+3/7v/vf/F/8v/x//K/8j/yf/M/8v/0//d/+D/3v/b/9r/1P/c/+X/7v/9/wsABwAHAAIACgASABwAJgAvADYAQQBdAGoAcgB5AH8AgQCCAIEAfgCHAIcAkgCKAIcAdwBjAEkAJAAMAP//8//b/83/yv/M/8r/xP+3/7T/r/+p/6r/p/+t/7X/vv+6/7j/uv/C/8f/zP/a/+H/6//0//r/BAANABMAJwA5AE8AVgBZAE8ASgBIAEgAPwAyADAAMwBCAFkAbACAAIgAhAB9AHoAawBqAG4AcwB5AIIAkACLAIwAhgCOAJIAkgCRAIwAiQB/AHIAYgBHADYAMQAkABgABQDu/9r/1P/G/8H/sf+k/6H/nv+k/6v/vf/F/9P/3//l/+H/5v/z/wEA//////3//v8EABAAEAARAA0AEAAZACIAKgAmACwALgArACkAIwAqACsAKgAkAB8AFgAPAAUA+//9//3/DAATAB8ALQA4ADsAMgAiABUACAAEAAUAAgABAP//BAAJABAAEAAdACcAKgAuADoAVgBiAG0AdgCBAH8AfQByAGsAWgBKAEMAMgAaAAsABwAHAAwAEQAaABYACADt/9X/vf+s/6j/nv+g/5//oP+k/7P/r/+y/6X/nP+H/3L/av9g/1j/Vf9L/z7/Kv8c/xT/C/8C/wT/AP8B//7+DP8a/y//Rv9S/2r/ef+O/63/xP/P/8//zv/M/8n/yv+8/6n/o/+Y/5b/lv+M/4P/e/91/3P/dv9y/3D/f/+I/4j/lP+j/7r/yP/V/9b/2//f/+T/6v/n/93/2v/d//D/8v/v/+n/6//f/87/uP+3/7j/r/+j/5P/jP+U/4//iP+A/2f/Wf9V/1D/Uv9c/2L/ZP9k/2T/aP91/4L/gv98/3X/dP+D/4j/lP+T/5P/m/+f/6H/ov+l/6H/qv/A/+D/9/8ZADMATwBsAH8AkQCPAJYAkwCQAI0AlQChAK4AsACsAKUApgCaAJQAmgCRAI0AiACFAHYAYABeAFwAWgBdAGsAcAB4AHgAgwCFAH4AegB8AH8AfwBzAHMAcwBsAG8AZwBgAFQATgBKAEcASAA+ADMAGgAKAAUACwAVACMAJAAcACAAHgAjACYAIgAgACQAJwAlAC0APgBKAEkAPgA0ACsAKgAtACkAIgAlACsAIwAbABIACQAGAPT/5v/b/87/zP/F/7r/uP+y/7X/s/+0/63/sf+1/7b/uf+9/8D/wf+0/6n/nP+c/5v/n/+Y/5f/mP+Z/5n/mf+o/7L/wP/P/9j/3f/e/+L/7v/v//n/AQD//wQADwAgACYALwA7AD8APgA4ACwAJQAbABQAFQASABIAFgAeAB0AGwAZABoAGAAYABoAFgAUABYAFAARAAsABwAIAAkADgARAA0ABQACAPn///8IAAoA///7/wIAEgAaAB0AJgAsAC8AJAAjACMAIgAdABAADgALAA4AGwAwADwARABBADIAGgAEAOT/zf+4/7D/qP+i/6T/rf+0/7T/pf+b/5v/p/+u/8P/0v/l//L/+v8HAA8AEgAVACAAJQAmACUAKwAqACgALAAoACAAGQAlADMAPQBOAFoAWABeAFsAVABMADoALQAZAAgA/f/z/+H/zP+8/6v/lP99/2b/Tv86/yj/Gf8M/wT//P7w/ur+8f7//gH///7x/vH+7P7u/vf+Bf8O/wf/Df8l/0n/Wv9j/2//i/+c/6P/oP+X/6T/s/+4/7L/uv+3/7//w//R/9v/2//r//H/+v/+////9v/v/+b/5f/p/+b/3v/c/+X/3//g/+b/8v/2//f/9//3//r/CQAUACMAKQA4AEgAWQBxAH8AjQCbAJwAogCtALcAuwDDAMYA2ADiAOEA5QDjAOEAzwDFAL0AsACvAK8AuwC/AMYAxgDKANQA4gDzAPUA8ADuAO0A6gDmAOMA7QD0AO0A5gDkAOQA6QDlAN8A0gDTANUA0wDHALoAswCiAJAAfABfAFAAPwAsACUAIgAkACYAJgAiACAAHAAYAA0ACQD//+v/0v/B/77/uv+8/7z/xv/H/8P/vf+w/6b/n/+T/47/lv+g/6j/s/+4/7v/uv+4/8T/xv/I/77/uP+v/6r/pf+k/5v/j/+D/4L/cf9p/2X/ZP9f/13/Tf9G/0H/P/8+/zn/Mv81/zX/OP8w/y3/L/8x/zL/PP9M/1P/YP9v/3r/hf+L/47/h/+D/4X/iP+P/5T/k/+U/5X/l/+X/6L/sf+5/77/yP/Y/+j/8f/8/wYADgAOAAsACAAIAAAA9//s/+X/2f/Z/9j/2v/Z/8//z//S/9P/0f/M/8f/w/+5/6v/qv+u/7X/w//C/8j/0f/W/9L/zf/R/9b/2P/g/+f/5//q//n/AAABAAMA/P/9/wAAAQD5//b//P8SAB4AKwBAAFcAaQB/AI0ApwDJANQA5gDsAAABCQEVARYBFgEYASABIQEjASABIgEgASIBHQELAf4A8ADgAM8AvQCzAJ0AkwCOAIkAgQBlAEwANAAjABYAFAAFAPv/8v/3//b/9//r/97/zf++/7v/s/+h/5T/nP+h/5f/k/+N/4f/iv+L/5H/lP+S/5j/of+i/5v/mP+U/5r/mP+T/5X/l/+Q/4r/hP+B/3v/bf9d/1D/Sv9D/0H/P/8+/z//RP8//z3/Rf9E/0P/Qv9J/1j/Zf93/4H/iv+R/5P/q/+3/8D/wf/L/93/6v/4/wAACAARABgAGgAiACgALwAzADUAOwBBAE8AVwBgAGUAcQBtAHYAbwBhAE0AQQA3ACgAFgD+/+v/4P/g/9L/0v/M/83/x//E/8D/v/+y/67/rf+l/6z/uP/J/+D/9P8FAA8AEwATABsAHgAiACEAKAAoAC0AMwAvACkAHQAaAA8ABQAAAPv/+//5//v/+P/x/+3/7v/y//7/CwAKAAQA///7/wAAAQAKABQAGgAcACUAJgAoACIAIwAoACsANgA+AFQAaAB4AIAAhgCUAJkApAClAKUApgCzALwAwgDOANgA5wDoAOYA0wDLALcApgCaAJAAggBqAF8ASQBGADwANwAxACQAJwArACUAIgAhAB0AFAAEAPj/5//U/8X/uv+y/67/qf+e/5X/if+A/3D/Zf9f/1P/UP9Q/0//U/9X/1T/Wf9d/2T/Zf9q/3P/av9w/2z/aP9l/2b/ef+I/43/mP+a/53/nP+a/53/n/+q/6r/qP+m/6b/rf+w/7L/sv+r/6f/qf+q/6z/rf+s/6z/sv+6/8H/vP+1/7T/vP+9/8n/z//d/+j/7f/1//n//P/9//z/8v/r/9//3P/f/9T/yv/F/8n/x/+9/7v/vf+7/7D/q/+t/63/tv+//8v/0//T/9b/zf/W/9D/zv/C/7r/tv+2/6n/pv+n/6L/nf+T/4b/hv+E/4X/iP+X/5z/p/+s/7r/yP/d//P/AAAGAAkACwAIABkAJAAvADoARQBUAFkAXABtAH8AjwCRAJIAjgCSAJsApAClAKoAsgC8AMUAyQDHAMIAxAC/ALoArwCeAJAAigCNAIwAlACWAJsAlACOAIkAeQBvAFkASwA7ADEAOQA5ADkAOQA9ADkANgA3ADQAOQA8AEcATQBIAEUAQQBAADsAOgA6ADYAOwBIAFIAWABTAFoAVwBcAE8ARwBDAEMASABFAEoARgBBACkACwD8//D/4P/S/8n/y//G/7z/pP+l/5b/c/9a/0r/Nf8t/yn/Lv86/z//QP9B/1L/Yf9s/3X/e/+L/57/o/+p/6j/pf+k/5v/nP+d/6D/oP+d/5T/jf+J/5P/l/+d/5z/m/+Z/5X/iv+B/3L/av9d/2L/aP9x/4P/lf+k/63/of+Y/4//hf+A/3r/df9y/3L/c/91/3X/ff96/3j/d/95/3b/hP+S/6D/rv+6/8r/1f/g/+7/AgAVACYAKgAqACUAHgAcABEAFwAcAB8AIQAkACgAKAAvADMAMwAwADUANQAwADQAMwAzADYAPABIAE8AXQBuAHsAhgCLAIwAlgCjAKIApQCiAKAAqwC1ALgAtwC8AL4AwQC6AMQAxwDUANoA3ADVANkA1wDeAOQA5QDbANQAzwDLALoArACeAJAAfQBvAG8AbwB2AHwAewB8AH8AewByAGcAWQBTAEwAQwA5AD0AQAA5ADoANwAvACoAJwAmACAAEgAAAPH/6f/n/+f/4//m/+v/8P/u/+n/5//k/+f/5P/h/+j/6//r//H/+P/8//L/8f/q/+D/3v/d/9z/4f/r//j/+//+/wIABwAJAA4AEgAUABYAGgAaABYADQACAAgAAwAFAP3/8P/h/+b/3//b/9v/1f/H/7n/pv+d/53/mf+O/4//mP+h/6j/qv+w/7P/tv+3/7H/u//D/8T/tf+4/73/xf++/8T/w//I/9b/4P/p//D/+v8AAAoAAwAHAAIABAANAA0ADAADAAAA/f/1//H/9v/+/wAA/f/6//f/9//0/+v/5//c/+P/5f/p//X/9f/7/////v/+/wEABgAUACcAPQBMAGUAcwCEAJAApgCqAK4AswDAAMQAxwDGAMQAxADFAMAAtwCpAJkAjgCEAHAAZABTADoAJAASAAEA7//g/8z/tv+d/5X/lv+d/5j/nf+p/7H/tv+z/7j/w//K/9D/1P/R/8z/xf+8/7j/uf++/7z/rP+g/5f/lP+K/4b/iP+J/5D/jf+Q/57/r//F/8//1f/Z/97/3v/i/+X/5//l/+D/1f/g/+//+v/9/wAA/f/3/+z/4P/d/9P/1v/U/9//6v/t/+z/8f/7/woAHgAsAEcAWgBqAHcAiQCJAIIAfAB9AHAAcAB3AHwAdABxAGsAXQBUAEcANgAsABsACwD0/+H/z//C/7T/pv+Y/4r/fP9z/2r/cf+A/5D/q//C/+H//f8HABIAGAAbAB0AJwAyAD0APQBPAFcAYQBgAGEAbwB+AJEArQDIANMA4ADwAPkAAQEBAfgA9ADxAO8A4gDXANMAxQDGAMQAwQDDAMMAxAC8ALcApQCQAIMAgAByAF4ASgA/AEQAPAA8AEAAPwBAAFMAWgBaAE0ASwBKAEEALwAeABQADQAQAA4ACQAGAAcABQD5//D/8v8AAAkACQAGAAAA/P/1/+n/3P/L/7z/sf+k/57/lv+T/47/jv+P/57/p/+s/7H/p/+i/5//lv+S/4v/if+F/3v/d/91/33/jP+d/6L/tP/G/97/8f8CAAQAFQAeACEAGQARAA8ACgACAPn/9//v/+T/2P/N/8r/wf+5/6z/qf+a/5j/l/+T/47/jv+M/47/kf+W/6P/qf+7/8j/0P/T/9z/5P/p/+n/6v/o/+L/3v/W/8j/v/+0/7f/tP+r/5X/h/+M/5T/mP+Z/5H/kP+L/4X/gP91/27/Z/9l/2v/bf9r/2r/aP9f/1X/Tf84/yj/Gv8T/xD/E/8d/yT/Lv8+/1b/d/+W/7D/vv/O/9r/4//q//P/BwAeACEALAA7AEQATABOAFIAXwBdAFoAVwBjAHAAfACHAJ4ArQCrALgAyADGAMQA1wDmANUAzgDTAM0AywDMAM0A1ADKAMUA1ADYANkAyQDCAL4AuACsAKYAnQCWAJEAlQCXAIgAhACDAHkAaABaAEEAJwAWAAIA/v/3//n/8P/s/+3/6v/k/9z/yv+u/6D/jv+S/5T/mf+Y/5f/kv+U/5L/jf+G/3v/fP97/37/hP+D/4r/mf+r/8T/0//l//X/9v8IAA4AFgATABIAEwASABUADQD///H/6//e/9n/0P/K/8D/vv/F/8n/zv/X/9n/3v/t//D/5//h/+L/4v/p/+b/4P/b/+L/2//d/+z/8v/z/+7/8v/z//j/8//v/+b/0P/M/8X/wf/A/8L/xf+9/7H/pf+e/5L/h/+C/37/d/90/3H/bf9n/2b/WP9H/zj/N/8//0b/T/9W/2D/aP9y/3n/hP+C/4D/ev9v/3D/df9y/37/kf+Z/53/mf+f/6f/t//D/8v/1f/W/+T/9f8FABQAHAAeABkAGgAkAC8AOgBEAE0ATABBADcANQA9AEAAQAA3ACgAIQAbABoAIAAZAA4AAwD3//D/7v/v//X//P/6/woAIwA3AEkAXQB1AIIAjgCUAK4AxQDbAPYADgEnAT0BVwFnAX0BmgGsAbsBxgHTAdYB3AHcAdUB1wHSAdIBzgHHAc4BywG7AZoBfQFuAVoBRAEnAQ4B8ADWAMYAuwCcAHsAVQAyABMA8P/I/5j/a/9K/y//FP/0/t7+1f7P/sv+vf6v/qb+n/6c/qH+p/6x/rz+x/7V/uL+8P77/gb/Df8V/yL/Nv8//03/Zf9w/4X/lv+i/7v/1P/z/wkAHgA1AEIARgBHAE8ASwBIAEIAPwA3ACYAGgATABIADwAAAAEAAwAAAPH/6P/a/8//yP/C/8f/0f/Z/9j/0//F/7b/rf+u/7D/tv+6/73/wf+9/77/uf+2/8H/xv/T/+j/7v/0//H/5P/d/9D/w/+4/6v/qf+z/7z/v//K/8b/xv/H/8L/uv+t/53/h/9w/1X/Of8Q/+/+1/67/qD+kP6K/ob+gv6D/oH+fv5//oj+m/6k/qb+qf6y/r3+x/7P/t3++P4P/y//S/9o/3//iv+Y/6z/vf+9/8H/zv/i/wUAJgBCAFQAYwB1AIYAlgCoAMAA1QDrAAUBEgElATYBQQFIAUsBVAFhAWoBcAF0AXUBcwGBAYUBhgGDAYMBeAFtAV0BTAE1ASQBFQEIAfkA5wDjANcAygCoAIEAWQAwAP//1f+s/4//bf9N/zT/Fv8B/+j+0v7F/rj+lv5t/jn+Fv78/eT9yf2y/a/9q/2o/bj9vf27/cP90v3t/RD+O/5b/nH+g/6N/qP+zP76/iX/Vf9+/5z/t//C/9L/2//n//b/BQAOABQAEQAHAP3//v8MAB4AMgBLAF0AYgBfAF8AYABTAEMARABLAFsAYgBkAHAAigCrALUAugC0AKgAiQBuAGYAcQB9AJQAoACkAKcAsgDBAM0AzgC7AKAAhQB/AIAAiACUAI8AiACGAI4ApQC7ALwApwCIAG4AWABOAE4ARwA5AA8A5f/B/73/yf/W/9v/wf+U/2D/Q/8x/yf/I/8f/yn/Of9H/1r/af93/3H/Zf9Y/17/bP91/3H/Zv9x/3P/dv+O/6f/t/++/7L/qP+p/6r/s/+9/7X/t/+w/6L/kf+E/4n/k/+j/7X/xf/K/8v/yf/M/+H/5v/c/9b/zP/G/8D/r/+l/6b/rP+v/7r/2f/6/x0AKAArADIASwB9AMMACgFKAXYBiAGWAbgB5AERAjsCcAKwAuwCKgNUA3EDbQNnA2IDbwOKA6gDuQOkA3cDRwMOA+kC2ALbAtsC0gKxAnUCNQL3AbwBfAE4AQ0B6gDKAJ4AXAAFALf/gv9n/2b/bf99/3v/Tv8D/7j+iv52/nf+gP6K/or+eP5e/kT+Nf42/j/+T/52/pj+pf6a/ov+dv5y/nT+jv6m/rz+1f7V/tb+0f7G/rn+r/6Z/oD+Yf5C/jX+K/4s/jX+Of47/kf+Sv5E/j/+Rv5P/kr+Sf5G/kn+T/5a/nf+pv7W/gn/N/9d/4P/pf/L//b/NAB8ANQAGwFeAZIBygH6ATECdwLBAg4DVwOdA8wD7QMOBC8EUAR0BIoEhwR1BEcEBgTNA5EDRQPuApACJAK1ATUBpgAkAKH/Hv+x/k3+7/2J/Rn9t/xk/CH88fvW+737nft5+0v7JvsJ+wX7CPsY+y37Wft8+5b7qPuo+7n7zvvo+xD8QPxr/Hz8hvyN/Kr82fwK/UT9e/2r/cP9yv3a/f79Kf5T/nn+lP6c/p7+ov6e/pT+iP6F/pj+tf7W/ub+7f7x/u3+/P4Y/zr/Xf96/5L/sP/m/zgAmwAJAXoB2gFLAtICdQMgBMUEUAW9BSQGngYeB4cH2gcYCFkIngjjCBcJQQlBCQoJuAh+CG4IXQgxCNUHWQfLBjsGxgV3BTEF1gRKBJEDzgIZAoIB5wBVAML/Mf+n/iD+oP0k/a78NPzI+3T7OfsD+8L6e/oz+vr52/nr+RP6Svpy+pL6tvrk+j77sPsz/J787/w8/Yj90/0i/nf+2P4q/2L/l//Q/wYALQAyACsAPQBZAGkAaQBjAEoAMQAOAO3/6f/y//D/zv+x/57/oP+x/9L/BgBBAHUAoADJAAMBQgF2Aa0B7AFZAs8CPAOSA9wDGQRBBGwEpwT/BEwFbwVpBVoFTgU6BR8FDwX3BMcEfQQSBK4DUQPpAnEC4QFFAbQAIAB+/9z+Sv7R/Vr96vyB/CT8xftX++D6dPol+t75qPlx+Un5IvkE+fv48Pj0+AH5B/kG+ff49Pjz+PP4BPk8+Y/52/kU+i/6M/o9+lj6lPri+jj7evuN+4T7fPuF+6b75Psz/KT8Iv2c/Rj+if7q/kj/xP+FAJcBywLqA7QEPwWaBeYFYAYMB9YHggj/CFMJiAm2CecJHgpcCqMK6wowC2ILYAsqC8MKTgoFCuwJ+wn9CcIJOQlnCIgHyQYyBssFcQXvBC8ETwNjApQB7gBPAKv/Bv9G/oD9uvzv+zT7gPrh+VT56PiJ+Cr40PeA90v3OPdM94j34Pc2+Hj4p/jI+PT4S/m7+T76uvoX+0n7Wft2+6f7+ftj/MT8AP0a/R/9C/0B/SD9WP2Y/d/9Kv55/r/+Af8//3n/wP8RAHcA6gBjAb0B8QH8AfMB6AHZAd0B8gEFAvkBzgGdAXYBTAEYAdcAiwA9APL/mv83/9L+aP74/Zz9cf1u/Y79sf32/VP+0/58/1YAewG5AtgDxgSVBXoGhgeaCIsJMwp0CmIKKwoLCgoKDgrcCUUJbwigBwIHjQYRBoQF0QT6Aw8DDAIhAWoAs//A/qP9rvwS/J/7K/uy+iT6h/nS+Fr4VfiT+MD4j/ga+K/3fPeI99b3Q/iS+JD4WvhD+Hf4AvnO+cv6vPt6/Df9EP4J/woA9wDsAcoCigMzBNQEgQUPBmQGjwaiBqYGqQamBpMGXQbuBU0FmgQTBLgDdgNFAwcDpgIXAogBIAHfAMEArACtALgAswCzANoAQwG8AR8CfQLNAg4DPANdA3ADWgMZA8ECTQLSAUcBnQDl/x3/Uv6F/cT8/Psq+2761/ln+Q35o/go+LL3P/fK9nL2SPY+9j72SfZg9pf20/b99h33OvdW93T3oPfl9yr4Qfgl+AT4E/hq+A753vm++or7QfwI/R7+mv9sAXgDcQVBBwUJuwpcDNMNIg9JECkRxREwEoISxxK5EjwSfBGvEN4P/Q4GDuoMqQtTCt8IcQccBtIEkQNRAigBLwBn/7P+IP6f/UL9DP0A/SH9WP2G/Yn9Wf0M/bT8S/zc+2T74fpO+p756/hK+MD3Pfe39j/2//Xs9d31xPWr9bf11PUD9mL2//a690X4m/jn+Fz5BPq4+mL76Ps3/Dz88PuX+3z7s/v1+xH8APzc+8D7qvuh+577ovuq+7r7y/sK/IL8Ef2a/Rz+wP6R/5EAkwGnAvIDcwUAB5YIMQrVC20N2g4VEDERPBIeE90TiRT+FCIVBxWsFA4UKxMoEiMRQBBhDzsO1QxcCxwKIQllCNYHOwddBg4FfQP8AcUAy//R/r39nfx5+2P6Qvka+Ar3EPYF9fjzJPOj8kjyyfEB8RjwVu/n7rvuxO4C70HvRe8b7wrvTe/l76nwd/FI8h/z1PNb9Nf0ePVI9iz3C/jO+Jz5aPoH+3z7/vuZ/BX9Xv2b/fz9lP5e/0QAQQFCAiMDzwOJBKgFFQeWCAoKSAsxDPEMng1QDioPLhAVEaQRBRJmEsYSLxOdE+kTEhT8E3wTvBL/EXQRABFRED0Pxw0aDEwKnwg0B/IFigTYAhUBg/8z/vv8lPvO+db33/Uj9OfyKvJo8T7wsO4a7Qzs9Ou87ODtm+5X7hftheur6uvqFux57WDuj+477sTtgu2m7Tbu7O587+LvffB08YPycPP781X0wfRi9U72nvc8+dL6//vl/C7+QADQAnIF8wcgCgEMsA0uD58QJRKTE5MUKhWsFUcW9RajFxgYURhxGF4YIxgXGGsY8RhuGZsZSBmZGLkXrRZuFUkUaxO3EgYSJBHvD3YO1gwICzEJkwccBmwEZgI7ABH+8Pvv+RT4WfbD9FDzKvJ48T/xRvFH8SPxuPAQ8ILvRO9t79DvGfAs8A/w8e/M78XvCfCI8CrxxfFM8qvyxvLD8rDyePIt8hHyOvKO8gvzjvPh8/fz2/PF8zL0afUL93f4I/m5+E/3e/Xz807zxfPc9Or1afZH9vL1//XS9pj4Pft1/tEBCAXuB2EKhgyiDicRXBRbGMkc1iCmI+kk5CRhJEQkGiXRJr4o3SmGKbkn+yQhIvcf3R5UHo4d3BvyGBIVtRBMDC8IlASRAeP+Svym+eH2C/RZ8efu1+xi60bqIenN51Tms+Tz4jXhmd8+3lLdxtyO3Mrcjd3R3n7gWeIO5HXlvuYf6NjpKuwr757yA/YH+ZL7uv3U/0YCQgWwCD4MXg+UEZgSiBLwEUQRnxDtDyYPWw5zDVQM8wp1CSkIPgfFBtYGVAf6B2AISQjZB04HvgZGBuoFpgVsBUMFSQVhBXwFigUyBREE+gE6/3r8avov+Wv4tvft9hP2G/VX9IP08vUy+LL6KP2H/9UBKARRBh0IZQnuCeMJ3wlVChkLvQu+C/YKlgn5B68GCwbtBZYFqgQeA+wAUP63+4T5rfch9ub0/vNx84bzIPTU9Eb1bPWB9fH17vZM+Mr5C/vU+w/88Pu2+6/7+Psz/En8lPxI/Sj+Gv8bAO4AYgGRAbABIAJAAwIF+wbRCF4KYQvYCzgMvgxcDQgOhg6pDjwOUA3+CyUK8QefBZwDKQIpAWgAwP/p/qj99PsV+n74hvcs90j3lffr9w/4uvdZ92X3wfcA+Bj4Ofh3+Mb47/jN+D74G/dB9erywfBi7/juKe9W78PuSu1j63jpH+gT6JDpC+zH7l3xo/OH9R/3nPjT+u7+qQRyCk8P9xIBFYIVZRWcFYAW6Rf/GCkZhhhyF0sWhxWbFXwWfxf/F+UXdxf4FlMWYBVLFDUT3RGDEGoPjg4SDuYN3Q2dDTIN9wyfDMILZgp+CPsF4gJZ/7r7WfgF9YDxEe4y61vpx+gu6Qfq+eql68nroOvC61TsEu3H7XbuMu/z77zwmfHf8on0OvbC9yb5WPoU+wf7CvpP+DP28PPg8TTwqu757FDrEepj6Yvpr+qN7HzuI/B/8b7yDfRf9bf2S/hq+uP8MP9UAdoDHgfzCv0O7RJBFnIYlRlDGg4b9xunHNEcfxzxG1YbEBtZG1Yc0h2TH1Ah0SLvI3gkTyRII7Ah5x8xHjYcqxmuFpETfhBRDTEKbAftBC4C3v42+6D3PfSd8Jzsnugn5VviRuAF35Xe2t6l38TgBOJr4+3kSOZ857ro8un56p7r4evw60bsH+1r7hfw6fGY8wr1b/YN+Bn6bfyT/iQASgFtAqkD/QRdBsEHGglBCiwLKQxSDS8OQw6lDcgM7wsiCy0K5wgaB9wEcAJZAAX/cv5I/hX+pP0S/bv85Pyk/ZT+Ef+g/o39pfyA/Dv9Vf5T/7P/cf/k/of+rv5Q/x8AmwBpAJP/cP6O/RP98fxV/Sz+PP9VAIgB0wIPBEMF0QbWCBsLWg0ED5oPIA8vDk8NwwyJDFEM3QsAC6oJ/QddBhcFVgTpA2QDcwIOAW//wf03/BH7QPps+Yr44vei97n3Bfhw+Mn48PgQ+T75wfm0+rT7b/ym/Hf8YfzK/Lf9zf6h/xAALwBMAHUAxAAtAU8B1wC//43+sf37/DH8Mvsf+jv5x/i9+Pn4Y/nP+Qf6RfrX+qP7LfxA/AD8ufvW+3D8af1O/qj+ZP7A/fv8Ufz7++378vuc+8b6gvnp90P2CfV/9Iz02/QX9VD11vXW9oH4+/oi/m8BRASQBtsIqQvcDugRNhSnFUgWTRY7FlIWeBZtFgYWKhX7E8YSzREEETcQUg9QDm8NzgwzDHQLzgoBCpYIuwb0BLED9wKXAjwCvAHjAKH/Nv4A/Q/8DPvD+Tr4o/YE9X3zLPIZ8UDwc++57lzuj+4y7xnwEPHQ8V7y8vKt83H0JPXD9Xv2XfdI+Bv5yPlZ+tD6G/tH+7z7pPy2/Uz+I/5X/Sv8wfpb+Tb4nveV99H3avhf+Z/67fsO/ff9yv7t/3wBPAPeBP4FTgbJBeEEGgSzA7QD4wP7A+cDtQN6A0cDIAP/AgkDUgMOBFkFFAfVCD4KXQuHDN4NMQ90ENoRcxMIFUIWMRezF3UXMhZUFIYSIREZEAkPbA0EC84HTgQ5Adb+nfw1+u330fXi8x7ykvAy7xDuMe2i7I3s4OxF7WXtaO2F7YXtZO0e7Xzsnevr6nHqSuq/6qTrg+zk7LTsf+wa7dvumPHM9CP4Pvu5/a7/vgExBMQGLgkRC0sMCw3LDZoOfQ9cEL8QZxCVD9AOWQ5KDmMOkw7dDgAPZw7ZDBkL7gnICagKPQywDT8OuQ20DEwMKw37DtwQ9RHYEeUQkw83DtQMJQvDCJ4FJQIh/yH96PvH+k/5r/c39jj17vQy9Zf19fXe9eD0R/Pl8QvxgPAX8NPvje/t7hzupO217eXt4O2+7bTt3+0Y7urtB+3B65zqx+lV6Z3pYOpY65DsUO7D8LnzAPdf+nj99v8hAnEEJgcdCu0MPg/tEBoS8BKSE1wUWRUVFogW0RYGF9wWABbYFAUUhRMZE/cSFxNyE+ETNhRPFPMTOBNoEpwR0hAlEGsPQA5SDL8JDgd6BCsCUADS/lH94/tW+mn4d/Yq9XX05PMx81Xyb/F28Mfvuu9A8P7wt/Fg8gvz/vMo9XL2lPdT+Iv4S/jb92X3BffR9pf2bvZ49rH2xfZz9rn1pvRw82vy2/G88eDx3/Fb8ZTwI/Bp8JPxcPNq9dz2wPeM+Nb5Dfzr/poBeQNWBHoEfgRBBfQGEAkIC48Mww0QD+AQLRN/Fa8XzhnCG3cdDB9+ILshjyLfIrMiQiLUIYEhGyFtICQfSB39GkcYMRXuEZYOBws8B1MDav+G+7f3H/S48JPtBOvy6N3mouSX4qbgyd493UDc3tvl2+DbXdtw2oPZFdmF2ZTavtvL3K3dVN7z3uPfP+Hd4pPkZ+Z16CbrwO4b85T3uvua/3cDxwe7DMERExZaGYYb8xxEHt0fWiFTIrQipSJ3ImwilSLQItIiYSKWIagg6R+EHzwf+h57HpQdSBzXGosZjBjoFzcXGhaRFNsSvhAvDn0LqQhiBYkBa/1P+S/18/DX7DHpCOZc4zrhkN8k3tnc5dtl2y3bTtv+2yHdf94Q4M3hruPc5V7o6eoh7RDv8PCw8kL0Z/Xb9b71HvVT9LLzOfOY8oHxCfCf7t/tRO7y7+PypfZT+hT9y/5PAL0C2warDOQS6BehGj4bsxpAGpoaTBtrG34afxjVFQUTZRAZDmgMbwsDCzMLJAx7Dc0O+A9IEdwSbhS5Fc0W6BfZGI8Z+hnHGaEY0BYOFcoTFxPGEhAS9g8PDBMHNQIT/sL68vda9W3yBe9/65bo+ea05kfn+eeK6CLp5+nJ6vrroe1G707wrPCQ8Brwnu+B79jvevBA8RHy0fKz88j0uvUx9g32xvUd9mD3XPmX+3j9aP6t/h3/ZwB2AtAEqwZ+B34HcAe6ByoIgwhSCCQH9wSCAuEAtgCaAVACvAEKAC7++vzN/JT97/4TAFoAtv8B/8j+Lv9GACYCmQRJB6UJOwshDPYMRw7XD34RNxPHFM0VPhYrFlEVtBPpEZIQ8g/DD4gPyg4yDeIKXAgfBjMEoAJfAVsAtf8i/1D+Hv39+0f7BfsH+wj7qfrm+dD4i/cv9qb02PLw8BHvX+0d7ILrVOs36wProeob6rbpkenG6VnqJ+uf63/r7Ooi6qbp9emv6j3r0Ova7Hzu7PD287b2pfi3+Rf6V/oy+8z8w/4CAekC0gO1Ax0DawJLApEDGwYuCVQM7A6AEF0RTRLsE6kWRxr3Hc4gViLYIvEiAyN8IyAkHiT1It4glR6dHAcbXxk9F68U2BEiD9IM3wonCXUHmgWAA/YAJf6c++D52vhO+Nr3fvdH98D2uvWD9JbzC/Of8vjxzfA474nt8utL6qHoPecw5mHl7uTn5D/l8uXX5pjnV+hg6azqHuz07Tzwi/J49Nj1y/ax9/D4efoB/H39tf5f/2L/t/7A/Sv9Gf3i/FT8Bfwy/Gn8cfyy/JD9Ov+xAZEEhAeACkANsQ+ZEl0WcxoKHnMghCF6IQchkCBBIDEgwx+LHqkcMhoqFyoUIxLdEBIQwA+UDz4PtA67DVIM4QqtCXUI2gbnBOgC/AAk/x797frC+Mb26/Qj88vx9/AC8ILuc+wn6i3o5+bs5f7kMOSD48jiE+If4kTjNeXD55/qUu2878rxi/Of9Xv4p/sx/gQAawGLAvcD1wXIB00JSgpwCqcJmQjKBzQHdgZXBasDqwG5/0D+a/1c/Ur++P/dAbkDngVwB7II7Qg+CKcH/QfxCIgJ9gi0Bi4Dkv/E/Dr79fp8+wj88fuS+6v7U/xN/YL+AQACAs0E/AfcChkNkw5YD9wPuRD/EUwThhRYFe0UTBMiEfAOsAxJCgUIQAbhBGIDQwGn/gr8lvmy95z2IPbE9dD0APMW8ePvou8L8I7w/fBO8UrxKfEv8Wvx0vFQ8pPyOfKK8dzwQfCr74Xv+++Q8CbxGfJ98yb1H/dq+dT7d/4DAVUD4QW9CF4LmA1bD4wQYxEuEsUSzRJ0EpYRORCqDvoM/gqbCP8FZwM3Aa//o/7Q/VD9Ov14/RL+Pf8OAT8DmgXLB2cJTgqWCoUKQgrrCR0JcQcHBZYCsgBT/zn+2/zx+mz45fUq9JXz9vOJ9Ir0ofNo8tnxqPLG9HL36/nk+xn9if2e/a/92/0+/oj+UP60/d/81Puy+hP69fnV+aX5sfkJ+uD6bfyp/jMBgwNhBZ4GXgcLCAkJrgqPDPINxw6TDzMQYRA9EDQQHRByD/oN7AtrCX0GcQOBAO39v/uh+Uj31vTG8o/xsPH/8p70m/XR9VT13vQU9dX1pfbN9hj2m/QS837y5vKr84L0UPUG9jX3N/nR+2r+wwA4A9gFgghNC1EODBEDE3sUARbaF2wZUxqYGoUacRqiGv8aEBt6GiYZGhesFFMScBAFD7sN6AtwCXAGJANo/2n7tfer9BLyQu8a7MTop+Uq42/hauAI4BTgL+BO4IjgROGf4l3k3eXO5pzn/egA60bt3e968rb0WvZ694X4Kvqz/OT/VAMJB5sKqg0hEAYSjxNQFdcXyRpcHT0fKiDKH4UeSR2dHHUcahz7G+8afBn1F8UWtBVdFG8S/Q9SDc0KxAjNBiIEdwBk/If4VPXl8vLw1+5p7Bnq6Of55cXke+Sf5CjlgOYG6WHsj+//8czzJfVb9q/3Afkf+rz6b/oV+UL39/XP9WL28PZ496742/qa/ZYA0QO7Bu0IhAr6C3YNqg4sD6QOSQ3vCxoLpgoICtYIHQeSBYMEvQPqAqYB3P+R/S37aPll+M73VPeN9lr1K/Rb8+vyi/IY8gfyXfLI8iPzPvMH84/yIPJW8szzzvYK+5z/yANOBxUKNAzZDc4PoxLIFR0YQRkrGTIYBRclFtsVPhYKF/MX/Rh2GiccPR0gHREcsRp9GWYYBRcOFRESpg3nB6gBBPyu95r0aPJp8MHtTepR5jjijN7y293a5Nop2yvb7trD2sHa8NrE26PdR+DE4oPk2OUD59vnW+jX6MHpa+uW7eLvNfLg9Fv4g/z2AF4FkQmHDUIRrxQsGOUbTh/OIWIjkiSjJY0mMyeXJ4Un1yaoJVskACMNIdsddRmVFCIQpwznCVoHZQTrAJb9Dfuy+Xb5u/kB+p36Efwp/vT/mADx/5H+Vv2V/Ab8pPvw+j35mfaW8wzxY+9g7p7tJu1O7fvtCu9l8IfxjfL78w72yPiv+wf+n/+GACgB0gHBAuIDbwQSBBcDuAFXAPX+h/0b/MP6gfn295H20PU49Tz0YPMm83PzL/R49S33ovge+Zz45fcB+En5IPun/PH8wvuH+eL2+/QT9Sb3t/kZ+/z6Z/rI+n38N/9vArkFiAhhCvALZw6oEUIUUBVlFeMVjBcIGpQceh7lHuAdEh1kHQ8erh5LHxEfNR1pGqAXURWXEwUS6g8RDdcJ2gahBGsCif9j/Ln5bfeP9Z/0l/SH9LHzDvJG8Djvde9n8CrxQ/Fk8I3ufOxJ60jrsOtJ69rp++d95grm0+aV6JDq6ut07G3sSOxG7FTsZOxG7OTru+tI7FHtmO4X8LrxWPP19Pj2afn5+6D+awEhBGcGEwhxCTULnQ2GEEcTeBUFFxwY6RhYGR8ZNBghFwEW2hQLFPETQBSuFNYU2RSAFUEXyRmAHNMeICBNIJMfCh6qG4oYDxWOEfANZQo3B00EYQGm/oP8evte+zn7avrS+JD2MvRP8sjwv+5W7Cfqj+ia5znnWOe45xrodug+6avqZ+y87UfuYO6T7tjuAe9F733vnu/O7ybwtPAM8aDwMe8b7R/r5emC6bTp2OlL6fjnCuen5xjq++3W8m/3QfvN/s0C8gaKCpwNHBDbEeISmhNYFMYUehRTEwQSZhF1EQwSFRMnFDMVKBYkF3cYQBpLHEgeJyDhIWgjwCT7JdcmkyZpJRskoiJXICId4hlGF+0UahKBD0cMowjqBHkBWv5H++P3C/Tv7zDsE+lX5njjLeDv3KDamtnP2aPaKttE2zvbkNuU3BreuN8g4Tji9uKN41rkbuWy5izovOlG683s9+1/7nLuMe757R3u7u6b8Brz+/V5+GP6bvxn/40DmwizDfYRWRV4GG0b7h3MH0IhVyLbIr4iayLRIb0gDB8cHZEbmBq9GZkY+RYPFWMT+hEcERYRxhHVErET2BPkE20UWxXoFXMV4xNEESgOEwv9B7cENgG9/Y/6gvdm9Jzxju9C7oHtCu1y7KLrxupS6pjqUOs57N7sIu1L7c/tWu8g8l/1Ofig+tL8uf75/4cAxAD5ALAAsf8a/jL8H/oO+Bn2afTE8sjwdu4V7Bzqqeju5/TnoOi+6d3qmevf6z7spO1U8NXzWfdd+uD8Cf+YAKsBXgLBAp4C/AFlAdwApv/R/Yb8qPwj/nMANAP9BZEIMwtHDicS0RaIG7UfUyODJp4pxSzaL5gyhDRJNTM15TQvNGgyei/nKwYoziMbH/IZkxQ5D8UJgATI/6/7Jvj99NPxwO4U7Gbp+uUx4treMdxq2mzZftiJ19HWtdUe1OLS0dLu06bVW9eN2HXZQ9r32p/baNx13bHe1d+i4DzhNOJ845zktOWH59HpP+wu7/HyY/dH/EIBvQWkCc4NrhIRGG8dXCKKJscpJSyvLT8u9C3QLLQq6idoJTYkCCRQI78gwBwCGacW6hUJF1AZ5RowGzMbqhvWHBcevh7VHWQbShjLFA0R3ww0CO8CUf3o9zzzSO/E6+/otubw5MrjX+Oc47Tke+ZE6HLpIerc6hzs1u3L79/xZ/Pr8wf0yfS09j75P/sE/K775fpj+j/6L/rW+cD4wfYh9LXxBvDn7v3tQ+3K7JbsrOxX7bjunPAN8131fvbJ9p73MvnD+uT7oPwJ/Tf9gv0i/ub+Xv8q/zz+/Pw0/G78Xv3r/p8ANAIFBJoG/wlyDckQWRRXGGQcVCBzJKooJSxSLpUvoTDQMe4yrTN8MwAybS8KLD8oIiXaIiIgBBxEFoMPGAnCAxr/9vor99Xy3+1u6c7lueIG4AjdddkX1nbT6NDWzgLOw80azQ3MAMuMynLLQM3+zpPQFdIo05PUNNe62n/eMeJW5UHoG+yz8Av1OPmc/ZkBTAWWCToOcRJpFhYa/xxNH6gh8CMFJjYobiqNLIcuBzDcMP4wszBfMM4vty4mLf0qbigpJj8kPyIfIKUd2RoyGHYVUxLXDocLkgiuBZsCdf8C/A74sfNA7+zq4OYi4+nfqN1z3MbbAdvf2ZLYoNdW14jX/dcj2TLbd91730/h/+Jv5B3mLuhN6lTsBe5J76LwQfKa82z03/QT9bb1P/dB+e76OfzL/SEALgN1BqsJ+AxtEOETNhcwGnQcFR56H8gg9SHzIk8j/yJUIgohqx56G/wXkhQ9EsARcRKmE/kUjBXEFO4SphCyDsMNPA2DC6kH7QHM+9/2hPOa8Ertrel65rbkHuUJ53PobOiu5/TnROrP7drwMvLf8dPwUfAo8SfzPPXm9vb3iPgJ+cj5ffoa+yv84/3X/6YBZANWBdcHvAomDRAOrg3qDEgMjwtECoYIqQazBNsC/QGnAisEPAVXBbUFMAfxCJ0JoAg4BlgD3gAF/u75IfUK8B3q2uN13o3acNj118PYzdrB3WTgDeK64/zmkuwn9Hv8jAN3CGQMaBAcFWIabR+9IpIjLyPeIuQiyiK7IW8fyhytGtwZqRoYHAodxBy6G/MaYRsYHSkfVSDaH3kdRBk9FL8PdAzwCXcHtAS1AR7+4vnH9YjyLfC27WLqYeas4gngjN5o3S3cMNv/2uPbAN454ZvkQ+cp6Wnrwe7T8oP2e/lC/OX+5wA9AuECvwIQAiEBtf/R/FH4kfP47+nteOyb6gXoAeVs4mfhZ+IC5TfoP+v57aHwcvNk9pz5Mv21AGcEmwhVDIIO+w/BEcwTLxbaGAgbyRsxGxcaOxneGAUZWRmQGY8ZpxkJGpYaTBuGHAMeIh/pHwAhHSKYIk0iHyEXH8wc7RpTGVoXYhSIEAYM6wbMASj9Avn69Lvw9evH5iziCd+Y3UfdRd0k3TfdE94D4M7iH+Zd6Tvs8O4g8nn1TfiN+k38wP0A/+X/PwDp/8P+/fzU+vj3PPQD8L/rMecv4rvdcdoE2JrWydYw2ETa79wI4DjjoubQ6uTvrPXL+6sBawaeCVMMvg8RFPUY4x28IaUjHCQDJDwjtyHxH+wdexsvGegXkRc6F7IWZRbOFoEYyBs0IIckxCfWKUArayyYLV0ujS2+KmcmJSGnG3IWDBG5CmoD7Pt79Pfs+uUw4JbbxdeZ1DzS+dAY0ULSzdOc1QjYOttE3+DjsehO7SXxFvSL9kj5yPxyAIEDIAVJBd8EUwR+A2UCLQE2/yL8U/go9NXvu+um6EjnyudL6f3pW+nD6LDpkOz58Nv1Svq4/TcAbwJeBQ0JYgyZDgUQRBG2EiUUmRRFE6sQ4A3HC8kKVwpTCSMHNAScAZcAAwJhBUYJoQyVD9kS5RZ0G/YfoCMRJosnfSggKTgpYSjoJbchUxyXFkERPwypBjkAlvl98yvul+kk5uvjU+KW4KjeEN0/3HTcsd1331PhOeMr5RLn+uh467buN/JJ9Zb3L/k8+v766/s1/UP+Ov6+/PX5l/aV80Lxw+8g77vuxu1z7KzrwOt47KLtL++i8Tn1VvkC/ef/kwLiBUgKVQ80FDkYBxudHHsd9h25HTocihk3FtsSyA/mDFwJLwWiAcz/8P+XAc8D+QUGCHQK9g3LEmkYQB08IMkh8CLNI9wjsiJ5IG0dtRmEFb8Q0wuNB/EDPgBH/Fz46fRx8iPxgfDY76run+wc6ojoauj+6EXpjOgb5wXmMeaC50jpr+pd68zrjuzu7fTv/PHl8n/ydfFe8Dvvtu3h6yTqiOgo52vmYOa25oXnzeiZ6kXtVfF79pb7vP+GAo8E5QYxCiUOIhJ5FTAX+hY5FiUWgxbFFsEWKhYYFUEUxhMiEwASjBAWD0kOwQ6SEAATlxSOFKgTOBMoFEEWKxiYGFQXPRWlEwETMBP1EpgRlQ+yDVcMZwtyCiYJcgd1BVcDRgF4/+v9Ufxb+v33YvXi8unwAPC77/jucO2767Xq1+re6wjtL+0G7D7qouic5zrnGed55vTkguK833Hd6tvJ2sjZ+tgl2EnX+taI18jY/dpk3njiZOat6Xjse++a8xj5d//qBZgLDBCvE24XzRtAIMEj7SV8J0spMitBLMQr3CkvJxslnSQ8Jd4lLCbxJeMkliNtI68kaibEJ2ooISjWJuAkoSIdIE8d0hl2FZQQvgsxB/ACrP7r+eX0XfDh7GHqgeiR5h3kbeE+3yjeVd5v34TguuB94MDg1uHu4xrniupP7XHvQvHA8uHzxfSK9Rj2XfZR9qz18PNe8X7upus26YnnY+aA5Rzlo+Wv5nPnJ+iM6dDrve4K8uT0d/Zn9yv5P/zk/00DwAUYByUIBgohDacQWBN+FCcUFxNpEs0SthMlFDEUIRTNE1ATFBMPEyITuhNKFXQXgBkgG4kczh3rHvkf/iBFIdQgZyAuIJUfTR4tHHAZthZaFAkSDw9WCwkHnQL9/nb8q/oc+SX3hfQD8k3wM+9p7nTtS+yG67jr7+s/6/vpkOhd58Xm9+aG54/n/eZZ5tLleuVf5SDlYeRj43HiP+Fz3/jcGtpo13HVj9S+1DjVR9U01YXV3tYg2i7f7eSH6uHvY/V7+8kCFAtJEzAaaB+ZI3snXisfL/kxDTOaMtYxhzFOMT4wIC4CK8kn/SUrJoEn9ijUKcopZimxKTYrRi2YLhsu4CuNKOskqyGNHnwaUxWlD1MJ7gKP/Tz5LPX58ILsDOgc5FThCeCb383eH93J2m3YYddY2H3aa9yH3THed9/m4RflROjs6tTsLe6g77bxSPSV9v/3h/iz+KH4O/ge91j1fvOx8bzvte3l607qSekB6fvoGeme6b/qfOzV7p7xRvQt9qD3Vfmm+6n+4wF/BOoFhAaeBwkKgA01ESYUxRWpFhQYsRr5HRUhcCOUJIgkUyTGJN4l1SZGJ2cnSCcEJ7cm/SVrJHYi7SDZH+IeAB5KHQccnRlDFpMSTw/QDHgKTQfxArP9Bfh58nztxOiW4/3dfNj00znRH9Asz3/NJcwxzK3NNtDj0uvUnda92Ibb7t504m3lCejJ6s3t+fCC9P/37fqY/YQAmANsBrcInwpPDLcNpg7GDtoNAQyVCewGPwRvASX+YfrQ9m30xvOR9Br29/cP+l/87/7nATMFzwj9DJ8R4hXIGPcZjxkdGLEW7hWZFRUVhRMGEbYOWw2CDH0LewpRCuAL5A4hElEUGRU0FUkWNxkKHegf5yALIM8dSRtxGc8XEBUcEckMDQlLBrwDngDY/GD4tfOu75/sk+oy6TLnvePS36LclNrq2VPautrP2vHaTNsh3BfeM+Gu5O7nr+rG7InulPDu8jb1SfdN+fj6F/z6/KT9hv2W/H37kvpE+sD6PPsT+236//lC+iv7cPzF/QT/MQBdAcYCbQQGBkQHQAgsCd4JdApZC2YMIA2eDfENHw5SDtgOuw/+EFkSYBPhE+gTnRMxE8cSvBImE9kTyhS+FWQWZBaoFZQUuROQEzYU9xSMFKQSixAtDwMOTQzFCZYGHAMKAJ79HvtC+Pj0LvHH7avrhuo/6ZTnwOUG5C/jgONd5H7l4eY86CHpuOlo6lfruOyI7m3wNfJ58xL0n/SW9eL2Cvim+OD4VPk9+ln7hPxX/a79Ev4A/xwAqADZ/5j9wvo6+Fn2WfUm9WT1pvXg9Q32SvYi9zj54vySATgG+AmTDKgOTxH0FLQYihs+HbQdOB1LHHobpRpMGUwXBhUmE0YSGRLyEY8RORGjEfASuBSXFgQYphj3GHMZwxk/GWIXQRQvEAIMaQgFBQ0Bd/z39x30EfFd7sPrZOlc57bldORe46vicOKl4j7jDORs5D/kGuSn5Dnmo+ig64Pu0vDL8lX1uvjo+xz+of/SAOIBLgN0BOMEegSQA10CDQFS/x/9svom+Of1tPSZ9J30TPS38zrzV/Ng9D32tPgz+yz9s/7p//YA6QHfAhEEWgUdBsQFtgRwA2wCSAL6AsQDIQReBP4EYQZECEcKEgymDVAPWxHBEzYWcBhyGnwcjx4MIMcg0CDxH3Ee/xzDGzEa1ReuFBMRew02Cu0GagMAAPP8QPrZ94n1FfPi8PDu7uzq6hfpjedX5qLlc+Wr5fXly+V65fjlcOdT6QjrYOxo7VruUu9P8JTxS/Mb9ZD2pfe5+NX51voC/ED9Q/7p/hn/5f6Z/qz+5P6W/lz9hPuj+Qb43/aS9nv3Vfl9+5D98f51/xsA3QH9BFwJrA2SEDQSHxPZE9gU7xVkFs0VqxTeE7kThRM3Ep0PqAyBCiUKzAs3DvQPhBCPEEoRlhP8FsAZlhq/GXcYkxcEF7gVnhIaDjQJ2gRZAZH+FfxA+dX1WfKs7/HtBO2u7B/svOr+6Ibng+aB5q/nP+k66gvqDelm6APp+uqF7bXvEPHs8d3yV/Rq9n744vne+kv8Lv46AN0BawJGAlMCsgJVA/8DQATYAw4DbQIuAhACcAGKACIAFQDl/z3/rv2Q+9j5/vi4+F74TPda9STzyPEF8mjzzPSc9RX2//YR+V/8JQCuA84Gjwl0DJwPbxKYFFAWHhgOGukbqB0vH/Ifxh9zHzQfyB5AHmcdWxxrGzkabBgSFpUTcRHrD9sOnA2RC88IBAaoA6sBif+p/Pv43vTQ8HXtq+qc5+rjQ+Cp3VDcwNtQ20Hae9j51t/WC9iP2RbbAt0C3/fgOuPX5d/oTez178/zq/cb+yf+NAEhBLkGDwnGCpsL/QtfDKQMcwy3CyoK8ge2BRcEUQNHA1oDNQMnA5ADfgQiBjMIgAo3DQMQ6xLZFVMYBhrtGgQbbRqIGT4YahZ1FJcSUxBjDTkKdAdrBTsE3APfAxIETQR3BBAFbQYKCFoJUAr9Ck0LMAs4CpMIywYfBcYDsQJ5Aan/VP2Y+tv3C/YH9drzKPIi8CbuXOy26nbpfehx54vmN+YR5iXm9uYs6Frp1Orb7Cvv1/EX9ZL46fut/uUA5gL2BDwHpgl9CwsMVgv5CZIInAcZB3cGcwU3BK8CEgHI/7/+/P16/fz8hfwu/L/78Prw+VP5WPmE+U75sPgj+Db4Rfn8+oz8YP2j/SD+of/uAVEEVwbLB/YIlwrHDLAO7w+7EG0RehLlE1wVPxYuFnwV8RQlFfIVshblFskWyBYnF9gXRRi3FzgWOxQBEpcP+wwZCoIG3AGF/E73cvI+7s7qe+cb5P7gBt5b25bZqdg+2P/XeNfE1sHWytdv2QbbXdy63W3fluFh5Hnnaeo47drvH/Jt9Ej3c/rP/VIB1gQbCB4L/g3kEDcUxReQGs4b/hvpG5kb7hrtGasYQhcFFhYVYRTnE68TYBPoEqYSdRL7EUsRkRDSDxcPWQ5HDd0LPwqhCKIHQQevBmwF4gM1AmMA7f7//ff8f/v8+RT5Avlq+fn5d/rb+o/7AP3X/ncAMwEKAcAArABlAKb/d/79/IL7Qfp8+fH4KfjW9kT13vO18vHxXPGj8IfvT+5+7RPt8+xE7fvtku5E74LwKPIs9HL2jPgJ+jv7r/xV/sT/5QAMAjMDQwQIBWAFowUsBosGWAa9BfQEdQRSBBcERwO/Abz/Y/0b+3z5bfhi95j2b/a69mf3UPg1+S36KPyd/xEE7ghQDXQQuxIdFQoYIBuiHeMevx4JHoUd9xzLG5UZbRYNE2wQ0Q7hDfwMuwtSCkQJ0gjKCPAILwl5CXgJ6wjSBwMGoAM+Aej+K/wD+cz1xfLu7yftJOoW55TkpeIE4bDfn95v3R7cKNv02oPbi9yf3bzeMeBx4kflb+je61Pv8fKy9lT6cf0lANoCcQVvB7wIcQmcCYoJVgn/CD8I2AbdBD0D7wLtA0AF+wXlBZsF+gWtB6kKDA4AEewSxhM5FAkVQRZyFzgYXxg6GDwYSRjvF7UWvRRgEkMQAg9kDtoN1Aw+C4EJHwgaBygGfgVdBY8F2AUgBhkGjAWcBK8DCwOVAiICpAHFAEr/dv1q+1/5g/fU9Tb0k/KK8Mbtt+oH6DrmU+XK5Ark+OIA4vThPeN65bznZumm6oTsk+8U8yb2ZPj6+bn7Kv4gASkEpAYICG8IqggsCbcJ8QnbCYgJCgmZCEcI1AdeB0oHtQcxCF0IAAhBB5MGJQbuBbwFZwWkBEcDpgE+AE3/r/7n/bj8SPvz+Yz4F/fc9Sj1GfVg9dH1HPY39p728/dt+sz9JgGnA0cFkQYUCBsKUww4Dp8PmxA/EZ4R/BFzEs0SxhJtEigSLxISEokRsBCxD4oOywx/Ck4InAZRBT8E3gKpANP90/oL+Kz15PNn8ozwHe6k67PpbeiA54zmwOVV5THlD+XH5J7kxuQx5d7l5uY96J3pF+sP7bLv//K69uz6gP8LBDsIQAxREPsTKRccGpIcWB6lH3wgwSBuIJMfTB7SHBcb5RhvFtET2hBtDb4JNQY7A58A8f30+uX3UfWi89XylfKJ8kzyzvE38afwK/D77/7v6++4733vCu9/7knusu7d75XxefNZ9RD3kPgp+hP8Kf5rAL0CzQTRBiEJbwtkDRYPshBfEuwTBBXCFV0WyxYJF+oWQxZHFSoUDRPiEZYQ/w7VDPoJvAZ3A14Agv2k+p33n/TH8T/veu137CPsZezP7Dzt+u0f74DwBfJ88770nvVC9tv2dvcW+LT4Xvkb+gn7HfxT/dL+kAA8AskDJwU/BmAH/gj4Cr0M+w3YDoEPIhDuEMsRbBKuEm0SrxHGENEPug5QDasL6AnYB1MFlgL6/6T9sPvU+Xz3Z/Tl8IrtyurU6ELnp+XY4+/hY+DE3xrgxeBh4ePhjOLB447ltec96vzsvO+O8mP1C/iC+iL9HABeA5kGignWC2MNrg4YEOMRHhSBFoIYABo6G3YcuR3lHvcfxyBbIckhFyInIvYhXSENIA8enBvfGD4W+xO0ERgPEgy2CEIF/AE5/9P8bPrh9yP1UvKc7ybtIOti6cXnTeYO5QjkN+On4pniAOOj44PkzOWo5/3pk+w079nxxPQS+Jj7I/+eAtsF0QhYC1ANvQ7UD+cQ1BFBEvYRFBHxD7EOQQ14C1IJ9QZuBOoBkP9i/TH73/iJ9m301PLK8UTxBvH18A7xOPE+8RHx6fDN8NPwsfAN8Pfu6O0+7Q3tXO397bvue++F8CvyhvRa91f6Yv2xAFUEMAgnDO0PbRPHFh0abh2PID8jKyVpJlonGCiLKGYonSd8JlwlKSSkIsQgeB7fG/8Y3BW9Eq4PmQxNCcAFBAI//pH6FPf282bxhe8g7rvsK+uq6YPotecs58TmUebU5TTlSeQs40PitOFr4XLhueEi4qPiWeNI5IXlS+em6V/sQe8o8un0nPeZ+jT+OwIJBjcJvwvQDasPfhEyE3YUAhXgFHIUABSlEy8TZxJkEUUQIA/2DbIMVAvfCX8IaQeZBs8F9QQWBFMDvAImAoAByADx//f+zP1//Dz7HfoU+Rf4//aU9dvzBPJ58IHvae/l74fwMvGS8ZbxxfHY8uf0tvey+jH9Cv+RAEgCkgQ+B+IJTQxQDugPcREkE7QU3RWsFlAXuBfRF68XbRckF5YWixXbE4kR7Q6pDPMKRgllBwsFBALd/kn8bPoM+bj3FvZe9OTyuvHQ8Ovv2+627ZLsluvm6mTq1Ok36aDoKej/5yPog+g56RrqAOsQ7DbtYO7s70TyVvV7+BD7CP3K/ugAjwOrBrsJ9gtaDWoOhw/REDASShPoEx0U/BO/E5YTfRNmEy0TthIFEhsRARDlDuYNFg1VDHALWgojCfQHzQaVBTAEewKpAOf+5fyR+iL42vXE88zx0+/L7ZzrV+lA59nlTuV55TXmA+e156DoGuoj7IjuXvGp9A34W/uq/uwB+ATYB4oK5wwFDwkR1RJUFHIVNxbMFjUXexebF4MXVBcVF50W3hWvFBYTWBGmDwoOYQx9Cl8IIQbZA7oBxv/x/Ur8wPpG+eX3bvak9MbyIPGb7wfuYeyV6szoSuca5hblBOT74h3i0+FJ4lXjyeRy5jToKOqJ7HrvCPMA9/b6lP7AAc0E6wcYC3IOzBHJFBsXsRjrGQ8bMBxJHToevB64HlweyB0VHVscvhv5GrYZIBhbFmgUbRKrEBIPcw2bC6gJvQfbBQ0ETgKKAJr+SPyb+dz2UvQY8hDwAu6862rpRedR5WvjvOF+4Jjfz94c3qndcd1q3cfds94G4LfhtePc5UjoBOvu7RrxMPT+9sD5wPwPAFADGAZiCHAKcQyXDggRYBM1FWQWEBdtF8oXXhjsGBwZ4hhdGK0XARdqFvgVfhWbFEYTyBGBEIYPnQ5/DQwMMAoKCPIFPgTQAlABf/9V/TH7bPkV+Pr2yPU19JvyePER8Vnx6PGA8uvyTfMh9JH1kffe+eH7Zf2r/gcAgwHvAkcEhAV5BgYHRAdFBzkHOgc2B/wGZAZfBfIDXQL0APL/Gf/v/Ub8Y/q3+KL3Qvc29+H2OvaD9f707/Rp9ST2xfZH95j34fds+Fz5Ufob++H7lPwH/X39Xf5t/zQAjgCRAHgAkwDfAA0BDwHnAIUA/P+h/93/iQAaATUB7gCdALsAWgEzAgwDtAMSBC8ERgSwBIgFnAaMB/sHCQjkB9EH6gciCB4IzQcxB2YGtgVoBYQFrQWRBQAFTgQQBG4EBgWQBdkFsAVPBRsFcgUSBoAGagbcBSAFXwSdA+YCLgI1Ab7/1v3r+2T6OPkE+JL2G/Xw8xjzg/JB8mbyvPIP8yrzMfNl8//zGPVj9nP3L/jC+DH51Pn7+pX8Of5d//L/UgDeAJgBWgIXA48DmwNnAyYDEgNNA8YDFATwA4gDMgP9AukCIwN0A54DfwNEAwED0ALMAugCFANGA4wDngOAA04DHAP8Au4C1wK+AsUC1gKVAucBMAGXAAAAcP/g/gH+y/xt+zr6b/n6+Lb4X/jt94v3i/cn+Cf5Tvp7+6X81P0S/y0AGwH2AcYClgNHBLME4QTrBO0ExQRgBMUDNgPuAvgCXgPiAycEEATBA2wDUQN9A/gDcQSLBEMEtwMwA7gCLgJ+AdkAbQASALj/Zf8G/2z+kP2v/Ob7TPvw+pn6EfpS+aD4K/js97z3nPe59yL4ovgv+fX5F/uj/FP+/f+vAX4DOAW1BgsIPAlQClMLTAzuDAMNtAwQDDELYQrYCVEJiwicB44GTQX1A8gC4wEnAV8Ad/9o/lP9Zfy++0z7+Pqm+jz6yfmB+ZD55/la+qr6qPpz+l36cfqx+gT7X/uY+4f7Vfsi+wb7C/sP+/D60vrW+s76nvpd+hj62fmk+Zv53vkw+lP6Jfrh+d/5Lfqf+gX7V/uI+3/7U/tI+2r7rPsY/Lz8h/1D/sf+NP/w/yMBqQIvBHcFgQaIB5MIpwnRCgkMEQ2jDcoN9Q1lDgIPdQ9lD+IOSw7lDboNyg3fDa4N/gzxC/UKNQqMCawIbwfRBSQEqgI+AcT/K/6W/Cr7BfoL+RH4QPe89m/2Ffam9Tr13vSd9G/0NPTG81rzHPPi8rbysfLY8h/zUvNz86bzJ/QU9TH2P/cf+LT4Evma+XL6dvtw/C39rv0A/lD+w/5m/xgA1QCPAUYC/QLBA6QEkAVqBlEHQggOCbwJSArCClYL8AtSDIYMugzuDPsM4Qy4DIkMXQwiDOoLsQtMC7oK8gkmCZAIMwjTB1QHqgb+BXUFJwXcBFgEpQP0Al0C0gEeAR8A//7O/Zr8UfsY+uP4rveF9lP1LfQ484ny9fFW8dPwb/Aq8A7wAvAc8HXw9PBo8erxkvJo8130afWO9rP3zvjY+cH6hvtE/AP9tf0l/mP+cv5F/gn+4P29/Zr9Z/3+/I78Tfxo/Nv8ff0r/t/+vv/4AIkCSwQABn0HtQjvCWAL/QySDuQPlhCtEHAQJRAIEBgQBhB6D5sOtw3XDAkMLQskChQJNgjCB4EHQwfABssFfwRhA7cCXAIpAsAB0gCZ/3v+d/10/HH7Z/pZ+W/4k/es9tH1JvWL9AH0hfMU867yefKP8rDyx/L48kjzpvNg9G71kvbS9w35GPrp+sj75Pw2/pD/ogBiAecBYQLjAlEDvQMqBHIEjgRhBP0DuAPHA/gD+QPPA7QDyQPoA+UD2wPjA/gDEwRBBH4EvwTrBOsExQSyBNUEFAVIBVUFUAUwBQcF7gTKBIcEMQTbA5ADewOCA1gDDQO3Ak4CBgLqAe0B3wHEAZsBUwHoAIkAMQCu/y3/lf7f/Sr9kfwQ/Jf7PPvG+hL6efk3+SH5OPlg+Vz5Hfn4+Pf49fjw+MP4XPgQ+Pn3+vf39+j36Pfw9wn4IPhF+Jv4YfmF+sH7B/0j/u7+ff85AEsBkgLfA8kEWQXSBV8G6AZRB4kHjAeQB9oHaQj2CFAJcQl7CWwJaQlzCXsJkAmpCYAJDwlfCG4HcAarBRwFrQRRBN4DXQPYAlgC8QGTASsBwwBHAL3/I/9p/qL9+fxi/Lb70frV+fP4WPjw96r3hfds9133XveI99X3S/i5+P74SPnT+a76uvvJ/KH9Mv6w/mX/UgBSAUcCBwOuA0oE0gRHBY8FxQXRBaQFYwU0BRkF9gS4BDwEigPpAooCbwJqAnkCjAKMAnACRAL1AacBXwEHAZoAPADe/2z/3f4o/n796vx2/AP8nvtf+yz77PqG+hT6qvls+Wz5jfmh+bP5y/ni+f35JPp5+vf6hfsK/JL8Rv0a/ur+m/8qAKEA/QA9AWwBmQHiARQCDgLzAeQB5QHqARQCagK6AuoCIQNmA7sDCQRFBHYExgQlBXwFvAX/BVEGmQbVBt4GugaiBp0GswbeBvgGtQYIBioFUgSTA7sCsAF3ACr/1v2T/G/7b/qJ+cb4HviR9yj3/vYC9yb3Vfd595r3sPfo91744fgt+Uj5XfmY+Q76ofo1+5f73vs//Oj8vv2c/mT//v+IAA8BxQGTAl4DDgSqBDYFwQVfBvsGhwf/B00IeQiSCLcIwwiVCDgIzAdFB38GjAWHBHcDUAITAdX/k/47/dj7jfqI+cr4Mfiw9033IPc093L3yPc4+M74fPkt+tD6dftS/Hj9xP4pAI8B5QILBAgF8QX4BhkIIgn4CYcK5AosC2wLngu8C7kLgQsuC/AK1grWCsAKTwqtCeAIEwhwB/4GfwbKBdwErQNIAsUAWf8L/sr8nvtf+gX5wfen9rL10PTg8+ryQvL08e3x8PHj8dDxvfHX8TTysPJH8wL03fTI9dP23ffc+N358/oQ/C39R/4z/+3/gQAbAawBKQKRAt0CFgNQA5UD1AMJBBsEJAQoBEEEZgSDBHkEWAQrBP4DtwNjAxADsAJoAi0C3AGCATAB/wDxAPEAxwBzADUAFwD5/9b/uf+Y/2X/O//z/oH+Ev7H/Zj9mv3T/Rr+YP64/hD/jf9hAGYBcAKFA6oEogVoBjEH6AeKCP8IVAlUCUgJQwkgCcsIXwjtB2AH0gZFBq4F9gQsBFwDlQK0Aa4AlP91/mb9VPw++zD6MPk++GH3jPa+9fz0YvTv85/zY/M78zDzN/NX85rz/vN39PD0dfX09ZT2a/dZ+FH5XPpg+2n8iP3V/kYA3wGPAyoFlQbJB+II+QkHC/4L3wysDV0O0w4GDwoPDA8YDwsPxA5eDvMNdQ3uDDkMRws0CgcJ1wemBnMFQQQRA+MBtQCY/5L+of3C/P/7UfvP+l366vl1+e34dfga+NL3iPdY90L3L/f99rf2cfZE9j/2TPZo9pP20vb79g73LPdw9873OfiV+Nr4IvmC+Q/6rPpX+wf8sfxI/QL+5/7f/9wAwQF3AhEDrgNPBOoEgwXxBSsGRAZXBnMGrAbYBssGiwY7BgsGAQYaBjMGQQZDBkkGWQZJBisGKgYsBiUGFwYABuUFugWCBSkFugQ3BLYDOwO9AkkCywE+AZ4A5P8s/4f+9f1v/e78avzp+2n7+vqj+nX6afpJ+hf68vnw+f75Evow+kn6W/ps+on6svrd+gD7HPsu+z/7VPto+3/7mvux+9z7KfyC/Nf8G/1L/XP9q/37/WP+5P5z//L/ZQDsAIMBIwLEAl0D2QMoBHoE6wRhBbkF/QUgBhwGAAbWBacFcwUlBb4EXgTqA2sD4QJHArcBRgHyAK8AbgAyAPD/p/9W/wn/yv6//uH+E/9M/2n/Wv86/yH/GP8R/yX/Vf+A/6P/s/+X/z3/2/6T/mX+MP75/aD9NP3B/Dn8rvs2+8j6g/qH+sP6FPs6+1T7evvC+z785fyz/YH+Lf+2/ysAkADmAC4BgQHcARQCHwIJAusB6wEQAkACbwKVArMCuQLAAuECFgNPA5wD2QP9AxQEGgQSBP8D7gP7AzAEcASYBJwEewReBFQESwRABCIE4AN1A/gCZQK+AQcBOwBi/43+2P1Q/ej8k/wv/Nv7tfuo+8H7+PtK/Kj8/vw5/WD9lP3M/Qv+Nf5e/oP+pv7B/s3+BP9J/4D/lv+a/4z/eP9//4n/pP+r/7P/u/+2/5n/ef+C/7T/7v8wAHIAqwDnADABlAH9AVMCpwLxAisDYwOFA4UDWwMIA60CTgLyAY8BLgHRAGQA9v+d/0v/FP/2/uv+//4c/1T/ef+S/7z/9f8+AH8AsgDUAAIBRgGRAdsBJwJWAmQCTgIiAukBtwGPAVYB9wBwAM//Iv+K/g3+r/1a/fP8ffwa/OP7xfut+5j7jvuB+4L7gvuB+377b/to+2L7bftr+2P7T/tK+077Yftt+4j7tPvk+/j77/vm++T7CPxP/Kb88PwV/Sb9Pv14/eT9cf4J/6P/MQC2AEYB4QF/Av0CXQOyAxYEfATXBAYF8wS4BGQEFQTlA78DqANzAx8DrgJAAgIC6QHnAe4B3QHQAdYB/wEnAkICQgIlAgsCHgI/AoACxwL2AgMDDQMTAxsDNwNQA1EDMQP/As0CrQKsAo8CSgLSATsBrgBMACcAHwDz/5z/Q//v/rH+gv6C/qT+2f73/v/+6P7Y/sf+u/6v/qT+fP46/u/9uf2M/U397PyI/DH88vvC+6H7i/tl+zb7Gfsa+yr7Rvtj+4f7r/vx+0b8ofwC/Wz93/1c/uX+a//z/3kAEwG9AVUC0wI9A5gD6wM3BIIEwgT2BCYFSAVcBW0FagVSBTUFHgUNBQAF5AS5BHIEDgSeA0UD/wLNAqsCeAI5Au4BnwFGAekAhwAWAK//Qv/T/mP+5P1f/eT8Zvzl+2P79/qz+oL6Xvo9+if6LPpU+ob6uPr3+kX7tPs5/Mb8Vv3n/Xr+G/+1/1MA8wCnAUoC4AJSA7ID+wMpBEIEWQR9BKgExgTOBLQEiwRmBCkE1AN3Aw0DogJAAuUBhwEuAd8AlgA5AOj/rP+D/17/Iv/c/pz+Sf7a/WD98fyM/Dv8AfzS+6r7jvto+zf7APvt+vP6CPsq+1v7j/vG+/z7Rfyr/CD9nf0b/oz+B/+h/zoAuwAmAYMB5gFJAq4CFQNrA6EDyAPlA/gD9QP0A+kD2QPKA68DkwN1A2EDNgPxAqgCZgIbArsBWQETAecAuQBqAAcAlv8k/6v+Pv7g/Zn9Qv3n/In8Lvzl+6D7Zvsn+/X62fq++qz6sfq6+r/6wvra+hj7j/sf/K/8Iv18/eD9W/4L/+j/xwCHARgClAIVA7ADTwTTBDwFjgXFBeEFEgZhBrAG5Qb8BvcG2wadBlgGHwbiBZAFJwXBBEwE0QNHA7oCGgJUAYUAxf8m/5P+Bv5//fT8dvwG/K77c/tD+xT77frV+t366/oC+xb7OPtW+337svvt+yP8X/yg/O38Wf3B/Sr+k/4B/3T/5/9ZAM4AMwGEAdYBGQJTAowCxgL7AjIDdQORA5oDkgOKA3wDXQMjA+8CwAKcAnoCQwLzAZQBMwHPAHAAHwDR/37/Lf/f/pP+SP7l/Y79U/1C/Tz9Lv0X/f/8AP0V/UT9cv2a/cv9C/5B/m3+pP7u/kP/kv/V/x4AaACwAPMALwFWAWIBYgFvAZ0BywHiAfcBCAIVAgsCBwIMAhkCKQIsAgoC5QHAAYwBZwFGASsB9wC3AF8A/f+T/zP/4f6r/mv+M/76/b39c/0//RX96fzQ/M/88Pwq/Wn9m/2s/b394f0U/lj+uv4Z/37/zP8fAHoAzAAdAWgBwwEXAmcCogLSAgkDRANtA4sDrwO/A80D4wP8AwME/wP0A+MDywOmA3QDRQMeAwMD2wKaAk8C0AFEAdEAewA3AN//g/8h/73+Y/4V/sj9hf01/e/8w/yu/KX8o/y2/OD8Cf0x/V/9jf2t/c79/f0i/lH+i/7O/hH/Tv9//5L/rv/K/+//FwAwADMAOQBPAFAAPgAdAAIA/v8RACEANAAxAAoAzv+n/6j/q/+h/4z/eP9u/2T/Tv8u/wv/6v7G/qj+p/6h/n7+O/76/cT9p/2U/Zz9qP25/c/91f3e/fL9Dv49/lb+b/5//ov+uP70/i7/Tf9k/3v/nP/Z/xAANgBaAGYAdgCyAAYBVgGUAbkB0gHtAR8CTAJ0AocChgJsAmMCcwJtAl0CQgIrAicCJgItAi0CHQIGAvkB9gHuAdYBpAFxATYB/QC9AHwARwAXANH/kf9i/zH/D//+/gn/Cf/5/ub+5v7p/gD/L/9A/zz/Nv9M/3z/vP/u//n/8P/l/+7/FABSAJQAvgDNANQA2wDnAP4ABwEQAQ8BDwEFAdsAqwB/AGwAXwBeAGMAWQA5ABUAAgDv/+f/2v/p/+z/9v/u/9f/xP+0/7D/rP+r/6P/l/+D/2z/Xv9b/1v/VP9D/xj/8f7g/vL+Bv8S/yj/Ov9T/3D/mv/C/+T/7f///wkAEgAbABkAAwDr/9j/t/+u/6r/rv+b/4P/af9P/z3/M/8v/xT/7P6//p7+fP5b/jr+Iv4C/gD++v34/QH+C/4O/hH+I/5J/nf+qv7V/vL+Ff87/2P/eP+a/7H/vv/E/93/DAAwAFcAfQCvAOEAFAFOAY0B1AEJAi0CQAJEAlMCXgJrAmICUgIzAiACGwINAv0B6wHZAbABhAFeAT4BGQHzAMAAgwBOACYAAQDv//T/7v/h/9r/2//k/+n/6P/m/+n/4f/c/+D/4//q//D/8//u/9b/wP/F/93/+f8PAAoA9v/q/9//y/+6/7n/zv/s/xcAIQAaAA8ABgD+//X/3//V/9v/3v/s/+3/1//L/8n/2f/t/wIAFwAMAPL/3v/X/+D/3f/g/+z/CwAhADMAMQAuADAAOgA9ADoALgASAAwAAADz/9X/xv+y/57/i/95/2f/OP8S/+7+2v7L/s7+0P7P/sn+tv6k/pj+gv5h/lL+T/5W/kj+RP4+/kT+R/5Q/mn+hP6i/r/+0v75/i//Yv+E/5f/of+t/8T/3//x/wAACAAcADAAMwAxADMANgA5ADcAJgAzAEUARQBJAE0AWgBjAGAAYABcAFgAYQBnAHQAiACqALgAyADcAPgAHAEsASkBJgEvAT0BTwFQAVEBWQFgAWwBgQGcAbQBygHSAdEB3AH9AS4CZwKkAsUC3gL2AgcDDwMFA/cC5gLIApoCXQIuAvkBzQGMAU8BBgG1AF4AAwC4/2z/Jv/v/sL+g/5G/gL+s/1p/Tf9HP0M/RL9F/0A/e/85/zv/Pr8Cv0T/RP9Kv1i/Zz90f0R/lz+k/7L/hf/cf/Y/y4AcgCnAM8A/wA4AXoBxQEPAl0ClgLBAtICygK2ApsCewJkAkwCNwIcAvMBtAFhAQIBkwAkAK7/Q//n/pn+Sv76/a39b/08/Qv94PzN/Lv8tfy5/Mn81vze/OD81Py9/Kr8qvy0/M784fzv/Aj9Iv1C/V39cf17/Yr9oP3M/Q/+U/6L/qz+y/7f/vv+J/9X/5j/1/8bAE4AdQCJAJ0AuADdAP0AGwFJAXgBoAGwAbUBsQGnAYwBcwFhAUwBNwEbARQBAQHYAKYAggBrAGQAbACHAKYAugDEAMcAxAC5AKUAjACLAJUAngCqAMcA2ADrAPAA4wC/AJoAgwB3AHwAhACXAKQAqwChAJUAqQCzAMAA2wD3ABIBMgFRAXEBfQGWAbkB4AEAAhkCNAI/AjICDwLZAaYBaAE5AQcB8wDmAOMA2wDHAJ0AdQBFABcA/P/o/97/xf/G/8v/0v/T/9j/3f/d/97/4//i/97/zv/B/8L/yv/H/6j/e/9T/0D/S/9h/2n/bP9k/0//Qf82/0b/Y/91/4f/iP+G/43/lv+P/4f/ev9x/2P/Qv8q/yj/Mf8u/yD//v7W/q/+kf5+/mX+Wf5Y/lT+T/46/jX+PP5J/lT+bv6D/qL+yP4D/03/g/+m/7T/v//J/9b/6/8HABwAKgA0AD8APAA1ADMAJAASAAYADwAWAC0ANgAeAA0ABAD///f//f8AAPj/8P/t/wIAHwAsADYAOgA4ADQAMwA8AFMAdQCBAHEAVgBIAEAALQArADgATgBdAGcAbwB3AIkAmQCgAKIAswDNAPUAHgFLAXEBjQGnAb8B2AHcAeIB+QEaAkACUAI4Ag4C2AG4AbIBrwGyAbkBtAGxAZMBYQE6AQ0B7AC/AJwAdgBPAEIAMgAiAAkA6f++/5n/gP9r/1r/Rf85/yv/Ff/w/sv+q/6b/oP+d/53/nr+fP6A/n3+fP54/nn+gf6a/sL+6f4f/1T/iP+v/9D//f8hAEsAaQCNALwA8gAXASEBEgH6AOsA4wDtAOwA5gDBAIEAPQAEAOD/wf+g/37/Wv8z/xb/9P7b/rj+nv6R/or+kf6O/oz+hP5//nX+df6A/nj+X/5T/lD+Q/4w/hX+AP7v/ff9Cv4e/jj+UP5X/m7+k/7V/g//Pf9f/33/kv+S/5v/qv/C/8P/w//R/9n/0//K/9T/2f/h/+j/AAAdADkAYgB5AIYAiQCJAJcAuwDmABUBJwEnASIBHgEaAR4BIwEjARsBFAEFAQIB/ADrANsAwACyAKEAjwCDAGoASwA8ADYAJwAdAA4AAwD6//P//P8AABUALwBBAEgAUQBeAIIAoAC8ANgA+QAiAUQBdgGfAbQBvQGyAbgBxgHaAe4BAAIEAugBzQHHAcgBwAGrAZEBgAFgAT8BJgEfAQ8B7gC8AIEATAAiAP3/5f/K/6L/f/9a/y////7W/sT+u/68/sD+sP6l/p/+m/6P/pX+lv6g/rT+zP72/hL/Mf9D/07/U/9i/3j/gv+V/77/4f///xUAJQA0AD4ATABYAHsAsQDbAPgA/wDzAOAA2gDhAN0AzQC+ALkArACPAGsAQgAPANP/mf9a/w7/yf6Z/nH+W/5H/i/+DP7p/dP9uP2q/af9nf2V/ZH9hv17/XT9ef1z/Xb9h/2h/cr9+f0e/kP+av6T/sT+7v4b/0j/gP+5//H/JwBKAHIAmADLAPYAEQEkATYBUAFeAW0BfAGXAbEBwwHFAbABoAGPAY8BjQGLAYwBfwFfATUBCwHuAMoAswCVAHwAZQA/ABkA/v/p/73/lP9w/1f/Sv9P/1j/WP9i/1//Zf9l/2X/cf+D/5X/tv/c//7/CAATAB4AIwA0AEYAYAB2AJYAtgDEAMIAtwCvAJ4AiAB5AHUAdgBtAF8ATQA1ABwA/f/b/73/qP+e/6f/wv/h//j/BwAXACcAKAA0AD4ASABGAEYAWABoAHEAaABPADEAEQAKAAYA///6//f/8//y//D/6//c/9H/z//d/wUAMwBMAGIAdACLAKAArwC9ANUA6gADARoBRAFrAX8BiwGJAX0BdQFnAWQBZAFjAVUBSAE0ARUB9gC9AIEAVAAkAPv/3f/P/7//of9t/z//Cf/c/q7+i/52/mP+Sf4t/hr+C/7z/d39xP2q/Yr9fv2G/ZP9kv2F/Xv9d/2B/Zz9wv33/UD+g/7B/vb+Pf+P/+v/LgBdAH8AowDEAO4AGQFBAWQBhgGpAbsBzQHXAd4B2AHcAfIBCQIQAggC8QHRAaIBbQE3AQMB4wC1AJEAbQBTAD8ALwAmABkACwDy/9f/uf+h/4n/bf9Q/yj/9P7I/qv+oP6P/nL+Zf5W/lb+Zf6C/qL+uf6//tj+9v4b/0D/df+t/9n/7/8GABgANABYAHkAmACqALwAxADIAN0A7AD4APAA7QDvAOoA6QDrAO0A5ADkAN8A2gDFAL4AuAC0AKgAmwCbAJoAnwCmAKwAsgDBANAA0gDCALEApAB9AFMAKgAXAA4AAwAIAPn/2/++/7D/rv/E/9f/4//P/7v/p/+i/6v/wP/Z/+//BQAcAC0AMwAvADwAQQBIAFIAYwB8AJkAnwCoALUAxgDkAPQAAAEBAQAB9ADoAOQA4wDWALEAkAB8AHkAbgBlAFYAQQAbAP3/4P/G/63/kP9x/0r/LP8V/w3/Bv/7/t/+xv6n/pf+if6C/oP+jv6X/p7+rf62/sD+2/7r/gP/Dv8R/xX/K/8//07/WP9m/3f/hf+Q/5z/n/+t/7n/1f8AAC4AUQBnAHYAgwCUAKcAqwC0ALMAuADBAMsA3QDjANYAvACgAJMAkwCVAJMAjgCKAHUAZQBGAC0ACwDr/9H/vP+u/6X/oP+b/4v/ff99/4v/sP/T/+3/AwAeADkATwBvAHwAcgBhAFMAPQAyADEAOAA9ADkANAAiABIAEQAZAB8AJwAyAEgAXwBqAG0AZgBfAFsAXwBmAHIAeAB4AGgAQAAlABMA///s/+v/5v/Z/87/u/+0/6b/kf93/2X/V/9S/1H/Uf9N/13/aP+G/7D/2//6/xcALgA+AFYAbgB/AIkAkACNAIgAkACSAIsAfgBuAG0AbgB1AGgAZwBmAG0AdQCDAJQAiwB7AHIAZgBYAFIAQwA0ACYAIgAiACkAMQAdAAcA6f/Z/8v/yP/C/7b/oP+N/3b/b/9i/17/Xv9d/17/TP87/y3/HP8a/yb/LP9B/1n/df+G/5z/tv/c//D//f8IAA8AHgAkAC0ANAAxABcAAgDl/9D/vf+s/7X/yf/X/97/2v/Y/+H/AgA0AGEAhQCfALcA0gDiAPcABQELARcBDgEJAfgA4wDXANMAyQC1AK8AmQCCAHUAbwBgAEEAJAAKAPX/5P/R/8H/tv+h/4P/Yf9L/zT/JP8b/xX/CP///v/+7/7k/s/+xv7E/s7+1P7U/tj+0f7t/gj/I/9K/3b/mf/A/+L/EwA+AGUAhQCxAOMAGAFXAXoBiwGIAYMBiwGbAagBpAGVAXkBXgFMAUcBRAE6AR0B/gDaAK4AhQBhAEQAIAAFAOf/xv+l/43/dP9d/1L/Q/87/zX/Of85/0z/XP9a/1j/X/9k/2P/cv+E/4v/iP93/2v/Y/9e/1f/Vv9c/2T/dP+B/4H/fv+F/53/u//P/+D/6v/k/9r/1f/a/+X/7f/v/+7/7v/m/9r/4P/k/9//0/+6/6T/mv+a/6H/nf+g/6b/pv+h/6f/r/+8/8X/2//t/wAADgAjADUAPwBUAHAAkwCyANEA7AAHARsBJQEgARQBAQH0AOcA3ADTAM0A0wDTAMIApAB/AFwAOQAoABgABwDz/9n/xP+9/7T/sP+u/6X/nf+a/5f/kf+I/4r/i/+O/5L/nv+u/7j/t/+x/7r/yP/I/8H/q/+V/5n/oP+1/8v/5//9/wYADgAXACQAMgA7AEMATABTAF0AcQCEAJYAkwCSAI0AhACJAKAAtgDEAMkAxQC+AK8ApwClAKAApQCwALwAwgDIALkArwCrAKkArQChAI0AdQBhAEkANwAfAAEA4P/L/7L/nv+F/3b/Zf9h/2D/ZP9n/1r/Sf9J/z3/PP9A/0D/PP8r/xz/Cv8G/wz/Hv8w/y3/M/8x/zD/M/9I/1X/av+B/43/kP+W/6n/wP/f//f/CAARABwALgBKAGQAdACPAKYArACqAJgAiQB7AGQATAA5AC8AHQAAAN//u/+g/4b/a/9X/03/Tf9Q/1P/Vf9e/2b/dP+I/5X/pv+z/7n/wv/J/9T/4P/i/+r/8v/1//D/6//m/+n/5//n//H/BgAdADAANwA6AEAAVgB2AJoAtAC9ALQAqwCoAKEAoACtAMMA3QDlAOEAzwC2AJoAfQBkAE8AMQAOAPb/4f/M/7j/nv96/1j/Of8g/xb/CP8H/wb/BP8J/xX/HP8m/zX/Of9C/1H/cP+L/63/0v/s/wsAHAAfAB0AKAA0AD8ATwBXAGIAaABuAHAAZwBgAF4AZAByAIEAigCQAI8AkwCcALEAwgDNAM4AxgCxAJwAkAB8AGwAVgBAAB4A+//g/7z/kv9l/0D/Ef/y/tj+wP6p/pr+k/6U/pH+kv6d/q/+0P7q/gr/JP8+/1f/bv+J/5f/mv+t/8L/0//g/+3/BgAdACkAKgAgABkAIQAxAEEAUwBcAGgAhAClAMMA3wDxAAQBCgEZASsBOgFEAU8BXgFpAXABfQGEAYIBfAF0AWoBVgFHATwBJgH8AM8AsQCTAHsAaQBXAD0AJQAOAAIA//8CABAAFAAaABQACgADAAAADAAdAC0ANgBEAFMAVwBUAE0ARQA7ADcANgA6AD4ARABCAD4AOAAmAB4AHwApADQAPABFAEMARwBMAFUAcACMAKAAqQClAKIAmQCNAIgAgAB2AG8AZABSADYAGAAFAPj/6f/U/8L/pf+M/3X/Zv9a/1P/Sv89/zD/Lf84/zz/N/8y/zP/Nv82/0L/Wf9z/4D/iv+b/6n/wP/K/9X/3//b/9P/wP+4/7D/tP+3/7P/sP/D/8//zP/H/7n/uf+0/7v/yf/F/7n/n/+N/4D/cv9u/2r/Xf9L/0D/Ov8v/yb/G/8N/wH/+v4B/wv/FP8Q/wr/CP8V/xr/Gv8X/xH/Ef8c/yf/Mv85/0P/R/9Q/2P/gv+i/8P/4f/6/x8ASAB4AKwA2AABASsBSwFjAXMBhgGaAasBsAGsAZ8BhwFtAVkBSgE6ASEBAQHeAMgArgCMAGMAQwAiAAIA5v/S/8H/p/+U/3n/T/8g//D+zf7B/r3+x/7Q/tT+2f7U/s/+yf7V/tn+2v7e/uz+8/79/hD/Hv87/2n/mP/J//n/FgBEAHIAnwDIAOUAAQENAScBPAFbAXQBkAGdAaEBogGaAY0BfwFoAT8BDgHhAL0AjQBfADIABwDf/7r/n/+V/4z/f/+H/4T/fv9z/2v/Zf9a/1X/V/9T/0T/Pv83/y//Jv8V//7+8v7l/tn+zf68/rb+r/6u/qj+qf6o/rb+zP7i/gf/Iv80/z3/Uf9g/2z/ev+I/5z/sv/I/9f/4f/e/+H/5f/l/+X/4v/X/8H/rv+f/43/hP9//3P/cf9w/3f/hf+S/6L/vf/j/wUAMgBkAJMAtADWAPIAAwEgAT4BUwFTAVEBVgFYAVgBVQFEAR0B7QC9AKEAiQB4AF4APgAXAPj/6//t//r/CgAZABwAHwAqADYARQBMAFIAVwBeAFwAWgBZAFQAXQBTAE4APwAsACMAGgARAP//8v/r/93/0P/P/9//9/8OACoAPgBVAGsAkgC9AOMA+gAJARMBFwEiASYBKQEnASEBEQH2AOMA0ADDALAAmwB3AFkAPgAdAA0ABgD5//b/8//1//f/7v/t//L/+//8/wAAAwAJABEAFAARAAcABwAGAAIA+f/q/9j/yf+w/6L/nv+g/5n/gf9t/2L/Xv9j/3f/e/96/3r/bP9g/2P/a/9j/2H/Yv9s/33/jv+Z/5z/l/+X/5r/lf+O/4T/gP92/2z/Z/9l/2b/X/9c/1X/T/9X/1z/Yv9k/2r/gv+V/6//wv/P/8z/x//M/9v/6f/x//H/3P/D/6b/nP+l/7f/yP/W/8z/tP+e/5H/jf+R/5P/l/+g/6r/tf/M//D/DgApAEoAagCAAJIAqgC1ALsAtwC0ALQAsQDAAMsA0wDSANMA0gDFAKsAjABzAF4ASgA5ACEACgDw/9z/y//C/8P/0P/b/+H/2f/J/7n/q/+d/4//ev9q/1b/UP9b/2z/c/94/3X/V/88/yT/I/8z/0v/W/9g/2T/b/+N/7D/2v/+/xQAIQAuADUAPgBTAGcAdwCHAJEAlQCdAKIApwCmAJ4AjwB5AGsAVQA8ACMABgDz/+P/4v/k/+b/3v/I/8H/vv+//7//v//B/8T/yv/L/9P/2v/e/97/1//a/9j/0v/N/8L/tP+5/8b/2f/h/+X/7v/z/wgAHQAyAEoAYAByAHoAhACQAJwAqwC4AMMAxwC+AKMAhQBtAFwATQA1ACQAHQAUABAAAAD5//f/9P/u/+j/5P/m/+T/3//e/9z/4P/q//H//P/5//T//f8KABUAFwAQAAAA8f/k/9//7P/p/+H/3P/c/+T/9/8FAAwAEgATABAAGgAhACcALgApACQAIgAkACkAMgA8ADoANQAqABwADwAMAP//+v/5/+j/1v/E/7T/sv+t/67/tP+7/8r/1v/j//T///8IABIAFwArAEMAUABRAE4ASwA/ADwANQAvACoAGQALAPn/7//v/+v/4v/V/8z/vf+z/6z/pf+c/5f/mP+n/7D/uf/O/97/+P8BAAUADQASAAUA6v/W/77/pv+f/5v/m/+d/5H/g/9x/1//VP9N/0f/Rv9F/0P/Rf9I/0v/Uf9b/2L/a/9r/2j/aP9s/1//Rv83/yz/JP8m/y//N/87/zP/J/8o/zz/Tf9h/2//dP99/5H/qf+9/9T/6/8GACEAQQBhAIAApADKAPYAJAFOAXQBjgGXAZ0BogGlAbIBsAGrAacBkwF+AWYBVwFIATwBOAEtARwBBwH3APEA8gDgAMkAsgChAJIAiQCFAHkAZgBIADIAKgAsACwAIQAPAPv/4P/N/77/sv+g/5P/hf99/3v/ev9+/4f/k/+j/7L/x//j//z/EAAdACwAQQBfAHYAkQCvAM0A2QDWAMkAuQCrAJQAfQBVACkA9v/I/5r/ef9q/1r/T/9G/zz/Sf9g/2f/bv9x/4P/nP+1/9L/6v8CABYAJQAtADUANwA4ADQAKgAaABAAEQAXABkAIQAtACoAJQAiACEAHwAZAB4AJwAsADIAKAAQAAQA/////wcAEAAPAAgA+f/i/9v/0/+//7X/o/+U/43/iv+A/2n/UP82/x//Df/z/tr+zv69/rX+wP7U/uz+Dv88/3D/k/+5/9z/6f/x//f/+v/y/+7/8P/0//v/AAD6/+//5P/o//b/CwAkADkASgBPAEcAQgBMAFgAeACQAKMArgC4AMUAwwC7AK8AnwCRAIkAjwCaAKAAmACDAGwAVABTAE8AWABkAF4ASQAtABoAFQAaACYAKwAjADMAOwBCAFMAXgBjAGMAZgBuAHMAewCFAI0AkQCDAHsAcABgAFUARwBDADoALgAgABsAEgAEAPn/3P/A/7P/qv+n/6X/pP+r/7H/rv+n/6L/ov+h/6f/pf+l/57/l/+Q/4X/g/98/3//hf+T/5z/pf+s/6j/qP+i/5z/nv+m/7T/wf/Q/93/7v8EABIAHAAqADwAUwBjAGcAXwBGACcACgD0/+X/4P/X/8r/vP+t/57/jP95/2D/S/9B/zf/Nv9G/1v/cv+A/4j/lP+p/8P/3//3/wcAGQAwAD8APgAzACUAGgAXABUAIQAwAEMAVwBiAGgAZwBvAHYAggCLAJcApQCpALQAvgC7ALgAsgCtAKIAiwCJAHwAbgBhAEAAJwALAOn/0f+7/53/i/9w/1f/Tv9G/zT/I/8Z/xj/Hf8p/y7/Nv89/0b/Tv9f/3r/jf+h/7P/xP/W/+j/7//3/woAIQBDAGIAewCPAJUAlACbAJ0ApwCwAMQA4gD4AA8BIgE4AU4BbgGKAZ8BsAG2AbMBpgGTAXQBUwE4ATEBLwEpARoB9gDKAJMAXAArAPr/zv+s/4j/c/9o/2H/Yf9T/07/Sf9N/1P/W/9c/1P/P/88/zD/IP8U/xn/Kv81/0T/SP9O/0X/QP9F/1f/df+J/5v/pv+p/63/qf+r/7v/zP/X/+X/5v/l/+L/6v/v/+3/7P/t//f/9P/t/+n/7f/v//f/9v/x/+z/7f/1//D/5f/d/+L/6v/w//j/9//y//H/7f/x//7/CgAMAA8AFQAYACQAPgBGAFIAYwBvAHIAcQBxAGwAYwBYAEsAPAA3ADAAJwAmACwAKAAwAC0AJwAgABoACQD6//3/+f/m/8j/qv+g/6f/n/+S/33/Z/9P/zv/K/8K/+n+2v7X/tT+1/7T/s3+z/7O/tX+0f7U/tr+6v4C/xj/NP9P/13/c/+V/7n/5f8EAB8AMAA5AEEAUQBhAHUAhACQAKIArgC2ALQAswC6AMkA3wD0ABIBJQE6AUYBSwFVAVYBTwFFAT8BPQEzAScBHAEOAQgB9QDkAMkAqQCXAI0AfwBkAEoAMAAUAP3/3f+u/5L/k/+j/6T/h/9v/1H/Nf8m/x3/Kf88/07/VP9F/z7/UP9u/33/dP91/4X/kP+V/5v/o/+s/6z/qP+t/6//sf+o/6f/rP+3/8b/1v/i/+v/6P/Z/8X/tf+x/7f/w//S/9v/5f/s//D/+P/8/wAABAADAAQABwAVABsAFQAUABYAGQAhACoAMgAzAD4AWAB6AJQAlACWAJcAmwCsALkAtwCzALkAugC/AMAAyQDOAMIAtQClAJkAiQCAAIQAewB8AHwAcABiAFIASABFADsAJAALAPD/1v/C/7H/of+L/3b/ZP9V/0T/M/8n/xz/Df/9/u7+4P7X/tH+2P7V/tb+2P7V/tL+yf7F/sP+x/7Q/uD+8/4D/xT/Jf88/0//XP9r/4L/iP+U/6r/w//a/+b/+P8MAB0AMABIAF4AfACOAJsAmwCZAKMAqwC0ALoAxgDTAN8A3wDcANsA0QC8ALIArACiAJIAggBvAF0AYgBfAFQASgA7ACwAHwALAAMABgALABEAFgAVAAcAAAACAP//9v/q/+L/3//d/87/vv+5/8n/y//L/8T/xv/G/8X/yf/I/8f/wf+//7n/r/+l/5n/iv+B/3j/c/9u/2b/Y/9f/13/U/9C/zv/Nf82/zT/Mv85/0L/Qf9B/0f/U/9T/1T/W/9a/1z/Vv9X/1b/WP9c/13/aP9w/4H/lv+r/7z/zf/a//D/BQAaAC8ARABZAHMAjwCxAMgA2wDzABEBLgFCAUwBWAFcAWABbAFvAWYBVQFRAVUBUQE/ATABHAEFAe4AzwCtAIMAVAAmAPr/2f+9/5j/eP9b/zr/EP/n/sH+nv6H/mv+VP5C/jP+Hv4Z/iD+LP4z/kP+Sv5W/lz+X/5w/n/+nv64/sz+7/4b/zf/Tf9j/3r/oP/G/+b/+f8XADYAXwCJAKcAwgDjAAEBGQE1AT8BRgFEAT0BMAEoAR8BGAEDAfMA8ADhANEAwgCtAJQAcwBWADwAIgAIAPL/6P/h/9L/uP+q/6D/nP+u/8X/3v/1/wQADwAfAEEAVwBlAHAAhQCgAMQA5gD/ABYBGgEbARYBGwEiASYBIgEfASEBIQEwATgBOAEuARgBEAEGAQEBAAECAf4ABAEAAfYA4QDGAKYAjgB/AGUAQAAQAN3/pf96/1T/PP8c/wv/+v7t/uf+3P7S/tP+1f7R/uD+7f7+/hL/H/8n/yr/QP9N/2P/b/92/37/kv+b/5z/pf+p/6v/q/+q/6v/rP+3/8b/2f/p//T//P8NACAAMgA/AE8AYAB+AJEAnQCaAKcAtgC7ALwAuQC1AKoAmgCQAH0AagBMADgAIwAJAPb/3f/E/7T/pf+P/3r/bP9d/0L/Iv8L//3+7f7f/tf+1/7I/rr+rf6i/qD+m/6X/o/+iP6M/o7+l/6W/pX+nP6p/rf+w/7Q/tX+0/7b/uL+9f4L/xn/K/9F/2D/cP+M/6X/wv/b//j/DQAkADcAUABoAHYAhwCQAJMAigCEAHoAeAByAG4AaABhAFAAQAAwACsALAAsAC0AMABDAEoAVABcAFgAXwBoAHIAfACLAJMAnwCfAKAAjwCEAIQAdwB1AG4AaQBpAGgAcQBvAGgAWABGAD0AOQBAAEAANgAqACAAIwAqADkASgBWAGQAcgCFAIoAgwB9AG0AWQBPAEMALgAWAAsA///p/+D/1v+8/6P/jP99/2z/WP9P/0r/Tf9D/zv/Of81/z7/Rv9K/0v/SP9E/z3/Mv8k/x//Dv///u/+4f7h/uv+6v7k/uL+1/7Q/tP+3P7r/vX+A/8V/zr/X/+B/6P/xP/f//H/BgAXACkALwA2AD0AQwBIAE0AXABjAHEAcQBxAG0AcABzAHcAcgB2AHMAcwB4AHsAgACBAHkAYABQAEIAOgAtABgA/f/l/9P/xP+5/7f/tP+w/7f/t/+x/6j/nf+g/6r/sv+q/57/kP+P/5f/qP+9/83/5/8IACIAMAA+AEcAWwBmAG8AewCEAI4AkQCYAKAAqwC7AM0A4ADuAO0A8QD5APoA+AD3AP0AEQEeAS4BOwFDAUkBSwFbAWIBZwFjAVYBPAEfAQ8BBAEHAQcBBQHwAOcA1wDFALoAqgCnAKYAoACZAJoAowCkAJ4AmQCSAI4AgABrAFMAPAAqAB4ADgD8/+3/3f/I/7n/rf+b/47/i/+K/4f/fv9v/2L/XP9V/03/P/81/yn/J/8x/zT/NP8l/xP/Bv///vv+9f7t/uH+4/7a/tT+0v7d/uf+7P7i/tn+2f7X/tX+3f7p/gH/Ev8k/y3/Pf9R/2b/dv+J/6D/vv/R/9//8f/5/wYABAAJABEAEwAUABAADAAHAAYAAQDv/9P/xP+x/6X/of+p/7P/vP/G/8z/1P/e/+7/8f/6//z/AQAIAAoABwAFAPf/5v/X/8f/vf+k/5P/hf9t/2H/Vv9T/07/TP9F/z7/Ov89/0H/P/9L/1r/a/9+/5X/q/+y/8L/0v/h/+v/5//r/+X/2//V/8v/vf+t/57/i/+C/3r/fv+A/4f/fv+I/6L/z//8/xkALwBCAGIAjwC+APEAGwE9AVIBZgGAAZUBowGrAawBrgGsAagBoQGWAYoBdgFjAVUBRgEpAQsB+QDlAN0A3ADRANMA1wDaANkA0wDNAMMAtwCoAJsAgwBmAFIAPAAlABMACQACAPD/6v/j/9D/w/+t/5T/ff9h/1P/Rf8//zv/Rf9K/1f/bP92/4X/mP+m/73/zv/K/8j/u/+s/6X/qf+n/53/jf98/2n/Wv9N/0P/N/8w/yX/Jf8g/x//JP8f/x3/Hv8m/zX/TP9d/3D/g/+S/5z/qf+5/7z/yP/T/8//0f/Z/93/0P/R/9H/2P/c/+H/5f/q//n/CAAPAAcAEAAiAC4AQQBQAGgAdgCHAKAAwADaAOcA4ADgAOYA2gDaAMwAvwCzAJsAkwCSAIoAfABxAG4AZABbAFIATABIAEAAMwAsACEAGwASAAAA6//i/9f/z//A/63/k/93/27/Yf9W/0f/NP8d/wf/6P7L/qn+k/6F/n3+gf6H/nn+bv5z/nj+jv6e/qn+w/7U/uj++f4Y/zL/W/9+/5//v//f/wgAMgBUAHYAmACyAMUA0QDfAOoA+QAEARYBKQE0AUIBTgFYAVMBRAEzASMBHgElASwBMgE0AS4BIwEXAQoB+QDjAMoAtwCiAJIAfgBjAEwAOgArACIAFwAQAPr/6//j/+T/6f/t//T/+/8DAAUACAATACIAMgA/AE0AUABIAEMANwAtAC0ALwAwADkAOQA0AC0AJQAaABIACgD9/+//4P/Y/8r/xv+1/7T/r/+i/5L/hf93/2//bP9e/0r/NP8e/wv/Cv8K/wz/Dv8Q/xD/Df8T/yD/J/8j/zX/Qf9N/2n/g/+a/6X/uv/R/+f/AAAUACcAOgBMAF4AZwBlAGEAbgB+AIoAlQCVAI8AfQBgAEIAMAAlABQABQD4/+7/3P/J/77/uv+9/83/1v/o//r//f8IABAAGwAkACcAIwAaABgAGgAiAC0ANgAsACIADgDw/+T/2f/M/7//rP+c/3f/YP9O/zL/HP8T/wT/9/7u/ur+4/7a/sv+sv6g/of+ev51/nH+cv52/on+kP6T/pz+q/64/tX+9f4d/zn/V/9r/4X/oP/D/+X/DAAzAFQAZgByAHUAfgCNAJoApAC4AMcA0QDhAPQABQEVASMBKgEvATQBQAFUAVoBYQFfAW0BigGfAbsB3QHvAe0B5gHZAdgB1QHOAbwBowGRAXwBeAFmAVwBRwEgAQAB5QDQALkAswCuAK0ArACpAKYAmwCKAIIAfAB1AHwAewBvAF4ASwAxACAADAABAOf/yv+l/43/eP9p/1b/Rv8x/yb/E/8J/wH///75/vT+7/7u/vL++v4H/xv/KP8w/zn/R/9W/2X/dv99/3n/cf92/3n/hf+F/4r/if+G/3//ev99/3b/cv91/3//d/9y/23/b/9z/3D/ef+J/53/pf+y/73/0P/a/+j/7P/0//L/9P/z//f/+f/1/wEAAwD9//n////5//X/8v/z/+z/5f/k/9z/2//S/9H/0f/O/8z/y//K/8T/v/++/8X/wv/B/77/s/+q/6r/qf+n/6X/nP+S/4D/af9N/zX/If8Y/xL/G/8d/yL/L/83/zv/P/9H/03/ZP92/4v/nP+w/8P/1P/0/xEAMgBMAGIAewCdALkAzADiAPQAEAElAUEBUgFTAVQBVQFYAVEBWQFsAXEBbAFmAWoBXgFPAUABPgE+ATwBQQE+ATcBLQEbAQsBBAH2ANsAvwCpAJoAiwByAFwARQA4ADMAJwAkACUAIQAaABcAFQAZABkAGwAhACAAHwAeABYABgD2/+b/1v/U/83/x//A/7r/p/+X/5L/mf+Z/5j/mv+Y/43/hv+A/3D/Z/9U/1H/RP88/zX/Nv87/zz/R/9Q/1j/aP94/4P/jP+Q/4z/f/+B/4j/jf+X/5v/n/+j/5z/m/+u/7r/v/+8/7P/rv+u/63/rP++/8j/5f/1/xAAKwA2ADEAMgA2ADUAOQA7ADAAKwAwACwAIgAVAAEA3//D/7X/sf+4/6v/nv+L/37/eP92/3T/bf9j/1f/R/9B/zH/Jf8e/yH/Kf8v/z//V/90/4v/rv/L/9r/5v/w//T/9P/v/+7/7v/l/+L/4f/s//X///8KABAADwATABoAKQA6AE0AXQBsAIMAmACrAL8AzwDaAOkA5gDmAOUA6QDwAPoACAEeASoBMwE3ATQBKAEaARABDgESAQ0BAQH/AAEB/QD4AO0A4gDbANIAvACqAJcAkACAAH8AeQBwAFsATAA4ACgAIwAfAAMA3f+x/4P/bv9P/zz/Lv8c/w//C/8J//7+8/7f/tP+zP7B/rz+s/63/rb+vv7G/tH+3/7m/vr+C/8P/xH/IP8y/0//Xf95/5r/wP/i//j/CgAhADYASQBRAFYAXgBwAIQAnAC5AMgA0QDTAN8A4ADeAOkA9wAIAQQBAAH/APwA+wD5APcA9QD7AAEBBQHzAOQAwwCuAJ8AjQBsAEMAIwAJAPT/1f+4/6j/nP+X/5H/iv+I/4D/h/+Z/5f/l/+a/6H/n/+W/4f/ff94/3T/d/90/4H/l/+x/8H/0//b/+n/+P8MABQACwABAAMABwAEAAwAHQAgAB4AJwAsAC0AIAAJAPr/8//t/+r/6//y//b/+P/9//n/6//R/7D/nv+Q/4f/jP+T/6T/q/+y/73/x//M/8v/x//b/9//8/8IABgALwA2AEEATABfAHwAlgCmALIAugDDAMAAuACtAKoAqQCjAKYArwCrAKYAowCeAJ8AkACBAHcAcQBsAHMAbgBhAFEARwA3AC4AJQANAPv/6v/b/8D/r/+c/4j/bf9v/3f/fP9//4L/hv92/2v/cP+A/4//kP+W/6H/uP/N/+P/9f8SACAAHwAdACEAHwAbACIAGAAVABoAMABGAFsAbAB3AIUAhQB7AHEAcgBzAGoAaQB1AHcAeAB/AH8AgABzAGcAWQBSAEMAMwAxADgAPABCAEoAUQBOAE4ASwA6ACQADgD8//b/7//s/+L/1//N/8v/y//J/8f/yf+5/6r/m/+P/4j/ff+G/4j/kf+i/6L/qP+b/4T/dP9u/3b/ff98/3f/Zv9V/0b/Tv9Z/2n/c/94/3n/ev95/27/Xf9V/0n/RP8//zj/P/87/zX/P/9J/1P/Uv9I/zr/Mv8+/z//R/9V/2//g/+V/6L/pP+o/6//w//N/9v/4//x//r/AQD5//r/5//b/9P/yf/G/7v/sv+0/7f/vf/U/9v/5v/l/93/y/+4/6j/p/+z/8L/zf/l/+7/7f/z//r/8v/i/9L/wv+w/6P/jP+R/5z/pP+h/53/m/+j/5//o/+h/6j/s//G/9//9v8JAB4AMQBCAEQARwBLAFkAZABgAGMAbAB0AIAAeQB2AHkAjACOAIkAiwCOAIwAigCNAIwAhgB9AIEAkwChAKsAugC8AL0AxQDLANEA1QDeAOsA7wDjANsA5QD2APoA/wALAQkB+gDkANwAygC0AKMAjACNAIkAhQCPAKIAswDFANIA5AD4AAMBAwHyAP4AEAEtAUQBVwFmAV4BUQFFAT4BMAEgARkBCwH8AO8A4wDgANkA1ADHALoAqACcAIEAdQBeAEwAPAA2ACwADwD7//D/4f/N/8b/uP+h/5P/kf+G/3P/a/99/4n/i/+H/4b/hP97/3f/cf9w/2v/dP94/4P/hv+S/6L/s/+1/7n/wv/K/9v/5v/U/8H/p/+h/4//hP96/27/a/9g/2D/W/9Z/0z/PP8z/yf/G/8J//z+6v7f/s7+x/7B/r7+v/7D/s/+1v7f/u/+Af8O/yP/P/9a/3T/lv+2/9P/4v/o//r/BgAWADAATABpAIUAlACmALcA3AACAScBTwGAAagBzQH8ASMCUAJuAn0CiwKWAokCbQJOAjACCALWAbABkwFvAU0BMgEKAeEAsgB5ADwA+/+5/3v/UP8v/xL/8/7Q/qX+eP5K/h/+Bf7n/cj9of2R/ZP9kf2N/YP9f/19/Xn9e/2K/Zf9nv2m/b392f3t/QL+Gf4u/kr+af6P/qv+yP7k/vv+Cv8f/yz/OP9K/3f/tf/o/w8ANABRAGcAhQCdAKcAqACiAKcAngCZAI4AiQCFAIMAeQBwAGEAUgA+ACMACgD1/93/1v/O/7f/pP+c/5j/mf+N/4D/Zv9C/yT/Ff8H/wP/+/78/v7+AP///gX/Cf8R/yP/Ov9c/3z/nf+v/8X/3f/1/wkAKwBcAIsAqgC/AN0A+wAeAS8BRAFgAX0BngGvAcYB1AHYAdMB1QHPAdEBzgHKAb0BnwF3AVoBSQE2ASMBBAHlAM0AtACkAJUAfQBdADcAFQD7/9f/tv+n/6T/pv+n/6//wf/a/9j/1P/I/8H/u/+0/7v/x//g/wMAKgBHAFYAXQBiAFoAVgBaAGEAggCjAMgA7AAIARUBHgEjARMBAQHyANcAxQC9AMIAxgDOAMsAyADBALUApwCMAGsATAA5ACEAFwAHAPb/0P+d/2L/M/8P/+r+wv6k/oj+ev5r/lX+L/4Z/gn+B/4H/g/+GP4p/jj+Qf5A/kf+Vf5m/nb+kP6j/rv+4/4D/yT/Qv9g/33/lv+h/6L/pv+1/8v/w/+7/7P/v//F/8z/4P/7/xcASgCCAKsAtwC1ALUAvQDLAOQABgEeASoBMgE5AT0BJwEIAd0AuwCfAIsAeQBoAFsAVABOAEwASwBGAEQAOgA1ADMAOgAzADEASwBjAH8AigCNAI0AhwB6AHEAaABeAFYAaAB/AK4A0wDzAAcBCgH/AOYA2wDaAOkABAEbASIBKAEjASYBIwEmAR8BHwEnARsBBwHoAM8AvAC+AMMAvgCwAI8AdwBXADYA/P/E/5z/i/90/03/Jv8X/xr/Ev8G//7+AP8P/yj/Q/9Y/1n/Wf9b/2D/fP+Y/6j/vf/a//H/BAD4///////9//z/+v/3/+r/6f/l/+T/6/8FAB4AKgAmAB4AAgDs/9v/w/+0/6T/ov+n/6n/qf+j/5j/hP92/1b/P/8s/yz/I/8f/yL/KP8z/0b/V/9Z/1//Y/91/3//jf+r/8b/6P8BACMAPQBRAFcAYwBwAHkAeAB1AGQAWgBMAEEANQA6AEkAPAAaAOL/sv+I/2z/Sf8t/x7/Gf8X/w//CP/7/u7+6v72/gb/Jv8//0r/T/9g/4T/nv+//+T/CAAeADQAOwBKAFEAYwB4AJkAxADmAPwABAEHAQQB8QDYAMgAwwDJAMMAuwCwAJQAdwBoAFUAUwBAABoA+P/d/8b/t/+q/5n/hv9z/2b/aP9j/2j/b/97/4b/j/+b/6T/tv/F/8z/2v/t/wYALQBTAG8AgwCIAIYAhQB7AHUAbgB6AH0AgwCFAHwAcwBaAEUAMQAaAAAA3//F/7D/lf+E/33/if+U/5P/kf97/1//Q/8h/wX/4P7M/sX+tv6n/oT+b/5W/j/+Kv4R/vb93/3I/bT9nf2H/XL9aP1w/Yr9rv3G/c/90P3E/cP9x/3P/dz99/0g/k3+df6X/r3+4/4G/zn/fP/Q/ygAaQCQAL8A+wA8AXsBwwEWAlkCigK5AuYCEgMpAz4DcAOfA8AD3APsA/0DDAQlBDkEUwRzBH4EdARbBD4ECATBA4ADSgMqAxwDFwMAA90CqwKNAmkCSgIpAvMBvAGQAVYBDAG9AIIASAAUANv/qf96/1n/Nf8P/+X+x/6v/qX+n/6H/nH+XP5E/jH+MP4+/j7+I/4B/uX9yP2t/Zr9jf2P/Z39rP28/cP9yf3U/eD96P3v/en95v3b/dr94f33/Q/+LP5a/n3+rf7R/vX+Dv8q/0L/dv+k/+T/KABrAK8A6AAkAWcBtgEVAm8CxAIWA1sDnQPaAxcERwRyBLQE6gQKBSUFLwUqBR0FBAXkBLgEiwRXBBMEtANeA/4CjQIXAp4BJwGvAC0Anf8R/3j+5v1h/ej8hvwx/N/7h/sq+976kfpU+iv6FfoA+vP5+vkD+hL6Rfp6+rX66/ou+2r7ofvb+xT8UvyU/NX8Ef1U/Zn93P0p/mv+of7K/vD+F/80/z//Ov8h/wv/9P7p/ur+8/7s/vH+6f7E/pP+f/51/nj+gf5+/nH+Uf4t/hD+CP4Z/jr+bv61/vv+Jf8k/xr/LP9J/4r/4v9ZANsAWQG0AfgBMQJyAr4CIQOxAz4ErwQLBWIFwAUVBmYGwAY0B7AHEAhUCGgISAj0B5UHRAcaB/0GzwaQBjAGtQUnBYYE6wNuA+QCUALDAT0BlQDV/xz/lv4k/sD9Y/0V/c/8avwI/LX7dftC+zD7Svt7+6f7w/vg+//7Hvwz/FH8dfyW/L388PwY/TX9Rv1p/Zj9y/0D/i7+UP55/pr+pf7J/vD+C/8f/zH/Ov9A/0r/VP9h/3X/lP+t/8f/3f/4/wUACgAMABwAOgBSAGMAdwCFAJkAuADjABABQwF1AZMBngGVAZsBnwGoAbQByQHpAf0B/AHuAdkBvAGOAV0BQAEeAe0AtABsACYA5v+Y/zr/0/5u/gn+qv06/cv8ePxR/Ef8Pvw8/Df8O/wy/Cv8Kfwz/FD8Z/yZ/Nb8E/0n/Sb9PP2H/ez9Tf6r/gz/df/j/0gAmwDZAA8BSwGwAS4ClgLSAv8CUgO4AyoEkQT7BF8FpwXoBToGkga8BsUGxgbPBtUGvwaeBoAGSAb6BZ8FVwUQBbYERQTNA08DugIkAp0BJwG9AEEAr/8d/5b+Kf6//WX9FP3C/JX8k/yj/Lj80fzc/N/85vzq/O/8/PwH/QX9/vz4/A79N/1u/ab9zP3m/fX99v0C/gn+Bv4E/gb+Cv4O/ib+NP4y/hn+8f3a/df98P0P/jD+M/4k/hT+Fv4q/jP+H/4B/vD97/0G/jf+d/6m/q3+vP7f/hj/W/+f/+H/HABRAJEA5wBeAesBgAL8Ak0DiAPNAxwEcwTKBBoFZwW/BRwGbwa5Bt8G0gapBoYGgwaGBoUGYQYbBrMFUQUABZoEHwSPA/ICTwKMAcgAIACj/zP/yP5S/r79IP2P/CT82/uq+3v7Q/sr+0D7X/tR+w/7vvqB+mz6ivrK+hL7T/tn+377qvvz+zb8bfyi/Mz86vzy/P/8Hv1P/YP9xv0H/ir+Qv5b/of+sv7H/sX+1v77/h7/Nf9N/1v/SP8g/w7/IP9P/4T/qv/U/+r/+/8JADUAdQCsAMgA1wDzABcBNgFtAccBGAJKAm4CpQLjAhIDLANAA1EDhQPjA14EvATWBMUEtQTOBPUECgUGBeAEjgQZBLsDfwNcAxYDswJHAt8BcAELAZkAEABv/7/+Ov7p/ab9Vf3x/IH8Hvzc++H7FPw7/Cv85vuc+3z7qPv/+1v8qPzl/Bj9V/2//TH+jf7B/tD+w/7L/gX/V/+0/+n/6f/P/7X/yP8GADsAQQAjAAcA7v/t/wwANQA/AA8Aq/9l/3b/pf/N/+P/yv+S/z3/Bf8A/xX/E/8A/+b+yP65/sj+9v4R/wj/BP8j/2T/nf/s/08AlQClAKgA6ABgAecBUQLFAjMDawN3A54D8wNeBMEECwVSBYIFfgVwBYIFpQWXBWkFPAUKBb8EaQQbBMQDRwPHAl0CHgLuAakBTAHrAF4Asv8r/93+yP6n/m3+C/6z/Wn9Jv0D/QL9//zd/L/8tPzL/Pr8Lv1f/YP9lP2Z/cj9Dv5N/nX+lv6j/rz++P5H/6v/AwBEAF4AdwCjANcAGwFXAWMBSAEOAeIAygDGALIAhgBIAAQAxf98/zn/9/6p/mT+E/7D/YP9Qv3b/G78G/zz+9b7w/u6+6P7d/s3+xT7Kftb+5b74vsY/B38/vsB/Cn8P/wp/Az8Dfwu/FP8dvyM/Gj8//ud+677N/zI/Cf9iv3//ZD+PP8RABcBBwK+AmIDJwQSBdwFjwZFB/AHfAjzCF8J0AkvClkKZQpzClYKAwq+CaoJaAm9CL8HqAawBcwE7QMgA1sCdgF4AJn/B/+x/nD+Sv4W/vn96v3t/Qj+Qf6G/rv+2v7R/q3+mv67/uf+Iv9M/1T/Zf+b/9z/BwAYAPj/v/+L/2n/Q/8Q/7v+VP7u/aD9Sv3u/Lr8sPy2/L78ufyq/Kn8xvzw/BP9Lf0c/fn87/wG/UX9if2z/bj9wf3t/Sb+gf71/lH/mP/h/yIAQgBmAH0AjAB/AEIA6v+a/1j/+P6I/iv+zP1K/cD8S/zh+3b7/vp5+gz6tvlY+QX5+/gs+Yf5CfrG+pT7ZPw3/Q/+JP9zAOsBcgPjBBgGFgcHCPMIvwlZCtAKMguWC+sLFwweDP0LkQviCjQKowkyCaoI1we/BnUFOAQbAyYCVgF7AHX/Vf5U/ZX8OPwO/Or7tfte+wr70/rN+tz65vrg+rb6evpC+jj6WfqW+tX65/rx+hP7Sfua+x/8sPww/ZD94/1E/rX+RP/b/2cA1wAnAW4B1gFZAuUCXwO1A8IDnAN+A4EDnwO0A5QDOAO0Ai8CzAGfAYwBZwEaAb4AZwBOAG0ApQC5AJsAZwAoABQARgCKAMAAzwChAFYADQDm/7b/X//J/u/9/vwv/KL7PPvX+kX6evmY+MD3KPfk9t327/YB9xj3PPdu97/3Ifik+Ef59fl/+vr6lvs5/L38Cv1Y/e/94/4LAEQBhgKzA5kEOgWzBUoG/AaWB/YHSQirCAMJQgmFCfMJjgo4C78LHQxvDLAM6gwkDVgNRA3GDNgLxArDCdcI1we2BlkF1ANhAhkB7P+y/mj9/PuV+lH5TfiK9+32PvZh9ZL0BvTE85zzgfNn8zjzE/Mr85/zbfRP9S32Evf29+D4v/mb+mP7FPy5/JH9sf7Y/6AAEAFjAcIBQwL3AuQDvAQ5BWwFnwXuBQ0G4wWVBUIF0gRKBM4DfQMgA4cCzQE5Ad8AkQA8AOv/lv8R/3n+Lv5c/vb+qP89AN4A1wFUAygFGgcRCQwL/wy/DkAQnxHVEp0T4BPGE3ET1hLbEYsQ+g4kDd0KOAiBBfMCXACg/QL70Pjy9h71NvNf8drvp+7R7Xntau1c7UXtYO347efuBPA08Wjyg/N79HX1hPaK92v4Ifm1+fT51PmD+Vb5PvkU+dP4nfhz+D74B/je9+n3AvgP+Bn4SPit+Bb5XvnP+bv6N/wc/iEAEALcA6MFjQewCfoLIA7XDwkRpRHUEZQRzBB5D9YNUwwuC2kK0QkmCUIIUQe9Br0GKwe/Bz8IgAinCL8I7QhuCVUKWwsGDEwMPwzqC6ELpAvEC8ALbQu6CtYJ1AiWB/oFJwQ5Aj8Ad/7V/Pn63fjj9kL17PPb8hXym/Fn8VzxcfG48R/yifL48pbzT/Tf9CT1HvXw9MH0mvRy9Fz0PfQF9K7zPPOr8v3xbPEC8djw4vD38A/xDvEA8Rbxa/H/8cDyqPMH9dH21fjY+tz8IP+OAd8D5gW1B3YJYQuBDaUPfRHGEoMT5RMuFH4U0RTdFFIUVxNQErERkhGzEbQRbxEbEdAQrxDZEFgR6xFaEqYSpxJPEr4REREYEKwO5QwDCzcJqQc8BpkEnQJmADP+Ovx4+rL42Pbq9OfyDPGb76Lu+e1k7fbs0Oz67F7t9u3B7rjv5fBz8kv0GPZg9yP4tvhc+f/5ifoU+5H70PvL+7H7lvtg+xL71/q3+qr6Yvrt+Zz5cPlD+RD57Pjq+CD5evnv+Vf6n/rc+kH78Pu8/FX9kf2c/aD9q/3H/fD99/2e/Qj9dPwR/Oj74fsq/On83f3R/tn/JAHNAqwEmAbACHELYA4PER4TpRQDFnwX9hhMGk4bwxtyG1Ua5hjwF6MXLhflFd8TnBEzD40MpgndBmkE2gH+/lL8Uvqm+Mr2hfRV8rPwju+p7gLure167QPtW+zk69vrKex47K3s+Ox97QruZu6g7gfvte9f8Arx1/HS8tHzwfS79en2f/hs+mb8OP79/8gBmgNHBa8G4gcBCTcKiQvmDCgOCQ9vD5wP0g8oEGwQPhCLD6IO3w08DaYM7gv6CtkJrwjFB0kHHQcJB/cG+AYyB54HBghKCE8IIwgBCNEHQAdABj4FbgR1AwsCgQAu/+T9Ofzw+YL3fvUB9ADzevJf8jfynfGu8BbwK/Cd8DTx7/GQ8hbztvOH9Gb1GfZZ9m72xfZL97z3+Pca+BX47ffr90P43viM+Qz6F/qt+W754vk2+zT9Hf+PALUBugJgA+MD0QRFBs0HHglXCpsL2AzkDb0OgQ9qEGgRWxI6E9cTzxMoE3ESyhEUESIQAw/RDYAMEgvBCd8IhghdCCII5gfDB4IH8gY1BnEF2QRhBNwDDQMCAsgAiv9u/mn9evx7+0v63PhK99/1zPQC9FTzgPJ18Xbwtu9S70nvXO9V7yrv5+6N7i3u5O3D7cftF+6c7izvfe+d78nvO/BA8bbyCvTd9DH1T/Wx9Zz24Pci+Ur6Pfvn+2r8Cv0Q/lf/ygBMAvcD0QWjB1cJ0go2DI8N1w5YEHIS9hQnF4wYWRndGVQa4xpqG54bYBvAGtUZ2BixFz8WjBQME9YRtxCtD54OLg1GC2AJ8wfpBrQFAATRAaH/pP3p+3v6HPl193D1ZfPS8fPwlvAh8BDvhe0U7ELrM+uN67jrquul683rEux07NjsMO2G7Q/u6+4U8FTxTPIM88fzjfSA9dD2lfhd+q/7rfyk/Zz+X//1/3gAGQHJAV4C3wJ1A+sDFgQpBGwE4QRfBeoFWgaOBpwGqQaqBpsGggaJBtsGawcXCM8IkQk4CqoKHgv8C2ANvw7VD6UQTRGzEdER0hGtESURQRBiD9UOdQ6rDUkMeAp+CHIGbQT2Ai0CbgE8AKX+4Pw4+9T5vvj593b3xPaL9QL0ZvLM8D/vBO417aHsO+zk61/rdOpe6YroH+jy5/7ncuhU6W/qleu27Anunu9O8fDyfPQT9vz3TPry/IP/jQEIAz4EeAW2BjsIMAqTDCAPLRE9EncSUxI/EmsS1hKAEwYU2BPrEnwRBhD4DpAOmQ6LDiAOhA0aDSANeQ38DVsOLQ5yDbIM2wwnDsQPPhDYDhYMTQmKB94GoQYgBtQEkQKh/538Hvpy+Fn3hfbQ9Uv17vSF9ODz1/KA8XrwefBe8Z7yqfMh9AD0lvNU83bz7vOX9Bf1ZPWV9Z71lPVG9Xf05/ID8aDvGe9A75Pvf++17lvtwus86jrpK+n46THrZ+ye7VbvovEc9C726Pcp+sf9rgLYBzkMYg+WETwTnhTjFV0XGRmHGjsbRxtBG3kbyxvzG9AbnhvVG+Ecjx4ZIIYgkB/PHR8c4xoOGqAZPhknGMYVSBKgDsUL+wloCDwGkwPtAID+RPwH+qD3CPVK8rzv2O327M3smOzX64fqO+ld6O/n3ec/6Evp2+pl7HntCu437kPue+4N7wjwR/GC8pbzavSh9AL03fL68bjxCvK48sfzD/Ui9q/2v/bc9nf3gPiv+c36sPuT/Kz92v6w/yMAgQD6AKIBXgI9A2cEowVbBkoG7wXQBf8FbAYhBwoIFgkdCvEKqQuFDKkN6A4sEKsRrxNRFjwZqhvbHNccjxz1HCQefB9EIOsfNR46G3IXjhP1D9cM2wl7BqQCqf74+uL3WvXp8lXw/e1l7IvrLeu46szpbejZ5m/lUeR/4/bi3eJW4zTk9+Q45e3kbeQx5PDkKueP6k3uoPFZ9H/2X/h1+iX9YwC5A5UGmAgQCoALNw0JD1UQyRC/EPMQuxG7Em0TeRPxEu8RgxAAD6kNowypC5IKcglCCPwGkAUxBCoDpwLIApoDwQSZBY8FywThAzYD/QIdAxEDlwK/Ac0AKQDv/8X/IP8N/rb8ffvh+hv73/uW/MH8Efyt+jz5Zfh6+IH5Dfti/Nz8VPwG+3L5Z/iw+E76Z/wM/o3+wf1R/Ej7FftV+4/7lvsh+//5qPiy9x33rPZd9j/2gvY29yz4W/nJ+mz8G/6Z/w0BqQKABHsGjwiFCu0L0gydDYgOLw9LD+YObw5sDv0OlA+JD9AOhQ0kDFALMgsIC2YKsAkeCWYIhQfbBlgGrAXFBMADowKoARABswAgANv+t/xK+lL4IPeE9iH2kfV59KLyHvCV7dbrSut96/XrU+xC7LvrOes66+PrKO207jrwefFM8gjzQPQY9ur3S/l6+qL7jvxN/V3+v//9AN8BdQLjAk4DyQNiBDkFWgZxB00I9ghnCdYJgAqPC+UMVw6jD8gQ/hEqEwgUjRT1FFsVuBXqFdwVVxVHFPMSrxGQEGwPAw5QDKUKQAkhCBEH4AVcBLQCjgEUAcMARACU/7b+dv31+6v64fl2+RT5yvip+Fb4dPdK9jL1PvSE8+HyPfJ98YbwVe8G7tTs9Ot160XrI+u36v/pg+lz6aDpB+q/6sHr4OzP7YjuWO9q8LfxHvOW9BP2R/cz+Ev5wvo0/FD9Wf6l/yIByQLSBCQHOgmfCqALxQxVDkEQSxIyFJMVTxb5FkQYFxq9G5kcrxxlHKwbRBrCGAUYFRg2GL0XRhbBE4kQTA3zCjEKnQroCvQJygfpBAAC5//D/iL+sf0p/UL86fps+Sv4S/fF9nr2TvY49h/24PWL9VP1L/Xm9Ej0evO88n/y3fKC8+fzqvPN8sLxBvHg8EfxAvLh8p3z9/PS82XzF/NA8/bzOvX39rD43vlZ+j76D/p2+or7tvw2/bP8Ufuk+WT43/ei99X29fRL8rnvOO477s/vmvKG9Vf31Pco+Mn5l/0DA9kIIg5LEg8V2RacGAMbBR4fIagj/yQUJUokNiNJIsshpCFbIdsgISAKH5QdCRxxGpMYQBaKE4YQLw2mCRwG+AJUABH+xfsj+V321vPQ8Yzw1O/z7mjtK+ud6B3mBuSn4ijiL+JL4n7i/uIH5KTljOd/6brrfe608RL1XfiP+7j+2AGdBKgG0AdxCAkJ3QneCnoLDwtLCWQG7wL1/2f+Tf6o/jD+qPzU+kr5Z/hO+OT4lvnY+Yn59/jn+I35VPqw+s/6Ifuf+zn8vvz4/M/8Sfxx+1/6/vh792L2SPZo9xf5cPok+5f7dvyj/qwCEQiADaYRNRTGFTkXMBm8G0Ie4x8XICgfHx6vHZYdQh1tHNQaPhjvFJ4R2w6+DNcKeggiBd0AaPx/+Kb13fOf8kbx9e/u7hHuSO2z7HPscuyy7AztXO2O7Wrt4eww7NHrK+wn7SPuoe7Y7l/v1vB288f29/l0/Ez+9P85ArkFKwp5DqARNxN8Ew0TkRJvEnkSGBKpEO0NPgpTBtsCOgBQ/rn87fq1+Fr2HfQt8r7w+++i7zrvVO6m7KHqTunC6fvr5O5K8bnyfvNb9Aj2vfgG/CH/kgFRA+0E8QZfCbkLhA2BDvEOFQ8+D9cP8RA4EmcTXhT7FDQVMRV5FaEWoBjCGjccwhyYHOQbqxqxGOUVUhIRDncJzgRqAHz8CPkd9r/zxPEc8PTuZO5r7rvu/+4h7xbv1+5W7tbtyu2q7mzwp/LI9Ev2M/f39xX5vvr9/Dr/pADuAGsAwv9M//7+lP7x/VT94vxc/G77NvoD+QP4ePeQ9/n3SPhr+K74Vvk8+rL6Tvpt+b74nPg5+Vn6OvsE+0b5U/Za88DxHPL+8zf2p/fG9xb33fYz+EH7Mf8fAzYGQgjBCXoL7Q0lEY8USxfOGFIZthmSGt4bDR2jHYMdvhw/G+oYfhYfFTQV1RWKFYMTMxDNDEkK7gihCKgIDQg5BqoDDAGV/nH83vr1+Rr5i/cm9X3yefCd747vX+917tfs9+qj6ZXpnOoC7DvtFO5m7jDu0O0b7sXv8fKs9jf5o/kx+Cb2BfWN9SL3WPg/+Nb2nvRf8vfwovDZ8PzwxPBl8E7w0fD38ZfzoPX798X64/3CAPUC5QR8B9wKLQ6RELwRHhKAEjQTFBTiFKEVNxacFtoWwBZ+FpkWbxfCGPUZvRoqGz0b2hpFGsEZWxmXGBoXFhUYE4YREBA9DtkL+wjlBRgDAgGg/5z+bv2D+7j4ePVm8jPwEu907pXtEewf6kPoJ+dJ55DofOpZ7MftBe+78FLziPaB+bP7+/yD/aD9xv0X/if+p/1z/NH6Jfmd90n2L/Vs9OPzTvOQ8p3xlfDw72fwIfKC9Jf2r/eS9wP3Nffj+LL7eP4MADsAj//D/or+CP/n/4wAaQBz//P9cPym+wL8Pv3T/kwAswFlA4kFwQfoCa8MYxCmFMwYSRwYH54hNCStJq8o2SkEKkop6CcbJu0jOyHWHZIZhBQ4D4EKxAbzA54BP/+a/K75wfZY9PPyX/Lk8RzxE/Dm7nntBuzQ6unpOOmP6KPnLuZC5DjixuBd4MjgP+H84MTfPN7B3SffHeKP5Z3oEusx7XDvTvLw9RX6LP7jAREFpAeUCakK3Qp6CvsJiQn8CPoHbgZ3BHgC/ABKAGYA8wBjAWkBPgGtAU0DHwZnCVQMlw52EF0SYhR1FoIYTxppG6AbDxsdGiwZQhgsF7QVKBT/EggSyRDrDp4MZArxCKII1Ai4CN0HcQYcBVIE8APXAwIEKAS6A5sCVQFTAGj/B/7O+//4BfYl81fwk+3Q6jToI+a+5JjjXuIm4YrgJOH84pDlBejG6QnrbOzL7rrytfd5/EcAOAPKBXsIdgtODmAQYBGaEXIR2xBaD5sMBwlEBdcB6f4I/LX4IPXr8Y7vNe647dLtZu4V76zvTvBq8SvzSfVu96f5Bfwk/t//mQFLA50EewVHBnQHMwlIC0QNig7YDlEOkw13DYEOkxDBEkYU+RR/FU8WaBfGGCgaVxs9HL4c/Rw7HVodtxzPGpkXbRP8DsAKkQYmAln9cfj28/7vJ+xh6DrlXuMA443jOOSH5JPkueRf5cjm1Oga60TtGu+K8ODxefO79Zz4r/ts/q4AZAKuA+YEngbxCC8LfgxSDNEKsQjtBggGyQWIBXgEHwIE/x386flW+Cf3RPaD9Zf0fvNq8s/xIfKE8331vPZC9ib0G/In8tT0zfjx+9P8h/tl+dD3zPeb+b38RwBfA40FtQaGB9AIIgvFDmwT8RdFGwod6x0rH6Uh6ySeJ1golCZBIxUgWh7PHTMdphsCGTYVMRCNCpgFcQIGAUMAmf5G+/P24vIx8FDvlu+c723uZOx+6n/ppOl66mLrBOw87ALsfevt6tvqBuzP7kHyxfRN9Qv0ovLu8mz18fhu+8b7PPrY95/1RvQF9G70t/SF9L/zivJW8cjwTPHv8g/1lPbb9u31xvSX9A/21/jk+9n9C/5O/c38OP3o/sYBEAX/BzMKgAu+CzsL4QrbC4UONRLRFV8YuRmFGoYbCB21HgogzSAxIWghcSEpITMgTx6wG8QYKBbmE9ERrA8sDSEKqwYuA+H/Fv3D+q/4y/YM9W3z6/HG8FHwavCT8GXwtu+x7uHtxu097sDuDO877z3vB+/u7lHvDvAC8Rry9PIj82Ly9/C47xjvxu4N7prstur26LrnCufn5kDnueeV6Gbqc+1/8e/1/PkH/er+QgDwAZsEIgjfCyYPlBHmEhwThBKkETIRsRHiEjAU3BTCFD0U7BNBFFgVKhd0Gc4brx02HwMhASOaJFMl5iROI+QgHh4gGx4YNBUVEoIOlgqdBtkCb/+A/Az6zfeV9XLzPfEO7yTtw+sJ68nqpOo46oHp9+g06Xzqpuw874zxS/Ot9LX1lfaR99L4B/qb+kP6N/kd+Kz34PcQ+JD3H/bz88TxbPAa8JbwffFr8sPyOvJb8bvw0/Dl8Qz0q/bz+CT6HfpL+X74TfjG+Hf5yPm5+W75BPnO+CT50/ml+oD7ffyw/RX/pwCQAkUF3QgDDesQBRS7FuEZxh1BIrsmiCohLZEuOS+vLwMw4y/mLu8s6ynTJfUg5hszF/oS+A78CkMHBwQSARf+Dfvu98H0qvH07pbsQerN53LlleNH4lzhbOBS3zvesd383d7e6d/94NjhSeJs4ori+OIV5AHmVuiB6gDsxewP7SLtce1H7oLv2vDs8ZbyFPPN8zH1XPd5+kz+8wF8BKAFKAZRB9MJPQ15EKESmBOGE8oSJxJTElUTTxSSFDQUuhNjE2QT6RPqFPwV8xbdF5EY6BgtGTgaUBzqHvQgYyEOIPYdBBxUGuAYURdGFVwSxw4XCyYIQQbpBJoD8gGd//j8lfrs+Pr3NfcL9kP0wfHJ7vDrsukc6Cfnm+Yo5qDlG+WJ5CzkdeRx5eXmU+g+6W/pRulZ6UHq7OvG7X3v5fAy8sPz8vWc+Gb7C/4qACoBDQGNAEMAgQBLATYCXQIqAR3/L/0B/HH7EvuQ+rr5hfgV97H1k/Qy9MT0xfX79rn4PPtB/l8BXgRZB/4Kvw+IFZAbqSBOJJomuidWKBkp+ynlKtUrNSyKKwQqAiiiJcUiDR+UGtwVhREqDrQLawlrBmcCq/0k+Z31L/NN8W7vK+0q6pnmOuOL4HXeqtzx2hPZW9cO1l/VjNVu1lLXsdeA1yLXdNdc2azchuAA5J7mq+gf68vu2PPs+TQA+gVSCykRZRjOIK0oFC6eMHkxbDJLNGQ2GzcpNWswqSkpIh0bFxUXENsL0AdVA2b+zvlY9iD0nfKN8dLwCPAd74julu7V7o/ujO1B7Err6uph6troeeZD5D/jiuOw5D/mC+gs6ufsjfBi9Vz7JwLgCN4OJRTnGA0dmCBfI+YkJyXNJKEkcySFI/8hqSCfHyIeexuWFykT0A6SCvYFqwCZ+kz0re5U6iXnfOT74Z3f59163Vje2t9Q4aLiGOS65XXnLOn96ibt3u+g84/4Nf7JA34IFAxbDxYTSRd9Gy8f5CEcI90iXSEPH2scIBqIGDMXAxUhEfcLzQaxAu3/Bf7l+934LvXQ8aPv3O7B7nvuIu4p7lLuAO4L7fPrZ+t767HrUOse6q/ok+fL5jXm4uVS5qvntOlX7Hvvy/LI9VT4ZvpU/M3+2QFOBTMJRA3+EPET/hVxF6EY9Bn7G4keviB+IWgg7x3bGt4XMxW/ElUQyw0fCysIbAWLA7ACcQIrArEBOAH2AMYAXQDq/xIAxgAiAcsALgCF//X+uP6a/kz+4P3p/U/+pv6q/oX+Vv5q/v/+1f+CALIAagD0/3L/8f6T/g7+AP1p+335gfer9Sn0+vLb8Xvw0O4s7cPrdOrg6OvmluTX4dHeNtwg20rc+95D4czhSeGm4WPkjekv8AL3M/1DAi8GagmlDFwQpxQ0GV4dYyDkIUYibiLXIncjJST8JKwljSVgJJEiJyGxIIYgSB+ZHDoZQRYRFGASrxDXDrIM8gmGBtECZf+q/Mz6sfm1+Bj3CPVM82ry9fE38VLw2+8h8MnwXPGU8XDxGvEX8enxtPPS9cX3y/mC/AkAuQPUBvAI8Qk0CnUKBwtiC4MKIghqBMf/sPqz9RvxP+1x6lToUeYf5Mjhz9/A3snefN9v4HXhVuLi4ljjGeR95WDnUulK6zjt0O458NTxq/O39U74jfss/1ECcgQrBrMI4gw6EnEX0BtvH8MiBSY+KVAs6y7nMFoydDMkNDM0ozOQMkwxITDULr8svCkuJnkith6bGt0VdhB+Ck0EVP4I+cT0hfE670jt7uoj6Hnl5uOl4+/j0OMj4zriYuGy4Gvg5uAI4hzjr+Ph4+nj8eMS5APkieOf4o7heOAY3zvd/NoG2RXYYNjY2ZXc8uCL5g7sPfBG8932mvxiBNYMWBSwGZ4c4R1lHrsenR9IIesiaSPPIWkebhpBF7EVTxUlFZYUcxPbEVcQGRD3ESsV8RfoGPwXohaSFrsXoRg4GF8WlxNtEJgNaAuyCR4ImAb6BOcCZQAZ/pn8qftT+kf4MPbj9GT0YvRv9JD0tfQA9dT1bPev+cP79vx9/UH+vP+OAdoCwgL4ACT+svuD+lL67vlC+DX1vvED73rt/uw77c7tc+4+7pPs9umZ55HmK+eM6IjpWunf58Tl8OPe4nTim+JO40rkIOW85Xfmhucn6UrrAu5i8Rj15/jA/O8A8gUUDKwSyBgOHhEjyCiALx82SDtJPrY/G0EzQ3pFxEYzRnVDXz8GO/s28jJXLmko6SBfGOMPTAj9AZf8efdO8iHtz+dP4kXdsdkX2MPXctc91jvUd9Kp0fLRytKc0y/UidQ41aLWedgY2pDbMd0a34vhueSc6OHsOfFf9Sn56vxFAVgGvgvCECwVHhnYHIwgPSRRJ+koWyi3JSgiEx8IHWsb3RgtFCANMQVw/iP65ff+9e/yze6T6nLnIebB5g7ph+yZ8Hr0WvfS+Cn5ZPme+mn9aAFyBSQI3ggKCPMGsAbIBwoKOg0OEbwUZhfHGD8ZrhkdG8IdriBsIg8iyB/EHJMa0BmwGdEYVhYVEpwMIwfkAvf/j/2P+gz2wO/E6K/is97+3LHcYdz/2pbY+tU01O/TLNUd1yPZ3toE3Ijcx9we3YXdCt7T3jrgcOIM5bDniuoX7sHyTPgC/mwDigiADYYSxRdEHdgi+yfzKyoujC68LcgsdyyNLIMsyysDKvomICNuH7scLBtHGhsZJRd1FF4Rbg55DNcLkQueCr0ITwaiAzEB9/9JABYBOgEnANr9rPqw9+31XPX49JrzGPH07crqLehC5unk3uPr4uPhDuG54I7ge+Dk4NLhv+JU437jJeN84u3hzuFv4hPktub06QPtcu8j8Vbyo/O19bH4Hvwg/9gAGwG7ADkBQwNFBikJSwuqDLIN+Q4QERcUlxfqGoQdQB+PIC4iWySjJnIocSliKWIowibZJAMjniFpIMAecxwHGkQYbxdAF8wWLhXBEsMQ1Q9QDycOvAvYBw0D2v2L+GHzD+/u65/pZ+fY5Ovhc9883lHeBd/A3zngc+CY4BXhPeLU41XlS+aY5r7mOOcV6CXpbeoa7DruNvCN8SPyG/LT8Z7x0PFz8mfzZ/QG9dH0w/Nh8nDxmfHu8vX0Gff5+I/6APxz/VL/OAJiBi8LfA+oEkYVQRiFG0ke3B9sIOkgASJlI0Uk/yOJIlMgPB65HOsbcBv7GnIa8hnPGXEaqBvpHKkd2h2IHd0cxhsyGjMYKBYEFDcRNA0gCKoCjP0z+ZX1LPLT7rbrzOjr5RvjpeCF3vXcH9zv27jbJttO2qzZ7dlf22zdCN8V4B3hoeL85Avo+eoF7Rru9u5E8CTybvSj9k74SPm++cX5OPke+Pr2UPYl9sX1fvRx8kzw1O5v7j/vSfGw9HD5xv6cA0EHNwrKDSAT6RlZIAAlwidcKYYqnCu1LJctwS2ULCwqOieYJBQjzyLiIlMi5yA0H+IdER1+HNYbEBsKGlwYvBU9EiQOvAlnBUwBjv0n+sr2DvMF7zPrQehs5ivljONN4RHfbt1S3HfbEdtk21ncn91J34DhJeTU5jfpYuvc7TXxMfUU+SD8L/6b/7gAqgEDAk0BYf+D/AX53/RV8N7rzufD4ynfVtp21hnV/dbD2+fhJudJ6hfs5u6x9Mf9VwigEegXFRs+HLkcix1EH7Eh9SPoJCgkJiLrH4Yewx6oICQj1CT6JDokFSRwJTAoHivhLMksKCvqKL0msSR7IgogPx0oGrMWyBJgDp8J0QQeAEv7ZfZw8U7s1OYA4ena8NTez5LMB8toyvjJTMmmyNfI3coUz6fUMdqL3rvh0uT36FLu2vNG+CD77fyg/vkAwgMFBvMGcwZ1BTIFNwZpCCwLxw24D9sQQBFqEcwRiBKHEz0UvBOYEW4OTAvgCPUGtgRZAdT86feQ83vwne4s7XfrZeks51TlPORA5PrlU+lG7c7wx/Pe9gz7zwDPByUP/hXbG7cgwiRvKPIrNi/QMX4z9TNmM14yMDGfLwwtEynLI6wdXhdlEewLrAZzAS/8QPdC8yfwW+2M6g7obeaP5djk7+Pv4h3iQuEG4GHey9zt2+HbBdzT22nbbNuK3ErfUuPN5+Prme978wX4bf1+A5gJzw6EEsQURhbnF+cZpBsUHKcalxflE6IQJA76C28JIgZcAor+/foB+Kv14fOb8qXxpfBN76btReya69vryuw37rrvQfEh89z1YPn7/PP/XwINBYoIlAxnEKUTPhY8GNQZMhtFHBUdkR20HWUdshzSGwYbaBq2GcgYlRdcFjMV5xNaEpkQow4KDEkIcQM6/pL57PX38uDvROya6Ibl3+J24HzeYN1p3Wfex98O4VLiCeRb5hfp4uu67s3xVvV3+dn9+wFfBd0HjgknCywNew9mETUSuBF3ECQPDA7/DGYLIQmEBiQEWwK2AKX+OPwI+ov4rPdp98734/h5+kf8I/7L/wEB0wFSAnsCTgKpAQ4AQ/2T+Wb1E/H07Grp1+ZQ5ZDkQORx5JHlD+jq6+LwefZJ/C8CXQgmD4wW+B2AJJ8pNS1JL/YvkC9gLj4s7CiHJGwf0hnDE60NFwhDA9j+n/q/9p/zIfHn7qvsXupo6E/nR+fI50noeuiH6Nro5ema65Xtv+8S8ln0G/Y+9zn4iPkJ+2T8TP3H/Un+S//qAAsDlAVGCOEKDQ34DioR4xPfFqUZnhtmHGAcFRzQGz0bABqpFwIUbA+mCugFBgHp++r2kvIY72rsQeqF6GLnA+c756Xn/ecH6M3ne+dN5ynnxuYs5gzmxeYN6EPp+uln6izr4+x276bycPYW+0YAHQXuCMULew7wEV0WDBswHw4iTiPxIrYhniAhINEfBx9THdcaMxgQFpUUZhP/Ef8PSQ0oChQHLgRWAZb+rfs5+Fb0gvA37Zzq/OiS6EHpuurJ7PTu2/Cw8tf0Ofd9+bj7K/7RADUDtQQvBegEeARGBHAEEAXzBaEG1wa2BoAGKwbOBZ0FgwVoBScFvwQlBGQDawIWAVf/rf2G/On7tft1+7D6MfmD90b2q/XJ9Vv21Pbw9uL2GPeG9/j3kfhD+dT5QPqN+qj6Sfqj+QD5d/jN95f2zPTJ8jLxlPDz8NLxtfJQ83rz4fOQ9Rb5Cv5oAwYISgucDRIQPhN5FswYGxpwGtMZbRjHFk0VMxRPExQSMBDwDfwLrwoHCtIJWQnlB1AFZwIyABH/of5K/pL9VPyo+hD5Efj896n4m/lA+lz6Wfqp+lT7Gfx+/H78Evxu+xD7SvuL+yb7B/q8+Lz3VPeb9zj44fiQ+ZX6+fu4/eP/RAJOBKUFdgYxByUIOAn7Cb0JUgguBhEEpgL7AXUBpQCi/7v+AP5P/dr80Pwc/Xv9Z/3E/K/7gfpK+fj3YPZ69HHyX/BV7mns5uox6lzqFuso7JDtE+8w8Kfw8/C78VnzzfWO+CP7gf3F/0YCRwUbCc4NKRNcGKwcrh94Ibgi7yMlJcIlZiXQIwYhOx0aGScVpxFzDmgLFghcBJoAR/28+uX4f/dC9kT1jfTO88Xym/HP8NPwtfEc81z0SfUO9sn2a/cv+H/5P/sB/Tv+vf60/pr+2v5Q/6n/2f/q/6H/E/+1/rb+Of8SAA8BygFUAv0C2AObBB0FVwUcBVIEIQOqAe//CP4d/P75Xvds9K7xbu/H7cXsN+z26zLsA+0x7rjv8vH19HT4//t0/60CuAWzCJwLXA7yEDQTpBTjFB8U1hJhEdAP1g0yC+wHlQRrAX7++fs2+jD5n/iK+PX4yfng+mX8XP6LAOQCUAW5BxgKMgySDe0NfA2PDEsLswm0BzcFMwLy/sX72/hI9lP0MvPB8uPykPOT9MT1QPcn+Un7bP1v/0gB2gI3BHoFsAbHB74IdgndCfoJ3wmKCQEJTAg7B64FlgMSAW3+0/tZ+Qz3+PRC8wTyMfHJ8LXw7PB98ajyX/R19tP4QPuc/df/+AHRA0sFkAa1B5cI8wirCP4HTQecBsoFyQSlA6UCGAIRAkoCywJ4A1AEUwV4Bn0HKwiXCBwJzAl5CrQKLwrhCO8G2gQAA0cBQf+p/Jz5lvbm82nx7O5Z7N/p1udI5vXk8uOv43TkGeYy6IDqQe3S8FH1bfqL/1kE1gjfDEgQABP6FBYWShZsFZkTBRH2DZoKGgfaAyIBD/+h/dn8svwi/Vv+TwChAiAFrgcuCpEMrg5IEDcRuhEtEpoSnBLuEZwQ0g64DFAKiQdoBB8Bvf1J+tT2tfMO8ebuNe0M7Gfrkuu87KruDPGz86T2lPmB/HD/TQLQBOsGcwg5CVwJIwlkCNkGkAQKAo7/J/3P+mb47vXe85ryOPKB8lvzp/RD9lf49frw/T0B4gR8CHALeQ27DooPPBDiECkRjBDNDhYMtwg2BfgBOv/I/Dj6MvfS84Pwze3J62vqyunL6S3qlOop6wnsR+2/7l/wQ/Jv9MT2O/mj+/T9OACNAucEFAeqCIsJ9AlhCiAL/QuyDC4NWw1HDRoNQw35DUwPJREuExUVoRbZF+gY7hmdGt8alxrMGVEYERYcE5QPhwv/BicCPv12+PHz4O8+7ProGebA4/nh4uCk4D7hq+K05CTnzOmz7OXvC/Pk9ZX4X/sr/t4ASQMeBUEGwwb+BhgHLAdbB3AHIAdjBnQFiwTIA08D/QKgAnECmgIPA74DnwSBBS0G5QbAB4YIEglPCVQJLgn1CHgIWgeTBV8DCgGv/mz8Nvrr95b1bfOL8QDwAO+L7kbuuu3A7LjrQeua66fsJO7O72vxuvK+8+n0vPZ++QD9twD1A2kGcwiYChQNpg8IEjEU6hXuFuoWKxZ/FV8VbBXtFJcTwxH2D4MOig3xDHMMwwu8Ck8JlwcHBuoE5wOeAuwA9P7//A375vh39uzzsfH/77bu0u1K7Qnt9ewa7ZTtae6774rxn/Ol9Xb3TPk1+wv9nP4CAIcBIwOpBNgFtQZkBwYIewijCIYIPgjvB6EHLwd9BocFdgR4A4YCkgG8AA4AoP9V/xX/0/66/uH+Ov+9/zUAcgB4AGIARgBIAJUACwE3Ad4AGwBg/wn/Lv+l/xAAMADo/4v/ef8FAB0BYwKYA3gEzwTkBBYFkAUXBmkGbAYdBoAFtQTgAw8DNQJFAS8Az/43/bf7efqB+ZT4kPd69mH1m/Rc9JD0+fQ49S31BPUF9TP1T/VZ9Wn1lvX99a72ovet+Kb5jfqI+7j8P/5qAA0DtwXkB1UJJQrUCsAL1wzGDT0OGA56DZkMoQusCrMJvQjVBxcHhwYnBtQFUQWQBKADvALvASgBQgBs/8P+Rf7H/Tr9ovwq/ND7kPtX+yv7QvvZ+8X8tv2J/h3/WP92/7v/OgDzAK4BJAInAscBcAFYAWABfAGbAagBqAGcAWgB+ABVAKH/2v4M/jH9Pvwy+x36CvkX+D73hvb59bb1wPU49hD3FPgc+ST6PPtX/IT90P4wAGgBSgILA9IDrQSkBaEGngeACD4J3wmQCjYLvgs8DJEMsQyGDDMMrQvpCukJxwiKBwcGMgQRArj/Pf3I+oT4gvbf9JrzkfKB8VzwUu+T7lzusu5n7xzwm/DU8OnwEfF+8UvygfMC9Z72Kfis+Wn7cf3H/14COAU8CAoLeQ2ADzoRnhKwE0wUZxQHFCsT/BGSEAkPeg3YCxsKRgiHBucEYwPuAYUAJ//c/Zr8b/sv+sD4S/cb9mH1DPUR9UL1mfUY9sr2tvfs+Fn69PvW/d3/7AGgA9YEkQXyBTMGcwa+BusG7QatBjEGfQW2BPkDVQPjApUCZQJCAu0BTAFzAJD/u/7W/dH82PsL+0n6avmU+PX3nfeM98L3FPht+NH4Yvky+ib7JfwP/eH9oP4z/4T/zv9EAN4AdgHmASICFAK9AUMB3gCvALsA8QAjAfMAVABv/5f+5/1w/Sv9A/3O/Fv8oPvN+j76HPp6+jb7Ofxa/Wv+U/8WAOMAwwGzAsADzQSxBXMGJQe1BxkIagjLCGoJXwqaC+AMEg4BD6UPDRBMEGQQIhBWD+UN3QtzCe8GhgQfAn7/o/zk+aH3E/YO9Vr0+POy82TzF/Pz8vfyG/Nj88jzKPR99Nz0T/XS9U72zfZp9zv4MvlJ+nj7xfz5/eP+iv8SAKUAUgENArsCPwN3A1UDAwOpAo8CsgIFA38D8gNxBOEERgWcBccFCAZbBp8Gggb+BUEFbwSNA5cClgF8AGb/YP51/bv8U/w8/Gf8oPzE/O78Tf0N/g7/IwAqAQcCwQJuAzkEIwUUBvMGjwfoByEIWAieCNIIqwggCEAHGgbYBI8DRALjAIn/Qf76/Mr7x/of+r/5ivmG+a35/fli+sH6E/td+7j7+/sa/C38M/wP/MT7S/uv+gv6ZPnJ+Bv4T/d99uv1wvXm9UL2qPYY92b3kPet9/f3l/iX+eD6FfwC/Zb98v1V/gD/GQBkAYECVQPiAzQEeATeBJUFcgZLBwYItghJCcMJQwrTCmQL2wsgDCUMEQwHDOwL0QumC1oLygr+CRQJFggeB1AGqwUOBSoE+AKTATAA4v6w/Zf8nPu++uD5Evle+L/3O/f69iX3pfde+B35xvlf+gj7v/t1/A79hP3Q/fj9BP7z/cr9e/0S/YT82fs6+776h/qg+uv6I/su+yf7Qvuy+2n8M/3e/Uz+kf7N/hL/jv8/APoAgQHWARICSQKLAvICXgOrA8kDswN9A0UDJgMTAwAD1gKhAocChAJ6AmICYQKSAvcChQMeBKQEJQWgBQIGZAbnBoEH9gdUCIkIjwhfCBcIxQdlBwcHgQbJBeYE/AMeA0ICbwGgANz/KP+f/lH+If7z/bX9eP1J/Tf9Mv00/UH9Pv0g/fb85fz5/CL9M/0z/Q79zvx6/Aj8gfvy+lz6ufn7+Cz4PvdP9nn1ufQi9KnzVvMl8yLzSfOj8yP0tvRU9fb1s/aJ94f4kvmO+l/78Pts/P78wP2c/nX/MgDDABwBZgHLAVIC5QJkA+EDZwT7BJ0FSQYBB90H7ggZCj8LUwxgDWQOcw+EEGcR9xEmEuEROxFTEEwPMA7nDGILmwmKB4YFyANTAvQAi/8g/s38vPvi+in6h/nx+HD4CfjF97P3rfew97n33fcu+Iz48Pgo+UP5U/le+W35ffmn+c758fn7+fL59/k0+sD6f/tL/P38iP0P/rT+dv8pANIAZgHlAVYCoQLTAu0C6wLEAoACGQKYAQYBYwC8/yD/jP4G/o/9Jf3j/OP8F/1Z/ab9F/63/l7/9v+pAJUBlQKlA70E3wX+Bu4HkgjrCDIJoQkfCnkKgAo5CsQJJAl2CLwHBwdKBoQFtwTnA0gD4gKBAggCoQFMARMB5AC9AIIAMQC4/xj/Yv6b/d78TPzQ+0T7l/qw+bz4+/d09x/31Pae9o32nfbE9gv3iPc5+BH5CfoJ+wj89fzJ/Yb+P//h/1oAswDgAOIA0QCrAEwAw/8f/3n+0/0z/Zn8CfyE+xr76/r4+k771ft1/BL9nf0z/uv+0f+wAIgBRgLYAjkDgQOdA5kDigNxAzYD5QKKAiUCwwFgAQABpQBkADcANQBjAMUAYAEdAuECmgNeBEYFRQZFBykI1QgxCUQJPgkiCfQInAgZCHUHowaxBagEoAOlAqABgABa/zv+OP1a/K77H/uY+jv6EPoe+kb6i/r9+of7JPy//GP9+P1p/rr+BP9c/6b/vv+u/4j/Rv/m/m/+B/6m/Vn9H/3j/LD8h/yA/Iv8sfzt/Dn9jf3x/Vz+2/5a/8P/MQC7AE0B1wFEAoQCpAKyAtkCBwMnAy4DFwPcApYCXQIkAvQBvwGPAW4BXwFYAW8BkgG0AcMBzQHfAfMBDwIPAgAC8gHbAaABTQHhAGkA5f9j/97+cv4c/rj9Yf0C/bv8j/yJ/J38v/zl/Bf9bP3g/Xv+I//C/1sA8wCRASYCtQJHA8MDKwRbBFYEMgTrA68DdQMrA64CBAJqAfAApABoADgAFwAPAA4ADQAUADQASABCADEABgDR/5j/ZP8i/8P+Rv61/Sj9xfx+/CP8uftR+wn72vrC+sP61foK+1z7x/su/Jn8Jv3d/av+gP9lACcBqgEIAlMCswIKAzIDMQP8AqICSAIIAuABqAEtAZwADwCf/0L/8P60/of+df5l/kv+Ov5F/mH+hf63/vD+Kv9r/7H/8f8bADcALwAFANz/u/+o/5T/Xf8O/7r+f/5s/l7+Q/4u/ir+L/4y/jX+Tf6A/uv+av/2/6YAfgF9ApADmQSYBaIGswe+CKEJPgqGCn4KGQpwCbII3QflBt8FzgSlA2cCKAEdAFv/3P54/hH+tP1i/RL90fyH/DX89fvY+9X74Pvp++L73fvs+xb8Qvx1/K788vxB/Yf9zf3z/QP+F/4y/k7+ZP6E/qj+3P4i/1//nv/u/0kArwAjAa4BSALSAj4DdgOVA5QDfgNRAw4DmwL3AS4BXQCr/x3/oP4O/nz97/xy/C78J/xL/Hn8ofzQ/AX9Sv2x/Qv+Yf6y/gv/dP/r/2sA5gBrAeUBQAKBAq4CzALRAsMCqwKLAmUCMwL7AcYBiwFcAUYBUwFtAYMBmAGuAdcBEgJMAm0CjwKcAoYCSgL+AacBVgH9AIoAAABR/5P+8P1x/Q/9t/xd/A781fvQ+/T7MfyE/N/8QP2l/SD+wf5k//T/ewDrAEMBiwHPAQUCIQIgAgACwwFmAQoBuABWAN7/W//N/jL+of0c/an8WPw7/Eb8XPyD/Mb8LP2z/Ur+0/5Z/9f/VgDTADkBgAGxAcwBxgGgAWcBJwHQAGwACACs/1z/GP/U/qD+hP5//m7+a/6L/tD+Mf+B/8P//P8pAD0ASQBeAHEAegB5AFgAEQDI/3//Pf/p/nD+9P2G/Rj9t/xt/EH8Fvza+5f7UPsa+wb7HvtQ+4r75ft+/E/9Vf5y/3QAUgEpAhgDNQSXBScHiwiNCSwKbQpnCkMKLQoSCsIJLQlkCHsHbAZsBYAErQP0Ak0CwgFLAcwAOgCi/xj/qf5j/jr+FP7o/b/9sv2j/Zr9o/29/eP99v37/fT96P3M/aj9c/1D/R798fyx/Hn8T/wz/Dn8UPxq/G38afx1/Ln8Pv3h/YL+Bv9p/7n/AQA+AHsAqQDMAMcAhwAbAJL/A/+H/j7+G/4V/hP+EP76/ev9Bf46/oz+8v5m/8v/FQBXAJkA9QBuAeUBWgLZAlgDzAMkBG0EpwTaBAwFJwU7BUcFMAXqBHME6wNhA/UCpgJSAuEBYQHwAHwAKwD6//j/9v/h/7n/ef9E/x3/B//p/sX+g/42/t39af33/Jb8P/zZ+3j7NPsG++X6zvrG+sz68Pou+3n75ftZ/Nb8Vv3T/Wb+8v57/wAAcQDHABQBcgHCAfsBKAJLAj8CCgK7AWwBJQHdAJYAQQDd/33/Pv8d/xD/Av/s/tz+8v4v/3n/wP8CAEkAgQDFAB8BjQECAl4ClQKyAsoC7QL6AusCxQKQAmICLgLxAZ0BQwHrAJgAUAAUANr/p/+A/1//Qv8t/xv/C/8A//3+9v7j/tL+uP6c/oX+af5Q/jn+IP4Z/iD+Iv4Q/uj91v3g/e/9Bf45/m3+hf6Y/sP+/f46/33/vv/x/x0ATAB2AJMAqwDHAOgAFAExATEBDQHdAKsAdwA0ANz/hv81/+P+g/4R/o/9Bf2S/Dn8+fvU+9H77fsS/Ej8lfwB/Yj9Iv7N/nj/JQDRAIQBMwLaAoEDDwR3BLoE7QQbBTkFXwV9BXwFTgUMBdoEpARrBD0EHgT+A+MDyAOkA2wDKgPZApECYgI9Ah0C7AGXAR4BnAAcAL//ff80/83+Sv68/S39tvxr/FD8Qvwy/Bf89fvU+7L7tvvi+y/8gfzT/B79Yf2x/R3+pf42/77/LgCYAOIAHAE6AVUBaQF2AXEBWwEqAdgAgAA2ABwAEQAHAPP/0v+m/3T/XP9u/6D/0v/z////BgALAA8AHwA0AFkAjADDAPcAFwEhASoBPAFUAXEBiAGGAXoBbgFxAYIBowHGAckBxAGwAYwBcwGDAbcB7AEOAhEC/wHlAcwBuwGnAYsBYgE4AfsAsQBjAAkAs/9j/wP/lv40/t39jv1X/T79Jf0A/df8xPzI/Oj89vz4/O/83PzS/Nv8//wl/T39SP1L/Vb9dv2i/cz98P0N/ir+XP6g/tT+B/84/3L/ov/G//3/MQB5AMEA+QAhATkBTQFjAX8BkgGZAZwBlwGDAXIBbwF5AYYBhgGCAXoBgAGgAccB2wHkAeoB7wEAAhUCLAJBAkwCUwJXAloCXQJcAmACVQJCAicC8QGzAXMBPgECAcgAhwAyANn/iv9S/xT/yP57/ir+4v2r/YH9Xv1M/Uj9MP0R/fv8+fwO/Tj9a/2j/eT9D/4e/i3+Sf5w/pv+xP7u/g7/Kv9T/4H/uv/j/woALwBPAIAArgDOAOQA9AD4APoA/wAEAfoA3AC6AJcAdQBYAFEATQBOADoAEQDX/6j/jf+A/4n/lv+a/3f/Tv8f//7++v4a/0X/XP9r/3r/kP+k/67/qP+0/9r/EgBEAHYAowC3ALUAowCJAIEAmgC8AMwAvACbAHQAWgA1ABEA8//U/7f/l/+D/3f/b/9s/2X/ZP9p/2b/ZP9w/4j/n//C/+3/+P/6/+z/4f/b/93/2P/L/8T/sP+e/4r/fP99/47/sP/d/wsALABDAE4AXwB+ALwADAFMAXgBnwHCAeEBDgI/AnwCvALqAgADEAMYAwUD6ALXAtMCxgKpAoMCWAI0Ag4C5QG7AZUBbwE+Af8ArgB3AG4AdwB6AFcAJgDe/4v/Nv/l/qf+fv5h/jL+4/2F/TL9+/zo/Or88/z8/An9G/0t/Ub9c/22/f/9R/6A/rr+8f4c/0f/fv+6////VAChANgA/AAnAU4BfAG7Ae8BAwLzAcwBnwF5AWUBUAEoAegAiAA3AAgA6f/o/+r/7P/p/+X/2//a/+H/5P/s/wcANwBzAKgAyADVAM4AvwCsAKkArwCqAIUASAAKAMz/l/9p/zz/EP/d/pz+Vv4e/v396P3P/bP9lv19/W/9cP14/Y/9pP2//dr9BP41/mD+gv6X/qr+r/7H/vv+KP9L/2P/cv+C/3v/d/+D/5r/s/+t/5//ov+6/+r/JwBvAJwAtwDOAPIAJwFiAZQBrwGqAZoBlwGiAbgByAHPAcQBwAHBAcsB5AH6AQ4CEwIbAiMCMgI3AjoCPgJAAkICSAJXAmkCcQJ4AnkCXQI9Ah8C/gHXAbkBoQF7ATcB2wBxABMAx/9y/xb/qf5E/uz9nP1V/Rr94fyj/HX8U/xF/Dz8Tfxw/Jr8w/zy/CP9T/19/a/92v39/Rz+O/5k/p7+5/4o/1n/df+F/6D/2/8nAHMAuQDxABABJQFYAY4BtAHZAeQB2AG7AZIBZwE0Af4ArgBfACgA5f+U/z7//P7O/qf+kP52/nD+cv5v/nT+gP6X/rT+0/4E/zX/Vv99/6P/vP/P/+r/CQA4AF0AdACCAIsArwDrACcBUQFnAWgBbgF8AYcBmwGxAboBtAGuAaUBkgF2AUoBGQHpALcAhwBNAAwAx/9//zL/6v6s/nL+RP4L/tv9sf2R/YT9jP2p/dH9+v0m/kj+dv60/gf/Yv/F/ywAhgDfACEBVQF/AZoBowGpAbcBxQG1AYYBVAEoAQIB6gDUAMAArACfAKAArwC+AMUAuwCuAKEAmACgAKsAsACkAJAAfABdADkAHQAYADQASAA2AAAAvP+B/3L/lf/D/9f/0f/A/7D/vf/e/xIAWgCsAPkAKAFJAVkBbAGRAcwBAgIWAgcC1QF8ASkB8AC5AHoAKADH/0//4P58/i3+A/71/fz98f3g/dr97f0U/lT+rf4E/0X/Xf9m/3X/ov/b/xQAOAA8ADkAGgDp/7b/l/+U/5n/qv+1/6T/if+K/6X/0f8EADoAZQCPALIA0gAAAUQBiAG4AdUB1wG0AYoBZgFAARoB2gCIABUApv9T/yT/C//p/rf+ev5d/k/+Wv58/rn++/4x/2v/qP/n/zwAlQDmACEBPQE6AToBRQFWAWEBWAEsAe4AvgCVAHEATwAzABgA7//G/6H/a/89/y7/QP9a/2//ev9s/13/Uf9Z/17/af90/3P/a/9Y/zf/EP/l/r/+vP7C/rz+o/58/mf+Y/59/qn+7f4i/0j/dv+//xkAfADsAFQBnAHVAQQCOwJyApwCrwKqAp0ChwJrAkYCJgL+AbgBWQHwAIIAKgDl/6H/Xf8V/9f+nf55/mL+WP5X/k3+VP5f/n/+qP7U/u7+//4L/xv/Kv80/zL/Hf8K///+//70/uf+0v60/o/+eP5x/nH+ff6S/r3+8v40/2v/nv/F/+z/HgBSAH4AnwC6AM8A1gDaAOEA5wDvAPMA4QDJAKUAhQBtAFsATQA6ACcAJgAyADwAOwA+AFAAXwB8AJ4AvQDSANMAxAC/AMMAyADLAMAApAB2AC4A5/+1/4L/Yv8y//v+xf6P/mL+PP4y/j/+Wv6D/qv+y/7r/hT/RP95/6j/0f/t//j/CwAgACoAIgARAPH/1/++/63/m/+P/3r/UP8o/wT//f4I/xH/Ff8I//f+6v7h/uT+3/7V/sn+zv7h/v7+Mv9t/6T/xv/N/83/4f///yUAWwCMAJ0AlQCAAHIAdgCUAKYAoACRAIYAkwDGAAABQQF+AboB+wE+AoQCxAILAzoDaQOPA6sDxAPGA70DpwN9A0EDBQPKAowCUwIeAvABwgGaAWkBRQEjAeoAmgBAAOT/of99/3f/b/9L/wT/p/5b/jT+Kv43/jX+KP4H/uj92/3U/d797P3z/fv9Av4W/jT+Zf6a/sr+//40/23/ov/v/0EAkADAAN0A+gAaAUUBfgGyAbMBigFPAScB/ADUALAAgwBEAPv/x/+Y/23/Ov8b/wj//v7q/t/+4/75/hP/Kv9B/0v/Vf9k/3H/f/+V/67/z//+/yYASwBiAF8ATQBFAGIAgQCaAKAAlAB8AGYAWgBcAGUAdAB1AG0AZABjAGsAiACnAMIA2wD+AB8BKwEyASgBDQHeAL0ApQB/AE4AEwDQ/3b/BP+O/iL+z/2I/Uj9GP3s/Mb8ovyG/Hf8efyV/Mj8CP1P/aL9B/5a/pj+zv4F/zn/b/+1//7/NwBcAG8AdQB6AJAArAC8AMUAugCkAIQAcABtAH4ApgDMAOUA9AAPARcBJQE2AVQBdQGMAZIBngGlAZ4BjQFmAT4BIwEOAfQA2wC8AI8AYgAwAA4A8v/g/8v/uf+v/6r/sP/D/97/BwA2AEUAPwA4ADkAUQB0AJoApwCjAI4AZAA5ABgA+f/R/7T/oP+S/3//cf9v/27/a/9t/3z/jP+x//X/MQBfAHwAgAB4AG4AegCLAI8AiQB2AFsAOgAlABEA/f/d/7v/j/9Z/yH/9f7K/rT+rP6k/pP+fP5i/k7+Tv5k/nn+mP62/s/+9f4d/03/Zf95/4j/l/+k/7r/0//c/+n/8/8TADAAWwCCAJsAuADSAPoAOwF7AcoBHgJdAokCmQKtAr0CyQLCArEClgJoAh8C0AF/ASYBvwBVAAAAvP99/zv/8f6e/kP+6/2b/WD9Nf0f/Rn9G/0e/Sz9VP1//aT95f0l/mf+n/7r/jL/eP/Q/xAAPgBVAGEAZgBvAIwApwDUAPAAAwEWASABPwFTAWQBcgGMAawBygHfAekB8gEAAvoB4gGzAYABUwEhAeoApABgABsA2f+c/1z/KP/7/tv+uv6t/qr+qf6u/rf+xf7Q/uL+Af8p/1j/jf/E/wcANwBeAHoAiQChAK0AsgCmAJsAjAB9AHsAeABjAFIAIwDx/8v/p/+G/27/X/9j/1r/T/9N/zv/OP8o/xf/Ff8i/0X/VP9X/1b/Rf8v/xX/9v7U/qj+hv52/m3+av5z/nb+hf6T/p7+sf7U/hL/Vv+n//T/RQCOAMoA9AAPASoBOwFHAUsBTQFXAWIBaQFMAREBygB5ADEA7v+y/3j/Tv8n/wT/5/7P/sn+yP7Q/t/+9v4S/zf/Yf+Y/9H/BAAwAEQARAA7AEEAVQB4AJgAtgDUAOMA5QDgAN0A3ADjAOcA9AAAARYBLAFCAVEBTQFCASwBIwEYAQQB8gD9AAgBDgEHAfUA6QDdANkA0ADUAN8A8QD/AAMB+wDoAMkAqwCaAJMAkgB6AG4AdgCKAJoApQCnAKYApgCjAKEApACpALIAvQCzAJAAZQA+AB4A7f/H/6D/df9M/zb/G////t3+uv6S/nP+XP5X/mr+g/6o/sX+2v7p/uP+1/7a/ub+7/4A/xn/Sv97/6//2v/6/wYADAAFAAIACwAHAAkAEgAkADQAOwAyABcAAgD9/wYAJQBMAHAAgwB8AGEAOgAbAPv/5//X/7n/oP+T/5z/pP+n/6L/iP9u/13/Wf9o/5H/y//+/yEANwBCAEEAOwA4AD0ASABSAGIAbwBzAHgAdwByAFYAPQAnABEABAD0/+f/2f/O/7v/o/+J/3X/Xv9R/1D/Wv9q/3P/hv+T/5j/iP90/2b/Wf9L/z3/LP8g/xX/Af/2/v/+Cv8Z/yj/LP83/1H/eP+z/+f/BgAPAAUAEQAhAEIAZQCGAJkAqAClAKIAlgCWAJUAiwCMAJMApQC+AM0AygDEALcAtADEAN0A9wACAf8A8wDgAMUArQCiAJoAiQByAFoAOgAcAPL/wv+T/2//S/8o/w3/+f7k/tn+1/7i/vb+CP8u/17/k//B/+b///8SADIAUQByAIcAlACYAJMAkgCQAJkAlgB6AFEAJgAJAPf/8P/k/9v/x/+6/6//rf+u/7r/y//N/8H/uv+8/8P/x//C/7f/rv+d/5P/jv+Q/53/of+q/7H/s/+u/63/q/+k/5z/kP+K/5L/pv+z/7r/tf+4/8H/2f/9/xcALwBAAE4AYwB3AIoAmwCVAHkAWAA6ABwAAADc/7f/pv+R/4r/iv+S/5n/of+0/8P/0v/V/8//2P8EADAAYwCOAKMArAC9AOAA/wAlAUMBXAFnAXUBfQGHAYsBmgGjAaQBpAGeAZIBcgFgAUQBLQH+ALkAcAAoAPH/u/+L/13/Nf8H/9r+s/6a/oX+ev5q/mb+Xv5X/lv+Xv56/pX+uP7X/uj++P4A/wj/F/8x/1f/ef+W/7P/yf/i/+7/CgA+AHUAqgDXAA0BPAFtAaMB0AHuAfkB9gHmAdUBwgGoAZMBeAFMARkB0gCQAFUAMQASAPL/x/+g/2//Tv80/yb/F/8G/wX/9P7q/uj+9/4M/x//LP8w/0T/T/9b/2f/dv97/5P/tP/a/wYAKQBFAFwAXgBVAFQAUgBYAF4AXgBfAGoAdwB/AHAAVAAwAAAAxf+W/3j/bP9l/13/U/82/w3/6P7U/s7+0P7b/uX+7f7t/vn+EP8z/1L/a/9+/5r/qv+4/7//x//O/9z/7P/8/xUAKwBDAE0AQwA1ACkAKAA2AEUASwBBADUAKAAkADIAOwBEADwAJgAdABUAIAAvAD0APgA/ADUANQA5AD0ALAABAM//lv9j/0r/Qv9J/1H/Vv9h/2//if+w/+b/FAA9AFoAZQBhAFkAXQBqAH8AkgCWAJ0AnwCeAJwAnQCoAK4ArwC8ANsABgEjAUQBXgFkAWYBaQFyAXMBbAFUAToBKQEfASABKQE0AToBPQFIAVQBXAFQAUQBLgEiAQ4BBwEEARQBGQEVAQQB6ADLAKsAhABZACcA7v/E/6X/g/9u/1r/Rf8o/w7/AP/w/uj+3v7X/tn+1/7T/tv+5v7//hL/Jf84/1H/X/9w/3X/hP+U/6v/xv/r/xIAMwBWAIAAowC2AMEAvQCxAJ4AlgCKAIwAhQB8AHIAaABdAEsAOgAiAPz/z/+m/4X/ZP9O/0D/Mv8o/x3/B//z/uD+3/7c/uD+5P7p/vP+//4U/yX/PP9Z/3j/mv++/+T///8mAD0AVABxAIcAoACxALsAwQC9ALwAqwCjAI0AcQBRACIA+//Q/7H/kP9t/0b/Nv8h/wz/9f7V/rv+pf6W/o/+l/6p/rj+xf7S/tH+y/7X/un+Bv8n/1z/iP+i/7T/yP/W/+7/+P/6/w4ALgBOAGIAcAB4AHoAgQCNAJUAmgCfAK8AyQDcAO0A+QAGAQIB8wDZAMEAoACGAHsAgQCdAL4A1gDoAPYAAwENARYBFgEXAQ8BEwEZARoBHwEgASQBHQEGAeYAxAC2AK0AnACUAH0AaAA6ABoAEAAKAAkAAQDh/7f/nv+F/2n/RP8i//r+4f7L/rX+rf6v/qf+l/6O/oj+hP5r/l7+VP5M/kT+RP5V/mr+f/6X/rb+wv7I/tf+8P4P/y7/Uf95/6X/3f8NADYAWQBvAHkAbwBeAFgAWQBTAE4AQQAyACQAGQAJAPX/6P/a/83/0P/K/9j/4//r/+3/5f/c/9X/yv/a//j/EQAkACkAIAAdACEAMgBHAFUAZgBzAH8AjwCXAK8AtQDDANUA5gDoAPIABQEUARoBGQEUAQwBAAHuANoAyQC2AKIAiwBzAFkANgASANr/l/9X/x///f7q/tr+xf6l/oP+cP5p/nH+fv6Q/pv+qf7E/uT+D/9N/3//pv/H/+z/GgBXAJcAzwD4ABYBNAFRAXkBnQHBAdYB3gHYAcwBygHMAdcB3QHWAcIBsQGKAWUBSAE9ASoBEAH4AOkA3QDJALkAlQB3AFIAOwAqABYA8f/S/7H/kv95/2v/Zv9h/1H/O/8w/yv/I/8e/x3/Kv9C/13/c/+J/6H/vP/X/+v/6P/k/+b/5f/i/+P/7v/s/+T/2v/M/8X/s/+i/5H/ef9g/07/P/8t/yL/Gf8p/zv/VP9i/2//ff97/3f/af9W/0P/NP8n/y3/Hf8V/xX/Dv/9/u/+7v4B/x7/K/8v/zD/Lv8k/yj/Rv90/5n/vf/X/+H/6P/r/wIAEgAjADcATwBvAJMAuADaAPUA/gD9APIA6gDfANYAxwC7AKYAkQB8AGkAXABQAFUAUABQAEQALwAdABUA9P/c/7n/kv98/2z/Yv9Q/z7/Mf80/zf/Rv9K/0T/Sf9S/17/bf9//5L/nv+V/5f/jf+U/6H/tP/H/87/1P/Q/83/xP/H/9f/6P/w//L/+/8GAAwAEwAaAC0APwBXAHQAlwC1ANEA+gAOAR0BJwE0ATwBSQFTAVMBUAFPAUQBNgEqARwBBwH1AN8A2wDYAOcA+wAOAQgB+ADrAN4A1wDbAOQA7gDwAOsA2wC9AJ0AegBMACIA+v/Y/73/q/+i/5P/gP9u/1z/Uf9W/1j/Y/95/5f/uv/b//T/BAARACMANgBaAH8ApgDJANAAzQDTAM8AvQCgAIkAcgBgAEgALQAUAPX/2f/C/6n/kf92/1z/Sf88/0T/Tv9Y/2X/dv+D/6D/w//s/xIAKwBMAGAAcQBxAG4AZgBYAEkAPAA6AC8AJAAbAB4AKQAsADcANwA2ADQAPABRAGMAgwCnANMA9gAXASYBIgEIAeAAvwCkAIIAaQA9ABoA8P/C/5j/cf9F/xP/5/69/qb+m/6J/nf+e/6H/pP+o/6q/rP+tf66/sj+4f7t/vT+Cf8Y/yT/Iv8y/zD/Ov86/0L/T/9d/2H/X/9X/0//Uf9X/2j/d/92/3T/d/+E/43/kv+R/5z/q/+//9j/8f8GABwALQA/AEQASwBKAEsATwBOAE8AXQBiAHcAfABuAFwARgAtABwAGQApAEAAVwBiAGkAZgBhAGAAVgBKADkAJQASAAUA+P/0/+3/6//p/9v/x/+w/5f/hv9x/2j/bv90/4X/i/+K/5X/p//J/+b//f8XADAASABgAHYAggCOAJQAnwCmALEAxwDcAPcACQERAQoB/wDsAOUA2wDSAMUAvACuAKYAlgCCAGMASQAtABMAAAD4//n/AAAEAAEA6P/Q/7P/of+h/6v/rf+y/7z/xP/T/9z/5//h/9//2//m//r/IgBYAHwAhgCPAJYApQC6AMoA0wDbAOAA5QDkAN8AwwCaAG8ASQAiAAwA9//S/5v/W/8x/yD/Dv/y/tT+tf6y/rX+s/6q/qn+rf6q/pz+kP6O/qX+x/7o/g//Lf9D/0r/SP9P/13/cP+C/6j/0//9/xsANwBfAH4AkwCpAMIA4ADuAOMA6QD2AAcBEwEXARoBFQEOAQMB+gDiAMcArgCQAGMAPwAiABIA/f/j/8X/pv+W/5L/k/+X/5H/gP9j/03/Pv8t/yf/J/8x/zT/L/8u/z3/Wv9w/3D/b/9q/3H/bf9t/13/Wv9U/13/dv+h/8j/8P8IACYAPgBTAHYAlACmAKgApQCnALUAugC7AL4AvwCwAJQAdgBfAE8APwAfAP3/yf+k/5L/qP/I/+D//v8TAB4AHQAbABoAGAAZACIAKQA4AEcAXwBzAIAAiQCYAJYAoQCwAMYAzgDIAL8ArQCmAKkArwCxALsAvwC0AK8ApwCUAHsAXABEABoA8P/P/7f/n/+R/4X/ff9l/0//P/8w/yT/Ef/7/uD+y/6z/qH+lf6K/oX+if6R/pz+o/60/rv+xv7J/tT+4f7s/gL/JP9G/1z/bP92/4T/kP+U/5r/pP+u/7n/uf+3/8H/0f/q/wMAHwBDAFUAXABOAEAAMQAlABYACQADAAkAGwAmADQAPQBHAFUAYABoAHMAewCEAIoAiQCNAJEAkwCWAJgAlQCHAHUAWwA4ABgA7v/Q/7f/pf+V/4r/gf9z/2L/TP8y/yD/Gv8Q/wr/B//8/vv+Av8Q/xX/Jv88/03/av93/4X/mP+o/7b/xf/S/+j/AAAYADIATwBzAJkAugDMAN4A7ADyAPoABwEPARYBGwEVAQYBBAEJARABIAEmASEBDQHzANoAuACZAHkAYQBNADsAKQAnADUARABPAGIAdQCIAJcAnwCeAJIAhQCGAI8AoACuAL0AzADaAPQACQENAQkB+ADgAMEAsACpAK8AwwDRAMsAuwCjAJgAjACEAHcAagBKAB0A6v+4/4L/Wf88/yL/Cf8I//v+2f66/o7+Zf43/hv+FP4T/hz+Lf45/kv+Yv54/pL+sP7H/tD+2v7x/gn/Gv8v/1n/jf+//wIARQB+AKkAxgDkAPUACwEZASABIgEXAQ8BDQEMAQcB/gDyAOUA1ADHALEAkwCBAF0APQAiABQAEQAPABQAGgAiACcAJAAiAB0AAwDT/6X/eP9g/1f/Uf9g/23/df90/3D/bv9y/3n/cP9n/1r/Pf8o/x3/Kf87/1H/Wf9X/0H/KP8X/wn/C/8I//3+5/7M/rr+q/6e/p7+o/6l/qr+vf7U/vL+CP8U/xz/H/8t/0D/Vf9s/4P/s//o/yQAXQCHAKsAyQDbAOEA4gDeAOoA7AD4AP0A+AD7AAMBAgEHAQYB/QDqAOAAxwCjAIYAZwBWAFEAVABfAGsAdwB4AG4AWwBLADwALQAlACgAJwAeABgADgAPABcALQA7AEUARgBEAEIAPAAuAC4AMQAuACUAHQAeACsARwBoAIAAiwCFAH8AbgBfAFUAUABGAD4AKgAbABUAEwAOAA0ACgAEAPj/6P/l/9//4v/b/+D/8/8MADAAUABqAH8AiQCKAIkAgQCBAG4AWwBBACwAIgAdABgACQABAAcAFgAUABcAEgABAO//1//K/8b/z//T/8z/uP+g/4z/ev9s/2L/Wf9K/z7/L/8q/y7/Mv8y/zP/Pf9Y/3D/kv+1/9H/7f8CAAwAFwArADgAPQA3AC0AJQAfABsADwADAPf/5P/R/7j/nP+A/3T/a/9q/2r/YP9g/1T/Qv8u/x3/Df8C/wr/HP8u/0T/Wf9j/2n/Y/9c/1f/W/9b/1//YP9j/2P/av9q/2j/Yf9h/2//dP92/4L/hv+L/5b/ov+q/6L/nP+Y/5f/of+k/6v/sP+1/7v/uf+1/6v/of+Y/4b/bv9R/z3/K/8q/zX/Pv9I/1r/Yf9u/3j/iP+V/6j/uf/P/9//6P8CACQAUQBxAIQAkgCeAJ8AkwCRAIwAkQCUAJoAmACWAJIAmACsAMEA1gDrAPYA/gAHARIBIgEqATQBNAEwASEBDwECAfgA8wDsAN8A1AC/AL0AtACwAKwApwCjAJwAmwCbAJ8AngCXAJYAnACiAKEApACnAJ4AlgCPAJIAjACKAIUAjACNAJcAnAChAJwAiAB3AHQAegByAGcAUQBDADIAGQD+/9b/tv+b/4v/ev9y/3X/gf+W/6H/rv+2/7//vP+//8D/sv+q/6v/tf+6/8D/yf/R/8//3P/q/wIAFAAhACwANgA1ADcAOQA7AEAASABZAGkAdQB+AJEAmACZAI0AlwCZAI4AdwBaAEEAJwAUAP7/5//f/93/1P/R/8P/tP+c/4T/af9O/zz/KP8b/w//Af/2/vX++/4J/xf/L/9C/1T/X/9v/4b/pP++/8//0//R/9j/5f/1/wYACwAQABUAGQAnACUAJQAiABwAGwAmACoAKQAcAA4A+//i/9T/xf/A/73/tv+t/6P/lf+H/4L/e/9z/2P/UP88/yL/GP8Z/yX/Of9G/13/bP+B/57/u//U//T/DQAqAEMAUwBgAHEAewCBAI4AmwC6ANAA6QAAAREBHAEqAS0BNgE2AS4BJgEaAQ4B9gDyAOMA1AC+AK4AkgBxAEoAKgARAPX/3P/G/6n/gv9i/1b/Xf9b/1j/Wf9b/1r/W/9b/1v/b/+D/5P/k/+T/4z/hf+C/3H/bf9o/27/c/93/3b/d/91/3j/f/+M/5f/rP+8/7z/wf/D/8z/4P/x//z/AAAFAPr/+f/6//T/6f/e/87/uv+s/5v/l/+W/5X/lP+e/6z/xv/d//T/BAAcADsAZQCUANEABgEsAUYBUwFXAVcBVgFPAUcBNwEYAfgAzgCrAJEAbABJACEAAADo/9j/xv+8/7f/v/+8/8H/wv/E/8v/1f/g/+3/+v8CABYAIwAoACgALAA2AD0ANwAyADAAMQA1ADoANwAqACIAHQAeACQAGwAeADEASQBXAFgATAA7ADcALwAxACcAHgAPAPf/5P/T/9P/yv+4/6H/j/9y/2H/Uf9H/z7/PP9J/1H/Y/95/5H/tP/U//3/LABnAJ8AygDsAAcBGwEvAUsBWgFkAVsBSgE8AS8BFAHvAMsAqACLAGcAQgAnABEAAgD2/+X/yv+z/6z/pv+j/6D/o/+d/5b/nP+f/6P/sP+0/67/nf+R/5f/lv+P/4f/hP92/2L/Wf9T/1X/a/+K/5z/qP+1/8P/1f/5/xwAOwBXAG0AeAB+AIUAjgCYAJgAnQCaAJIAgABvAFwASwA4ACcABgDu/8T/n/9+/2f/XP9M/z3/Lf8h/w3/CP8G/xb/Lv9D/2H/df92/3//g/+D/4v/iv+S/5T/iP95/27/bf9m/2X/Z/9v/2//a/9u/3T/gf+P/5T/kv+L/5D/lP+W/6D/qv+t/6n/pf+r/6j/qf+l/6L/nP+L/3X/Zf9X/0r/R/9R/1z/af9z/4D/l/+j/7f/xv/Y/+f/+v8NABgAIgAiACQAJwAjACoAOABBAEIANQAtABwAEQAGAPn/+P/8/wwAHwApADwAUQBTAFMAUwBWAFAATQBRAE0ATQBIAFMAXwBnAHgAjACYAKcAqQCrAKwAuADDAMwAyAC/ALcArgCnAKAAmACUAI4AiACFAHoAcgBiAFgARgAwACcAHQAiADMAQQBLAFMAVwBgAGUAYgBjAFgAWQBXAFUAYwB3AIkAkQCXAJwAnACVAJQAmgCcAKQAsgC+ALwAuwC7AMAAvAC9AKwAmACNAIoAhgB8AHQAcgBuAGkAYgBKAC0AFAD1/9n/xP+0/6z/m/+C/27/Xv9S/0z/TP9K/1D/Uf9f/2T/X/9a/1P/U/9V/13/W/9q/3j/ff+C/4X/h/+E/4j/iv+F/4P/ef9l/2H/UP9O/0z/Sv9E/z7/Qf8x/yr/Jv8n/yP/Iv8b/xL/Df8K/xb/Jf8z/0n/X/96/5T/ov+s/7X/uf+5/7v/uf+2/73/0P/h/+f/9v8BAAwADQAHAP3/9P/v//L/8//3/wMACQASABgAIwAsACoAMgA5ADYAMAAvACkAGwANAAQA/v/5//r/9P/+/wwAFQARAP3/7f/e/9//2v/k/+n/8v/x/+b/5f/m/+v/7P/m/9n/y/+0/6r/of+e/5//mP+R/4P/ef9//4j/mf+g/6j/o/+n/7f/xP/Y/+T/+/8ZADAASABmAIQAmACnAK0ArgCoAKMAmwCYAI8AhwB9AHQAZgBXAEwAOQAdAAcA+v/u/+j/3P/V/9H/yf+8/7z/tP+z/7P/tP+3/7r/vP+9/7z/tP+y/8P/zP/F/8D/w//E/77/xP/L/9//8P8CAAEACQAGAP3/CAANABcAGgAZABwAKAAxAEAATgBZAGEAZABsAGkAZABhAGQAYQBWAFAASgA9AC4AJgAjACMAIAAaABgAHQAoADAAPgBMAFkAYgByAH8AhACGAIcAgAB1AGcAXwBXAEsAPgA0AC8AKwAoACYAJwAqAC4AOABIAF8AbQB5AHsAfwB+AH4AfgCNAJUAigB8AHcAbgBrAGUAXgBVAEIAOQAtACYAIgAiACIAEwACAPz/AAD5//j/9f/0/+3/3v/Y/9P/1P/J/8r/y//K/8b/v/+y/6r/q/+v/77/wP+9/7b/rv+j/6P/qf+Z/5P/if95/2L/T/9H/0r/U/9m/3v/jv+j/7L/xP/L/8v/z//U/9b/2v/e/9n/zf/A/7f/tP+y/7T/uP+3/73/vv/J/9L/1P/d/+H/4//f/+b/8//z//X/9f/1/+7/7//3//H/6f/m/+H/3v/X/9j/3P/f/93/2//e/9n/3f/e/+D/0//L/7j/qf+l/6T/pP+f/43/ev9q/1n/Uv9R/1D/Tf9K/0f/QP86/y3/Iv8i/yv/MP8z/zH/OP8//0z/Wv9m/3L/f/+G/4z/mf+j/7T/1P/7/xwAMgBKAF8AcACBAJUAsQDKANQA0QDQAMkAvgDAAMMAwgC5ALUArwCqAKYAmwCJAHgAYQA9ACAABQDq/9P/wf+3/6r/ov+X/5f/jP+M/4b/f/+F/4j/mf+t/8n/4P/x//v/BAAUABwAJgAqAC4AOQA7AD8AQQBFAFMAVgBdAGEAaQBrAGYAawBpAF8AUAA/ADIAIwASAAYA+P/u/93/zv/E/7f/pf+a/5H/kP+i/7b/zf/R/9z/4f/t//f/CwAmADsATwBnAHsAlgCsALsAyQDEAMQAugDAAMUAvgC9AMkA0wDcAOkA9gABAf8A7QDWALQAmQCEAG0AUwBCADgALAAmABkABQDr/9L/tv+Y/3b/Wf8//zH/MP80/zn/PP88/z3/Qf9R/1z/aP92/4n/of+3/8//4//+/xwALgBFAFcAZABwAHUAeQCBAI0AjwCbAKYAqACsAKkApgCdAJUAjQCGAH8AcgBkAFkAVwBTAEkAQQAqABAA9v/i/8n/tf+g/4v/gP97/3j/bv9s/2//cf9y/3n/gf+U/6v/yf/h//3/DQAaADEAQQBiAHQAjQCfAK4AvQC5ALEAowCcAJIAfABsAF8ASwA3ACMAHAAIAO//1P/G/8L/tv+w/7L/sf+f/6L/q/+l/5D/ef9f/0L/PP9B/0H/OP86/y3/IP8v/0b/YP98/6D/wP/O/+D/8/8JAB8ANABMAGMAfACGAIkAkACMAIAAcwBoAGAAXgBcAFIATQBCADMAHAAdABkADQD//+X/wf+o/5r/kv+T/5b/oP+c/5X/mf+X/5X/m/+l/6j/qv+9/8n/2P/n//L/9//4//b/7//w//P/9//6//n/9f/5//7//v8CAP3/9P/t//L//f8PABsAIwAeAA8ADwAEAAQA///9/wAACAAYACYAQQBIAEsATQBEADUAIwAVABAADgASABUAEwAdADEARABPAFwAXgBTAE4ARwBCAEQASwBHAEoARQBFAEoAUABNAFQAVQBQAEkATgBbAFoAXABZAFAATQBUAE4ARwBAAEAARgBTAGoAcwB1AHUAeQB2AGgAagB3AIgAjgCMAIAAdABeAFMARQA5ACcABQDn/8v/vf+w/6v/pf+n/6L/mv+H/3z/fv9//4P/h/+X/6D/qP+x/73/xf/N/9j/4//v//T/9f8CABcALgBCAEwAUABUAFQAQgAnABIACQALAAsAFAAWABcADwADAPf/6v/c/9L/z//N/9T/3f/w/wIAEgAeACEAGwAPAAAAAgD5//H/8//t//P/+P8KABoAIQAuADMAOwBDAFcAbgCAAJMAmgCgAKQApgCoALAAtgC2AK8AogCdAJAAfgBsAE4AKgABAN3/v/+p/53/kv+M/4v/hP97/3r/df9u/2r/bP9y/4D/mv+4/8v/zv/K/8z/y//J/8z/y//M/8r/xP/C/8r/0P/a/9T/0v/T/87/1//X/+n//v8KABsAKQAyADkAOQA3ACgAEQAJAA4AHAAuADsAPQBGAEAAMgAYAAEA5v/M/8f/xf/N/9L/3v/w/wEADwAfADAASABOAFcAYQBkAHgAjwCpALMAvAC7AK8ApgCWAJMAjACMAIMAgAByAGYAXgBPAEMAOAAyACEAIgAmACcAJAAgABsADgD1/9T/tv+h/5j/pf+3/8H/0v/g/+j/3f/W/8T/r/+f/5j/m/+V/5T/lv+i/6f/uf/N/9b/4v/j/+3/BgAYAC0ARQBMAE8AUABYAF0AZABoAG4AbgBlAF0AUABIADIAHgAKAOn/1f/N/9D/2f/k/+7/+P/0//T/+f8BAA0AGQA1AE8AaACBAKcAzgDpAPoA/QAGAQoBBwEFAQIBBgH9APAA5QDdAMkApQCDAFwANwAbAAwABQD6//X/8P/q/+b/3f/d/97/2f/a/9j/2v/e/+T/5v/b/87/u/+q/5n/fv9t/2n/aP9x/3n/g/+S/5v/mf+R/4v/hf+H/5H/m/+r/77/3v/4/wEAAwACAAIA+//0/+f/2v/Q/8r/zv/O/8f/tv+l/5P/h/+C/3f/eP9w/2n/Z/9m/2n/a/90/2r/Yv9f/2f/fv+U/6z/xP/c/+z/9v/8//X/6//h/97/5f/w//3/FwAuAD8ASwBRAFQAVABYAFUAXQBqAHIAgwCRAJcAkACAAHEAYgBMAEIAPAAxACsAIAAXAAkA8v/a/73/q/+g/5H/iP9//4T/iv+D/33/a/9b/0P/L/8s/zv/UP9x/4//qv/G/9D/1f/K/8r/vf+y/6z/s/+8/8n/1f/c/+//9P/8//j/9f/0//z/CQAUAC4ARQBSAFgAYABaAFIASQA6ADYAOQBDAEwASgBIADwAKQAgABQACQAMABIAHQAnADYAQQBPAE4ARwA/AEcATABRAGAAcwCGAJcApACsALQApgCdAJAAjwCXAKEAqACuALgAsQCeAIIAZgBJAC8AEwD3/9X/tf+n/5//o/+b/4z/fv91/3P/d/+B/4v/oP+//9j/5P/m/9z/z/++/6r/l/97/3L/df94/3//h/+P/5H/k/+R/4z/jv+Q/6H/tv/F/9v/7//+/woAEAAOAAcA+f/w/+b/5//q/+r/7v/m/+D/0/++/6z/mP+L/4j/jf+W/5j/pf+x/77/xf/M/9b/5v8BABYAKQBBAF8AbgB8AH4AeQB4AGcAWABIAD0APgBCAEMASABHADgAJwATAP3/6//o//H//v8NACQANQA/ADMAJgAjABUA9v/j/9H/wv/F/7v/tP+u/6n/mv9+/2L/T/8z/x3/F/8X/yD/Mf9D/0z/Uv9K/0v/Vv9o/3n/iP+c/67/yf/e/+3/9f/2//3/AgAEAAoACQAVACgANwBBAEAAOgAzACMAEgAIAP3/AAAAAAQACQANAAkAAQD8//L/6P/m/+z/8f/7/woADAAJAP7/8f/f/9L/xP+9/8T/zP/Q/9f/1//N/8v/w/+4/6j/nP+g/6z/wP/O/+D/3f/j/+j/6//t/9//1f/D/7z/vP+1/7n/uv+3/6j/lP+D/3z/eP91/3b/eP96/3H/dP+C/5b/pv+u/7H/s/+v/6X/p/+v/8b/z//Y/+7/+/8SABwAJgAyADkARQBRAF4AZABjAFgASgBBAEAAOwAzAC0ALgAtACMAHgAPAAQA/f/r/9v/zv/C/73/v/+9/7r/tP+q/53/lv+Y/5T/mP+l/67/sv+1/8D/0//k//X/BwASABwAJAAvAEAAXwB9AI8AnQCtALkAxQDKAM8AygC7AK0AnQCOAIYAigCLAHwAXgA9AB4ABgD1//L/7//k/9f/y//E/7//tv+u/6n/p/+p/7X/v//I/9f/2v/o//H/9P/1//P/8//q/+n/4//k/+f/7P/6//3/AAD9//z/+//4//7//f/+/wAAAAD8//v//f/9//f/8//r/9v/2P/a/9n/0f+8/6n/lP94/2f/Tv80/x7/D/8F//v+9/7w/uj+2/7T/s/+z/7Z/vH+Ef83/1v/eP+V/63/xP/Q/9r/3P/j//D/9/8AAPf/6v/j/9z/3f/Y/9X/1f/I/8L/sv+t/6f/pv+n/6L/oP+b/5v/nP+k/7X/yf/X/+H/6P/w//z/AwAJAAMA/P/3//P/+P/0/+z/4v/V/8r/vf+y/7H/q/+n/6b/o/+s/7T/uv/K/9n/4v/p/+L/4v/k/+L/4P/h/9n/z//B/7D/pv+Y/4v/ev9n/1z/Vf9M/0X/Rf9E/0T/Sf9X/2f/eP+F/4//nf+q/7X/wP/N/9H/2v/X/9P/0v/V/9n/3v/n/+r/7v/y//j//f8BAAAA/P/8//v///8KABwAMgBAAEEAOgA1AC4AMAA6AD8ARwBMAFUAUwBPAFUAVQBXAFsAZQBtAHYAgwCKAI8AlACJAIQAdwBqAF8AUQBCADoALgAmAB0AHQAoACcAJQAVAAQA8P8=\" type=\"audio/x-wav\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ]
          },
          "metadata": {},
          "execution_count": 86
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "convert to coefficients"
      ],
      "metadata": {
        "id": "UhQV9P7Vgpkt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
        "    "
      ],
      "metadata": {
        "id": "DaDq_PR8guaQ"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mfccs_scaled_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZt03Ehog29d",
        "outputId": "f57b5dc3-b475-4160-abca-6f62f69bcdcd"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-2.9255460e+02,  1.2333990e+02, -1.7977497e+01, -1.9465195e+01,\n",
              "       -3.4824532e+01, -5.0322423e+00, -3.3660961e+01, -1.4659142e+01,\n",
              "       -1.1089680e+01,  2.3560376e+00, -2.6743579e+00, -4.9213500e+00,\n",
              "       -1.1083390e+01,  8.8822281e-01,  5.4673033e+00,  3.8802702e+00,\n",
              "       -1.4164753e+00, -5.2310200e+00, -6.6400552e+00, -8.7423944e-01,\n",
              "       -5.8875451e+00, -1.0457999e+01, -9.1981153e+00, -1.3042639e+00,\n",
              "       -5.1963168e-01,  1.6647016e+00,  3.2785468e+00,  1.4544599e+00,\n",
              "        4.8839760e+00,  2.7494414e+00, -5.9516716e-01, -1.8394426e+00,\n",
              "        4.4991046e-01,  9.5993906e-02, -2.2570299e-01, -8.8305968e-01,\n",
              "       -1.8622298e+00,  9.3149734e-01,  1.3050426e+00,  6.6363078e-01],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mfccs_scaled_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yK4e2TuhSlI",
        "outputId": "6afc1d8f-bedf-4596-e1d4-9c66390bcb8c"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40,)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)"
      ],
      "metadata": {
        "id": "w7A2D-iLiZUf"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mfccs_scaled_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtnW4aqOicsf",
        "outputId": "d8c859d1-53aa-4fb6-9b04-49e24dd3f589"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_label=model3.predict(mfccs_scaled_features)\n",
        "predicted_label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vJqB5CghwbS",
        "outputId": "f6c406f6-922e-43da-a577-1c90a6284b40"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 66ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.9042181e-12, 8.6290993e-06, 5.1331819e-05, 9.9294055e-01,\n",
              "        5.3707654e-06, 7.8537852e-09, 6.8191234e-03, 2.9689065e-18,\n",
              "        1.5929883e-04, 1.5621585e-05]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label=np.argmax(predicted_label,axis=1)\n",
        "label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpdVgP5xiX0C",
        "outputId": "9c26519b-9479-4fc0-80e3-26d98dea7808"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3])"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_encoded_data.columns[label]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6cHyY5amGFK",
        "outputId": "dfcbcaed-93d1-4361-af74-88d7f3edc1b8"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['class_dog_bark'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[3] is dog_bark ,hence prediction is right"
      ],
      "metadata": {
        "id": "mtnn2tHNlPpC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pkAcKyCN-i1M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}